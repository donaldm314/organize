{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to organize's documentation # organize - The file management automation tool Full documentation at Read the docs v3 is now available # The new version should be much faster and fix a lot of bugs. It also comes with a some new actions, filters and options. If you encounter any other bugs or problems during the migration, please reach out! See the changelog Migration guide About # Your desktop is a mess? You cannot find anything in your downloads and documents? Sorting and renaming all these files by hand is too tedious? Time to automate it once and benefit from it forever. organize is a command line, open-source alternative to apps like Hazel (macOS) or File Juggler (Windows). People use this for: # Sorting and tagging pictures into various folder structures based on EXIF data Sorting and renaming PDF invoices based on file content Removing incomplete downloads from their ~/Downloads Cleaning up their ~/Desktop from unused files Freeing up disk space by removing duplicates Automating various business processes and many more Features # Some highlights include: Safe moving, renaming, copying of files and folders with conflict resolution options. Fast duplicate file detection. Exif tags extraction. Categorization via text extracted from PDF, DOCX and many more. Powerful template engine. Inline python and shell commands as filters and actions for maximum flexibility. Everything can be simulated before touching your files. Works on macOS, Windows and Linux. Free and open source software. Getting started # Installation # Only python 3.9+ is needed. Install it via your package manager or from python.org . Installation is done via pip. Note that the package name is organize-tool : pip install -U organize-tool This command can also be used to update to the newest version. Now you can run organize --help to check if the installation was successful. Create your first rule # In your shell, run organize new and then organize edit to edit the configuration: rules: - name: \"Find PDFs\" locations: - ~/Downloads subfolders: true filters: - extension: pdf actions: - echo: \"Found PDF!\" If you have problems editing the configuration you can run organize show --reveal to reveal the configuration folder in your file manager. You can then edit the config.yaml in your favourite editor. save your config file and run: organize run You will see a list of all .pdf files you have in your downloads folder (+ subfolders). For now we only show the text Found PDF! for each file, but this will change soon... (If it shows Nothing to do you simply don't have any pdfs in your downloads folder). Run organize edit again and add a move -action to your rule: actions: - echo: \"Found PDF!\" - move: ~/Documents/PDFs/ Now run organize sim to see what would happen without touching your files. You will see that your pdf-files would be moved over to your Documents/PDFs folder. Congratulations, you just automated your first task. You can now run organize run whenever you like and all your pdfs are a bit more organized. It's that easy. There is so much more. You want to rename / copy files, run custom shell- or python scripts, match names with regular expressions or use placeholder variables? organize has you covered. Have a look at the advanced usage example below! Example rules # Here are some examples of simple organization and cleanup rules. Modify to your needs! Move all invoices, orders or purchase documents into your documents folder: rules: - name: \"Sort my invoices and receipts\" locations: ~/Downloads subfolders: true filters: - extension: pdf - name: contains: - Invoice - Order - Purchase case_sensitive: false actions: - move: ~/Documents/Shopping/ Recursively delete all empty directories: rules: - name: \"Recursively delete all empty directories\" locations: - path: ~/Downloads targets: dirs subfolders: true filters: - empty actions: - delete You'll find many more examples in the full documentation . Command line interface # organize - The file management automation tool. Usage: organize run [options] [<config>] organize sim [options] [<config>] organize new [<config>] organize edit [<config>] organize check [<config>] organize debug [<config>] organize show [--path|--reveal] [<config>] organize list organize docs organize --version organize --help Commands: run Organize your files. sim Simulate organizing your files. new Creates a new config. edit Edit the config file with $EDITOR. check Check whether the config file is valid. debug Shows the raw config parsing steps. show Print the config to stdout. Use --reveal to reveal the file in your file manager Use --path to show the path to the file list Lists config files found in the default locations. docs Open the documentation. Options: <config> A config name or path to a config file -W --working-dir <dir> The working directory -F --format (default|jsonl) The output format [Default: default] -T --tags <tags> Tags to run (eg. \"initial,release\") -S --skip-tags <tags> Tags to skip -h --help Show this help page. Other donation options: # ETH: 0x8924a060CD533699E230C5694EC95b26BC4168E7 BTC: 39vpniiZk8qqGB2xEqcDjtWxngFCCdWGjY","title":"Home"},{"location":"#welcome-to-organizes-documentation","text":"organize - The file management automation tool Full documentation at Read the docs","title":"Welcome to organize's documentation"},{"location":"#v3-is-now-available","text":"The new version should be much faster and fix a lot of bugs. It also comes with a some new actions, filters and options. If you encounter any other bugs or problems during the migration, please reach out! See the changelog Migration guide","title":"v3 is now available"},{"location":"#about","text":"Your desktop is a mess? You cannot find anything in your downloads and documents? Sorting and renaming all these files by hand is too tedious? Time to automate it once and benefit from it forever. organize is a command line, open-source alternative to apps like Hazel (macOS) or File Juggler (Windows).","title":"About"},{"location":"#people-use-this-for","text":"Sorting and tagging pictures into various folder structures based on EXIF data Sorting and renaming PDF invoices based on file content Removing incomplete downloads from their ~/Downloads Cleaning up their ~/Desktop from unused files Freeing up disk space by removing duplicates Automating various business processes and many more","title":"People use this for:"},{"location":"#features","text":"Some highlights include: Safe moving, renaming, copying of files and folders with conflict resolution options. Fast duplicate file detection. Exif tags extraction. Categorization via text extracted from PDF, DOCX and many more. Powerful template engine. Inline python and shell commands as filters and actions for maximum flexibility. Everything can be simulated before touching your files. Works on macOS, Windows and Linux. Free and open source software.","title":"Features"},{"location":"#getting-started","text":"","title":"Getting started"},{"location":"#installation","text":"Only python 3.9+ is needed. Install it via your package manager or from python.org . Installation is done via pip. Note that the package name is organize-tool : pip install -U organize-tool This command can also be used to update to the newest version. Now you can run organize --help to check if the installation was successful.","title":"Installation"},{"location":"#create-your-first-rule","text":"In your shell, run organize new and then organize edit to edit the configuration: rules: - name: \"Find PDFs\" locations: - ~/Downloads subfolders: true filters: - extension: pdf actions: - echo: \"Found PDF!\" If you have problems editing the configuration you can run organize show --reveal to reveal the configuration folder in your file manager. You can then edit the config.yaml in your favourite editor. save your config file and run: organize run You will see a list of all .pdf files you have in your downloads folder (+ subfolders). For now we only show the text Found PDF! for each file, but this will change soon... (If it shows Nothing to do you simply don't have any pdfs in your downloads folder). Run organize edit again and add a move -action to your rule: actions: - echo: \"Found PDF!\" - move: ~/Documents/PDFs/ Now run organize sim to see what would happen without touching your files. You will see that your pdf-files would be moved over to your Documents/PDFs folder. Congratulations, you just automated your first task. You can now run organize run whenever you like and all your pdfs are a bit more organized. It's that easy. There is so much more. You want to rename / copy files, run custom shell- or python scripts, match names with regular expressions or use placeholder variables? organize has you covered. Have a look at the advanced usage example below!","title":"Create your first rule"},{"location":"#example-rules","text":"Here are some examples of simple organization and cleanup rules. Modify to your needs! Move all invoices, orders or purchase documents into your documents folder: rules: - name: \"Sort my invoices and receipts\" locations: ~/Downloads subfolders: true filters: - extension: pdf - name: contains: - Invoice - Order - Purchase case_sensitive: false actions: - move: ~/Documents/Shopping/ Recursively delete all empty directories: rules: - name: \"Recursively delete all empty directories\" locations: - path: ~/Downloads targets: dirs subfolders: true filters: - empty actions: - delete You'll find many more examples in the full documentation .","title":"Example rules"},{"location":"#command-line-interface","text":"organize - The file management automation tool. Usage: organize run [options] [<config>] organize sim [options] [<config>] organize new [<config>] organize edit [<config>] organize check [<config>] organize debug [<config>] organize show [--path|--reveal] [<config>] organize list organize docs organize --version organize --help Commands: run Organize your files. sim Simulate organizing your files. new Creates a new config. edit Edit the config file with $EDITOR. check Check whether the config file is valid. debug Shows the raw config parsing steps. show Print the config to stdout. Use --reveal to reveal the file in your file manager Use --path to show the path to the file list Lists config files found in the default locations. docs Open the documentation. Options: <config> A config name or path to a config file -W --working-dir <dir> The working directory -F --format (default|jsonl) The output format [Default: default] -T --tags <tags> Tags to run (eg. \"initial,release\") -S --skip-tags <tags> Tags to skip -h --help Show this help page.","title":"Command line interface"},{"location":"#other-donation-options","text":"ETH: 0x8924a060CD533699E230C5694EC95b26BC4168E7 BTC: 39vpniiZk8qqGB2xEqcDjtWxngFCCdWGjY","title":"Other donation options:"},{"location":"actions/","text":"Actions # This page shows the specifics of each action. For basic action usage and options have a look at the Rules section. confirm # Ask for confirmation before continuing. Source code in organize/actions/confirm.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 @dataclass ( config = ConfigDict ( coerce_numbers_to_str = True , extra = \"forbid\" )) class Confirm : \"\"\"Ask for confirmation before continuing.\"\"\" msg : str = \"Continue?\" default : bool = True action_config : ClassVar [ ActionConfig ] = ActionConfig ( name = \"confirm\" , standalone = True , files = True , dirs = True , ) def __post_init__ ( self ): self . _msg = Template . from_string ( self . msg ) def pipeline ( self , res : Resource , output : Output , simulate : bool ): msg = render ( self . _msg , res . dict ()) result = output . confirm ( res = res , msg = msg , sender = self , default = self . default ) if not result : raise StopIteration ( \"Aborted\" ) Examples Confirm before deleting a duplicate rules: - name: \"Delete duplicates with confirmation\" locations: - ~/Downloads - ~/Documents filters: - not empty - duplicate - name actions: - confirm: \"Delete {name}?\" - trash copy # Copy a file or dir to a new location. If the specified path does not exist it will be created. Attributes: dest ( str ) \u2013 The destination where the file / dir should be copied to. If dest ends with a slash, it is assumed to be a target directory and the file / dir will be copied into dest and keep its name. on_conflict ( str ) \u2013 What should happen in case dest already exists. One of skip , overwrite , trash , rename_new and rename_existing . Defaults to rename_new . rename_template ( str ) \u2013 A template for renaming the file / dir in case of a conflict. Defaults to {name} {counter}{extension} . autodetect_folder ( bool ) \u2013 In case you forget the ending slash \"/\" to indicate copying into a folder this settings will handle targets without a file extension as folders. If you really mean to copy to a file without file extension, set this to false. Defaults to True. continue_with ( str) = \"copy\" | \"original\" ) \u2013 Continue the next action either with the path to the copy or the path the original. Defaults to \"copy\". The next action will work with the created copy. Source code in organize/actions/copy.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 @dataclass ( config = ConfigDict ( coerce_numbers_to_str = True , extra = \"forbid\" )) class Copy : \"\"\"Copy a file or dir to a new location. If the specified path does not exist it will be created. Attributes: dest (str): The destination where the file / dir should be copied to. If `dest` ends with a slash, it is assumed to be a target directory and the file / dir will be copied into `dest` and keep its name. on_conflict (str): What should happen in case **dest** already exists. One of `skip`, `overwrite`, `trash`, `rename_new` and `rename_existing`. Defaults to `rename_new`. rename_template (str): A template for renaming the file / dir in case of a conflict. Defaults to `{name} {counter}{extension}`. autodetect_folder (bool): In case you forget the ending slash \"/\" to indicate copying into a folder this settings will handle targets without a file extension as folders. If you really mean to copy to a file without file extension, set this to false. Defaults to True. continue_with (str) = \"copy\" | \"original\": Continue the next action either with the path to the copy or the path the original. Defaults to \"copy\". The next action will work with the created copy. \"\"\" dest : str on_conflict : ConflictMode = \"rename_new\" rename_template : str = \" {name} {counter}{extension} \" autodetect_folder : bool = True continue_with : Literal [ \"copy\" , \"original\" ] = \"copy\" action_config : ClassVar [ ActionConfig ] = ActionConfig ( name = \"copy\" , standalone = False , files = True , dirs = True , ) def __post_init__ ( self ): self . _dest = Template . from_string ( self . dest ) self . _rename_template = Template . from_string ( self . rename_template ) def pipeline ( self , res : Resource , output : Output , simulate : bool ): assert res . path is not None , \"Does not support standalone mode\" rendered = render ( self . _dest , res . dict ()) # fully resolve the destination for folder targets and prepare the folder # structure dst = prepare_target_path ( src_name = res . path . name , dst = rendered , autodetect_folder = self . autodetect_folder , simulate = simulate , ) # Resolve conflicts before copying the file to the destination skip_action , dst = resolve_conflict ( dst = dst , res = res , conflict_mode = self . on_conflict , rename_template = self . _rename_template , simulate = simulate , output = output , ) if skip_action : return output . msg ( res = res , msg = f \"Copy to { dst } \" , sender = self ) res . walker_skip_pathes . add ( dst ) if not simulate : if res . is_dir (): shutil . copytree ( src = res . path , dst = dst ) else : shutil . copy2 ( src = res . path , dst = dst ) # continue with either the original path or the path to the copy if self . continue_with == \"copy\" : res . path = dst Examples: Copy all pdfs into ~/Desktop/somefolder/ and keep filenames rules: - locations: ~/Desktop filters: - extension: pdf actions: - copy: \"~/Desktop/somefolder/\" Use a placeholder to copy all .pdf files into a \"PDF\" folder and all .jpg files into a \"JPG\" folder. Existing files will be overwritten. rules: - locations: ~/Desktop filters: - extension: - pdf - jpg actions: - copy: dest: \"~/Desktop/{extension.upper()}/\" on_conflict: overwrite Copy into the folder Invoices . Keep the filename but do not overwrite existing files. To prevent overwriting files, an index is added to the filename, so somefile.jpg becomes somefile 2.jpg . The counter separator is ' ' by default, but can be changed using the counter_separator property. rules: - locations: ~/Desktop/Invoices filters: - extension: - pdf actions: - copy: dest: \"~/Documents/Invoices/\" on_conflict: \"rename_new\" rename_template: \"{name} {counter}{extension}\" delete # Delete a file from disk. Deleted files have no recovery option! Using the Trash action is strongly advised for most use-cases! Source code in organize/actions/delete.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 @dataclass ( config = ConfigDict ( extra = \"forbid\" )) class Delete : \"\"\" Delete a file from disk. Deleted files have no recovery option! Using the `Trash` action is strongly advised for most use-cases! \"\"\" action_config : ClassVar [ ActionConfig ] = ActionConfig ( name = \"delete\" , standalone = False , files = True , dirs = True , ) def pipeline ( self , res : Resource , output : Output , simulate : bool ): assert res . path is not None , \"Does not support standalone mode\" output . msg ( res = res , msg = f \"Deleting { res . path } \" , sender = self ) if not simulate : delete ( res . path ) res . path = None Examples: Delete old downloads. rules: - locations: \"~/Downloads\" filters: - lastmodified: days: 365 - extension: - png - jpg actions: - delete Delete all empty subfolders rules: - name: Delete all empty subfolders locations: - path: \"~/Downloads\" max_depth: null targets: dirs filters: - empty actions: - delete echo # Prints the given message. This can be useful to test your rules, especially in combination with placeholder variables. Attributes: msg ( str ) \u2013 The message to print. Accepts placeholder variables. Source code in organize/actions/echo.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 @dataclass ( config = ConfigDict ( extra = \"forbid\" )) class Echo : \"\"\"Prints the given message. This can be useful to test your rules, especially in combination with placeholder variables. Attributes: msg (str): The message to print. Accepts placeholder variables. \"\"\" msg : str = \"\" action_config : ClassVar [ ActionConfig ] = ActionConfig ( name = \"echo\" , standalone = True , files = True , dirs = True , ) def __post_init__ ( self ): self . _msg_templ = Template . from_string ( self . msg ) def pipeline ( self , res : Resource , output : Output , simulate : bool ): full_msg = render ( self . _msg_templ , res . dict ()) output . msg ( res , full_msg , sender = self ) Examples: rules: - name: \"Find files older than a year\" locations: ~/Desktop filters: - lastmodified: days: 365 actions: - echo: \"Found old file\" Prints \"Hello World!\" and filepath for each file on the desktop: rules: - locations: - ~/Desktop actions: - echo: \"Hello World! {path}\" This will print something like Found a ZIP: \"backup\" for each file on your desktop rules: - locations: - ~/Desktop filters: - extension - name actions: - echo: 'Found a {extension.upper()}: \"{name}\"' Show the {relative_path} and {path} of all files in '~/Downloads', '~/Desktop' and their subfolders: rules: - locations: - path: ~/Desktop max_depth: null - path: ~/Downloads max_depth: null actions: - echo: \"Path: {path}\" - echo: \"Relative: {relative_path}\" hardlink # Create a hardlink. Attributes: dest ( str ) \u2013 The hardlink destination. If dest ends with a slash `/``, create the hardlink in the given directory. Can contain placeholders. on_conflict ( str ) \u2013 What should happen in case dest already exists. One of skip , overwrite , trash , rename_new and rename_existing . Defaults to rename_new . rename_template ( str ) \u2013 A template for renaming the file / dir in case of a conflict. Defaults to {name} {counter}{extension} . autodetect_folder ( bool ) \u2013 In case you forget the ending slash \"/\" to indicate copying into a folder this settings will handle targets without a file extension as folders. If you really mean to copy to a file without file extension, set this to false. Default: true Source code in organize/actions/hardlink.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 @dataclass ( config = ConfigDict ( coerce_numbers_to_str = True , extra = \"forbid\" )) class Hardlink : \"\"\"Create a hardlink. Attributes: dest (str): The hardlink destination. If **dest** ends with a slash `/``, create the hardlink in the given directory. Can contain placeholders. on_conflict (str): What should happen in case **dest** already exists. One of `skip`, `overwrite`, `trash`, `rename_new` and `rename_existing`. Defaults to `rename_new`. rename_template (str): A template for renaming the file / dir in case of a conflict. Defaults to `{name} {counter}{extension}`. autodetect_folder (bool): In case you forget the ending slash \"/\" to indicate copying into a folder this settings will handle targets without a file extension as folders. If you really mean to copy to a file without file extension, set this to false. Default: true \"\"\" dest : str on_conflict : ConflictMode = \"rename_new\" rename_template : str = \" {name} {counter}{extension} \" autodetect_folder : bool = True action_config : ClassVar [ ActionConfig ] = ActionConfig ( name = \"hardlink\" , standalone = False , files = True , dirs = True , ) def __post_init__ ( self ): self . _dest = Template . from_string ( self . dest ) self . _rename_template = Template . from_string ( self . rename_template ) def pipeline ( self , res : Resource , output : Output , simulate : bool ): assert res . path is not None , \"Does not support standalone mode\" rendered = render ( self . _dest , res . dict ()) dst = prepare_target_path ( src_name = res . path . name , dst = rendered , autodetect_folder = self . autodetect_folder , simulate = simulate , ) skip_action , dst = resolve_conflict ( dst = dst , res = res , conflict_mode = self . on_conflict , rename_template = self . _rename_template , simulate = simulate , output = output , ) if skip_action : return output . msg ( res = res , msg = f \"Creating hardlink at { dst } \" , sender = self ) if not simulate : create_hardlink ( target = res . path , link = dst ) res . walker_skip_pathes . add ( dst ) macos_tags # Add macOS tags. Attributes: *tags ( str ) \u2013 A list of tags or a single tag. The color can be specified in brackets after the tag name, for example: macos_tags: \"Invoices (red)\" Available colors are none , gray , green , purple , blue , yellow , red and orange . Source code in organize/actions/macos_tags.py 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 @dataclass ( config = ConfigDict ( coerce_numbers_to_str = True , extra = \"forbid\" )) class MacOSTags : \"\"\"Add macOS tags. Attributes: *tags (str): A list of tags or a single tag. The color can be specified in brackets after the tag name, for example: ```yaml macos_tags: \"Invoices (red)\" ``` Available colors are `none`, `gray`, `green`, `purple`, `blue`, `yellow`, `red` and `orange`. \"\"\" tags : FlatList [ str ] action_config : ClassVar [ ActionConfig ] = ActionConfig ( name = \"macos_tags\" , standalone = False , files = True , dirs = True , ) def __post_init__ ( self ): self . _tags = [ Template . from_string ( tag ) for tag in self . tags ] if sys . platform != \"darwin\" : raise EnvironmentError ( \"The macos_tags action is only available on macOS\" ) def pipeline ( self , res : Resource , output : Output , simulate : bool ): import macos_tags COLORS = [ c . name . lower () for c in macos_tags . Color ] for template in self . _tags : tag = render ( template , res . dict ()) name , color = self . _parse_tag ( tag ) if color not in COLORS : raise ValueError ( \"color %s is unknown. (Available: %s )\" % ( color , \" / \" . join ( COLORS )) ) output . msg ( res = res , sender = self , msg = f 'Adding tag: \" { name } \" (color: { color } )' , ) if not simulate : _tag = macos_tags . Tag ( name = name , color = macos_tags . Color [ color . upper ()], ) # type: ignore macos_tags . add ( _tag , file = str ( res . path )) def _parse_tag ( self , s ): \"\"\"parse a tag definition and return a tuple (name, color)\"\"\" result = sm . match ( \" {name} ( {color} )\" , s ) if not result : return s , \"none\" return result [ \"name\" ], result [ \"color\" ] . lower () Examples: rules: - name: \"add a single tag\" locations: \"~/Documents/Invoices\" filters: - name: startswith: \"Invoice\" - extension: pdf actions: - macos_tags: Invoice Adding multiple tags (\"Invoice\" and \"Important\") rules: - locations: \"~/Documents/Invoices\" filters: - name: startswith: \"Invoice\" - extension: pdf actions: - macos_tags: - Important - Invoice Specify tag colors rules: - locations: \"~/Documents/Invoices\" filters: - name: startswith: \"Invoice\" - extension: pdf actions: - macos_tags: - Important (green) - Invoice (purple) Add a templated tag with color rules: - locations: \"~/Documents/Invoices\" filters: - created actions: - macos_tags: - Year-{created.year} (red) move # Move a file to a new location. The file can also be renamed. If the specified path does not exist it will be created. If you only want to rename the file and keep the folder, it is easier to use the rename action. Attributes: dest ( str ) \u2013 The destination where the file / dir should be moved to. If dest ends with a slash, it is assumed to be a target directory and the file / dir will be moved into dest and keep its name. on_conflict ( str ) \u2013 What should happen in case dest already exists. One of skip , overwrite , trash , rename_new and rename_existing . Defaults to rename_new . rename_template ( str ) \u2013 A template for renaming the file / dir in case of a conflict. Defaults to {name} {counter}{extension} . autodetect_folder ( bool ) \u2013 In case you forget the ending slash \"/\" to indicate moving into a folder this settings will handle targets without a file extension as folders. If you really mean to move to a file without file extension, set this to false. Default: True The next action will work with the moved file / dir. Source code in organize/actions/move.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 @dataclass ( config = ConfigDict ( coerce_numbers_to_str = True , extra = \"forbid\" )) class Move : \"\"\"Move a file to a new location. The file can also be renamed. If the specified path does not exist it will be created. If you only want to rename the file and keep the folder, it is easier to use the `rename` action. Attributes: dest (str): The destination where the file / dir should be moved to. If `dest` ends with a slash, it is assumed to be a target directory and the file / dir will be moved into `dest` and keep its name. on_conflict (str): What should happen in case **dest** already exists. One of `skip`, `overwrite`, `trash`, `rename_new` and `rename_existing`. Defaults to `rename_new`. rename_template (str): A template for renaming the file / dir in case of a conflict. Defaults to `{name} {counter}{extension}`. autodetect_folder (bool): In case you forget the ending slash \"/\" to indicate moving into a folder this settings will handle targets without a file extension as folders. If you really mean to move to a file without file extension, set this to false. Default: True The next action will work with the moved file / dir. \"\"\" dest : str on_conflict : ConflictMode = \"rename_new\" rename_template : str = \" {name} {counter}{extension} \" autodetect_folder : bool = True action_config : ClassVar [ ActionConfig ] = ActionConfig ( name = \"move\" , standalone = False , files = True , dirs = True , ) def __post_init__ ( self ): self . _dest = Template . from_string ( self . dest ) self . _rename_template = Template . from_string ( self . rename_template ) def pipeline ( self , res : Resource , output : Output , simulate : bool ): assert res . path is not None , \"Does not support standalone mode\" rendered = render ( self . _dest , res . dict ()) # fully resolve the destination for folder targets and prepare the folder # structure dst = prepare_target_path ( src_name = res . path . name , dst = rendered , autodetect_folder = self . autodetect_folder , simulate = simulate , ) # Resolve conflicts before moving the file to the destination skip_action , dst = resolve_conflict ( dst = dst , res = res , conflict_mode = self . on_conflict , rename_template = self . _rename_template , simulate = simulate , output = output , ) if skip_action : return output . msg ( res = res , msg = f \"Move to { dst } \" , sender = self ) res . walker_skip_pathes . add ( dst ) if not simulate : shutil . move ( src = res . path , dst = dst ) # continue with the new path res . path = dst Examples: Move all pdfs and jpgs from the desktop into the folder \"~/Desktop/media/\". Filenames are not changed. rules: - locations: ~/Desktop filters: - extension: - pdf - jpg actions: - move: \"~/Desktop/media/\" Use a placeholder to move all .pdf files into a \"PDF\" folder and all .jpg files into a \"JPG\" folder. Existing files will be overwritten. rules: - locations: ~/Desktop filters: - extension: - pdf - jpg actions: - move: dest: \"~/Desktop/{extension.upper()}/\" on_conflict: \"overwrite\" Move pdfs into the folder Invoices . Keep the filename but do not overwrite existing files. To prevent overwriting files, an index is added to the filename, so somefile.jpg becomes somefile 2.jpg . rules: - locations: ~/Desktop/Invoices filters: - extension: - pdf actions: - move: dest: \"~/Documents/Invoices/\" on_conflict: \"rename_new\" rename_template: \"{name} {counter}{extension}\" python # Execute python code. Attributes: code ( str ) \u2013 The python code to execute. run_in_simulation ( bool ) \u2013 Whether to execute this code in simulation mode (Default false). Variables of previous filters are available, but you have to use the normal python dictionary syntax x = regex[\"my_group\"] . Source code in organize/actions/python.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 @dataclass ( config = ConfigDict ( coerce_numbers_to_str = True , extra = \"forbid\" )) class Python : \"\"\"Execute python code. Attributes: code (str): The python code to execute. run_in_simulation (bool): Whether to execute this code in simulation mode (Default false). Variables of previous filters are available, but you have to use the normal python dictionary syntax `x = regex[\"my_group\"]`. \"\"\" code : str run_in_simulation : bool = False action_config : ClassVar [ ActionConfig ] = ActionConfig ( name = \"python\" , standalone = True , files = True , dirs = True , ) def __post_init__ ( self ): self . code = textwrap . dedent ( self . code ) def __usercode__ ( self , print , ** kwargs ) -> Optional [ Dict ]: raise NotImplementedError () def pipeline ( self , res : Resource , output : Output , simulate : bool ): if simulate and not self . run_in_simulation : output . msg ( res = res , msg = \"** Code not run in simulation. **\" , level = \"warn\" , sender = self , ) return def _output_msg ( * values , sep : str = \" \" , end : str = \"\" ): \"\"\" the print function for the use code needs to print via the current output \"\"\" msg = f \" { sep . join ( str ( x ) for x in values ) }{ end } \" output . msg ( res = res , msg = msg , sender = self ) # codegen the user function with arguments as available in the resource kwargs = \", \" . join ( res . dict () . keys ()) func = f \"def __userfunc(print, { kwargs } ): \\n \" func += textwrap . indent ( self . code , \" \" ) func += \" \\n\\n self.__usercode__ = __userfunc\" exec ( func , globals () . copy (), locals () . copy ()) result = self . __usercode__ ( print = _output_msg , ** res . dict ()) # deep merge the resulting dict if not ( result is None or isinstance ( result , dict )): raise ValueError ( \"The python code must return None or a dict\" ) if isinstance ( result , dict ): res . deep_merge ( key = self . action_config . name , data = result ) Examples: A basic example that shows how to get the current file path and do some printing in a for loop. The | is yaml syntax for defining a string literal spanning multiple lines. rules: - locations: \"~/Desktop\" actions: - python: | print('The path of the current file is %s' % path) for _ in range(5): print('Heyho, its me from the loop') rules: - name: \"You can access filter data\" locations: ~/Desktop filters: - regex: '^(?P<name>.*)\\.(?P<extension>.*)$' actions: - python: | print('Name: %s' % regex[\"name\"]) print('Extension: %s' % regex[\"extension\"]) Running in simulation and yaml aliases : my_python_script: &script | print(\"Hello World!\") print(path) rules: - name: \"Run in simulation and yaml alias\" locations: - ~/Desktop/ actions: - python: code: *script run_in_simulation: yes You have access to all the python magic -- do a google search for each filename starting with an underscore: rules: - locations: ~/Desktop filters: - name: startswith: \"_\" actions: - python: | import webbrowser webbrowser.open('https://www.google.com/search?q=%s' % name) rename # Renames a file. Attributes: new_name ( str ) \u2013 The new name for the file / dir. on_conflict ( str ) \u2013 What should happen in case dest already exists. One of skip , overwrite , trash , rename_new and rename_existing . Defaults to rename_new . rename_template ( str ) \u2013 A template for renaming the file / dir in case of a conflict. Defaults to {name} {counter}{extension} . The next action will work with the renamed file / dir. Source code in organize/actions/rename.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 @dataclass ( config = ConfigDict ( coerce_numbers_to_str = True , extra = \"forbid\" )) class Rename : \"\"\"Renames a file. Attributes: new_name (str): The new name for the file / dir. on_conflict (str): What should happen in case **dest** already exists. One of `skip`, `overwrite`, `trash`, `rename_new` and `rename_existing`. Defaults to `rename_new`. rename_template (str): A template for renaming the file / dir in case of a conflict. Defaults to `{name} {counter}{extension}`. The next action will work with the renamed file / dir. \"\"\" new_name : str on_conflict : ConflictMode = \"rename_new\" rename_template : str = \" {name} {counter}{extension} \" # TODO: keep_extension? action_config : ClassVar [ ActionConfig ] = ActionConfig ( name = \"rename\" , standalone = False , files = True , dirs = True , ) def __post_init__ ( self ): self . _new_name = Template . from_string ( self . new_name ) self . _rename_template = Template . from_string ( self . rename_template ) def pipeline ( self , res : Resource , output : Output , simulate : bool ): assert res . path is not None , \"Does not support standalone mode\" new_name = render ( self . _new_name , res . dict ()) if \"/\" in new_name : raise ValueError ( \"The new name cannot contain slashes. \" \"To move files or folders use `move`.\" ) dst = res . path . with_name ( new_name ) skip_action , dst = resolve_conflict ( dst = dst , res = res , conflict_mode = self . on_conflict , rename_template = self . _rename_template , simulate = simulate , output = output , ) if skip_action : return output . msg ( res = res , msg = f \"Renaming to { new_name } \" , sender = self ) if not simulate : res . path . rename ( dst ) res . path = dst res . walker_skip_pathes . add ( dst ) Examples: rules: - name: \"Convert all .PDF file extensions to lowercase (.pdf)\" locations: \"~/Desktop\" filters: - name - extension: PDF actions: - rename: \"{name}.pdf\" rules: - name: \"Convert **all** file extensions to lowercase\" locations: \"~/Desktop\" filters: - name - extension actions: - rename: \"{name}.{extension.lower()}\" shell # Executes a shell command Attributes: cmd ( str ) \u2013 The command to execute. run_in_simulation ( bool ) \u2013 Whether to execute in simulation mode (default = false) ignore_errors ( bool ) \u2013 Whether to continue on returncodes != 0. simulation_output ( str ) \u2013 The value of {shell.output} if run in simulation simulation_returncode ( int ) \u2013 The value of {shell.returncode} if run in simulation Returns {shell.output} ( str ): The stdout of the executed process. {shell.returncode} ( int ): The returncode of the executed process. Source code in organize/actions/shell.py 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 @dataclass ( config = ConfigDict ( coerce_numbers_to_str = True , extra = \"forbid\" )) class Shell : \"\"\" Executes a shell command Attributes: cmd (str): The command to execute. run_in_simulation (bool): Whether to execute in simulation mode (default = false) ignore_errors (bool): Whether to continue on returncodes != 0. simulation_output (str): The value of `{shell.output}` if run in simulation simulation_returncode (int): The value of `{shell.returncode}` if run in simulation Returns - `{shell.output}` (`str`): The stdout of the executed process. - `{shell.returncode}` (`int`): The returncode of the executed process. \"\"\" cmd : str run_in_simulation : bool = False ignore_errors : bool = False simulation_output : str = \"** simulation **\" simulation_returncode : int = 0 action_config : ClassVar [ ActionConfig ] = ActionConfig ( name = \"shell\" , standalone = True , files = True , dirs = True , ) def __post_init__ ( self ): self . _cmd = Template . from_string ( self . cmd ) self . _simulation_output = Template . from_string ( self . simulation_output ) def pipeline ( self , res : Resource , output : Output , simulate : bool ): full_cmd = render ( self . _cmd , res . dict ()) if not simulate or self . run_in_simulation : output . msg ( res = res , msg = f \"$ { full_cmd } \" , sender = self ) try : call = subprocess . run ( full_cmd , check = True , stdout = subprocess . PIPE , stderr = subprocess . STDOUT , shell = True , ) except subprocess . CalledProcessError as e : if not self . ignore_errors : raise e res . vars [ self . action_config . name ] = { \"output\" : call . stdout . decode ( \"utf-8\" ), \"returncode\" : call . returncode , } else : output . msg ( res = res , msg = f \"** not run in simulation ** $ { full_cmd } \" , sender = self , ) res . vars [ self . action_config . name ] = { \"output\" : render ( self . _simulation_output , res . dict ()), \"returncode\" : self . simulation_returncode , } Examples: rules: - name: \"On macOS: Open all pdfs on your desktop\" locations: \"~/Desktop\" filters: - extension: pdf actions: - shell: 'open \"{path}\"' symlink # Create a symbolic link. Attributes: dest ( str ) \u2013 The symlink destination. If dest ends with a slash `/``, create the symlink in the given directory. Can contain placeholders. on_conflict ( str ) \u2013 What should happen in case dest already exists. One of skip , overwrite , trash , rename_new and rename_existing . Defaults to rename_new . rename_template ( str ) \u2013 A template for renaming the file / dir in case of a conflict. Defaults to {name} {counter}{extension} . autodetect_folder ( bool ) \u2013 In case you forget the ending slash \"/\" to indicate creating the link inside the destination folder this settings will handle targets without a file extension as folders. If you really mean to copy to a file without file extension, set this to false. Default: true Source code in organize/actions/symlink.py 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 @dataclass ( config = ConfigDict ( coerce_numbers_to_str = True , extra = \"forbid\" )) class Symlink : \"\"\"Create a symbolic link. Attributes: dest (str): The symlink destination. If **dest** ends with a slash `/``, create the symlink in the given directory. Can contain placeholders. on_conflict (str): What should happen in case **dest** already exists. One of `skip`, `overwrite`, `trash`, `rename_new` and `rename_existing`. Defaults to `rename_new`. rename_template (str): A template for renaming the file / dir in case of a conflict. Defaults to `{name} {counter}{extension}`. autodetect_folder (bool): In case you forget the ending slash \"/\" to indicate creating the link inside the destination folder this settings will handle targets without a file extension as folders. If you really mean to copy to a file without file extension, set this to false. Default: true \"\"\" dest : str on_conflict : ConflictMode = \"rename_new\" rename_template : str = \" {name} {counter}{extension} \" autodetect_folder : bool = True action_config : ClassVar [ ActionConfig ] = ActionConfig ( name = \"symlink\" , standalone = False , files = True , dirs = True , ) def __post_init__ ( self ): self . _dest = Template . from_string ( self . dest ) self . _rename_template = Template . from_string ( self . rename_template ) def pipeline ( self , res : Resource , output : Output , simulate : bool ): assert res . path is not None , \"Does not support standalone mode\" rendered = render ( self . _dest , res . dict ()) dst = prepare_target_path ( src_name = res . path . name , dst = rendered , autodetect_folder = self . autodetect_folder , simulate = simulate , ) skip_action , dst = resolve_conflict ( dst = dst , res = res , conflict_mode = self . on_conflict , rename_template = self . _rename_template , simulate = simulate , output = output , ) if skip_action : return output . msg ( res = res , msg = f \"Creating symlink at { dst } \" , sender = self ) res . walker_skip_pathes . add ( dst ) if not simulate : dst . symlink_to ( target = res . path , target_is_directory = res . is_dir ()) trash # Move a file or dir into the trash. Source code in organize/actions/trash.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 @dataclass ( config = ConfigDict ( coerce_numbers_to_str = True , extra = \"forbid\" )) class Trash : \"\"\"Move a file or dir into the trash.\"\"\" action_config : ClassVar [ ActionConfig ] = ActionConfig ( name = \"trash\" , standalone = False , files = True , dirs = True , ) def pipeline ( self , res : Resource , output : Output , simulate : bool ): assert res . path is not None , \"Does not support standalone mode\" output . msg ( res = res , msg = f 'Trash \" { res . path } \"' , sender = self ) if not simulate : trash ( res . path ) Examples: rules: - name: Move all JPGs and PNGs on the desktop which are older than one year into the trash locations: \"~/Desktop\" filters: - lastmodified: years: 1 mode: older - extension: - png - jpg actions: - trash write # Write text to a file. If the specified path does not exist it will be created. Attributes: text ( str ) \u2013 The text that should be written. Supports templates. outfile ( str ) \u2013 The file text should be written into. Supports templates. mode ( str ) \u2013 Can be either append (append text to the file), prepend (insert text as first line) or overwrite (overwrite content with text). Defaults to append . encoding ( str ) \u2013 The text encoding to use. Default: \"utf-8\". newline ( str ) \u2013 (Optional) Whether to append a newline to the given text . Defaults to true . clear_before_first_write ( bool ) \u2013 (Optional) Clears the file before first appending / prepending text to it. This happens only the first time the file is written to. If the rule filters don't match anything the file is left as it is. Defaults to false . Source code in organize/actions/write.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 @dataclass ( config = ConfigDict ( coerce_numbers_to_str = True , extra = \"forbid\" )) class Write : \"\"\" Write text to a file. If the specified path does not exist it will be created. Attributes: text (str): The text that should be written. Supports templates. outfile (str): The file `text` should be written into. Supports templates. mode (str): Can be either `append` (append text to the file), `prepend` (insert text as first line) or `overwrite` (overwrite content with text). Defaults to `append`. encoding (str): The text encoding to use. Default: \"utf-8\". newline (str): (Optional) Whether to append a newline to the given `text`. Defaults to `true`. clear_before_first_write (bool): (Optional) Clears the file before first appending / prepending text to it. This happens only the first time the file is written to. If the rule filters don't match anything the file is left as it is. Defaults to `false`. \"\"\" text : str outfile : str mode : Literal [ \"append\" , \"prepend\" , \"overwrite\" ] = \"append\" encoding : str = \"utf-8\" newline : bool = True clear_before_first_write : bool = False action_config : ClassVar [ ActionConfig ] = ActionConfig ( name = \"write\" , standalone = True , files = True , dirs = True , ) def __post_init__ ( self ): self . _text = Template . from_string ( self . text ) self . _path = Template . from_string ( self . outfile ) self . _known_files = set () def pipeline ( self , res : Resource , output : Output , simulate : bool ): text = render ( self . _text , res . dict ()) path = Path ( render ( self . _path , res . dict ())) resolved = path . resolve () if resolved not in self . _known_files : self . _known_files . add ( resolved ) if not simulate : resolved . parent . mkdir ( parents = True , exist_ok = True ) # clear on first write if resolved . exists () and self . clear_before_first_write : output . msg ( res = res , msg = f \"Clearing file { path } \" , sender = self ) if not simulate : resolved . open ( \"w\" ) # clear the file output . msg ( res = res , msg = f ' { path } : { self . mode } \" { text } \"' , sender = self ) if self . newline : text += \" \\n \" if not simulate : if self . mode == \"append\" : with open ( path , \"a\" , encoding = self . encoding ) as f : f . write ( text ) elif self . mode == \"prepend\" : content = \"\" if path . exists (): content = path . read_text ( encoding = self . encoding ) path . write_text ( text + content , encoding = self . encoding ) elif self . mode == \"overwrite\" : path . write_text ( text , encoding = self . encoding ) Examples rules: - name: \"Record file sizes\" locations: ~/Downloads filters: - size actions: - write: outfile: \"./sizes.txt\" text: \"{size.traditional} -- {relative_path}\" mode: \"append\" clear_before_first_write: true This will create a file sizes.txt in the current working folder which contains the filesizes of everything in the ~/Downloads folder: 2.9 MB -- SIM7600.pdf 1.0 MB -- Bildschirmfoto 2022-07-05 um 10.43.16.png 5.9 MB -- Albumcover.png 51.2 KB -- Urlaubsantrag 2022-04-19.pdf 1.8 MB -- ETH_USB_HUB_HAT.pdf 2.1 MB -- ArduinoDUE_V02g_sch.pdf ... You can use templates both in the text as well as in the textfile parameter: rules: - name: \"File sizes by extension\" locations: ~/Downloads filters: - size - extension actions: - write: outfile: \"./sizes.{extension}.txt\" text: \"{size.traditional} -- {relative_path}\" mode: \"prepend\" clear_before_first_write: true This will separate the filesizes by extension.","title":"Actions"},{"location":"actions/#actions","text":"This page shows the specifics of each action. For basic action usage and options have a look at the Rules section.","title":"Actions"},{"location":"actions/#confirm","text":"Ask for confirmation before continuing. Source code in organize/actions/confirm.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 @dataclass ( config = ConfigDict ( coerce_numbers_to_str = True , extra = \"forbid\" )) class Confirm : \"\"\"Ask for confirmation before continuing.\"\"\" msg : str = \"Continue?\" default : bool = True action_config : ClassVar [ ActionConfig ] = ActionConfig ( name = \"confirm\" , standalone = True , files = True , dirs = True , ) def __post_init__ ( self ): self . _msg = Template . from_string ( self . msg ) def pipeline ( self , res : Resource , output : Output , simulate : bool ): msg = render ( self . _msg , res . dict ()) result = output . confirm ( res = res , msg = msg , sender = self , default = self . default ) if not result : raise StopIteration ( \"Aborted\" ) Examples Confirm before deleting a duplicate rules: - name: \"Delete duplicates with confirmation\" locations: - ~/Downloads - ~/Documents filters: - not empty - duplicate - name actions: - confirm: \"Delete {name}?\" - trash","title":"confirm"},{"location":"actions/#copy","text":"Copy a file or dir to a new location. If the specified path does not exist it will be created. Attributes: dest ( str ) \u2013 The destination where the file / dir should be copied to. If dest ends with a slash, it is assumed to be a target directory and the file / dir will be copied into dest and keep its name. on_conflict ( str ) \u2013 What should happen in case dest already exists. One of skip , overwrite , trash , rename_new and rename_existing . Defaults to rename_new . rename_template ( str ) \u2013 A template for renaming the file / dir in case of a conflict. Defaults to {name} {counter}{extension} . autodetect_folder ( bool ) \u2013 In case you forget the ending slash \"/\" to indicate copying into a folder this settings will handle targets without a file extension as folders. If you really mean to copy to a file without file extension, set this to false. Defaults to True. continue_with ( str) = \"copy\" | \"original\" ) \u2013 Continue the next action either with the path to the copy or the path the original. Defaults to \"copy\". The next action will work with the created copy. Source code in organize/actions/copy.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 @dataclass ( config = ConfigDict ( coerce_numbers_to_str = True , extra = \"forbid\" )) class Copy : \"\"\"Copy a file or dir to a new location. If the specified path does not exist it will be created. Attributes: dest (str): The destination where the file / dir should be copied to. If `dest` ends with a slash, it is assumed to be a target directory and the file / dir will be copied into `dest` and keep its name. on_conflict (str): What should happen in case **dest** already exists. One of `skip`, `overwrite`, `trash`, `rename_new` and `rename_existing`. Defaults to `rename_new`. rename_template (str): A template for renaming the file / dir in case of a conflict. Defaults to `{name} {counter}{extension}`. autodetect_folder (bool): In case you forget the ending slash \"/\" to indicate copying into a folder this settings will handle targets without a file extension as folders. If you really mean to copy to a file without file extension, set this to false. Defaults to True. continue_with (str) = \"copy\" | \"original\": Continue the next action either with the path to the copy or the path the original. Defaults to \"copy\". The next action will work with the created copy. \"\"\" dest : str on_conflict : ConflictMode = \"rename_new\" rename_template : str = \" {name} {counter}{extension} \" autodetect_folder : bool = True continue_with : Literal [ \"copy\" , \"original\" ] = \"copy\" action_config : ClassVar [ ActionConfig ] = ActionConfig ( name = \"copy\" , standalone = False , files = True , dirs = True , ) def __post_init__ ( self ): self . _dest = Template . from_string ( self . dest ) self . _rename_template = Template . from_string ( self . rename_template ) def pipeline ( self , res : Resource , output : Output , simulate : bool ): assert res . path is not None , \"Does not support standalone mode\" rendered = render ( self . _dest , res . dict ()) # fully resolve the destination for folder targets and prepare the folder # structure dst = prepare_target_path ( src_name = res . path . name , dst = rendered , autodetect_folder = self . autodetect_folder , simulate = simulate , ) # Resolve conflicts before copying the file to the destination skip_action , dst = resolve_conflict ( dst = dst , res = res , conflict_mode = self . on_conflict , rename_template = self . _rename_template , simulate = simulate , output = output , ) if skip_action : return output . msg ( res = res , msg = f \"Copy to { dst } \" , sender = self ) res . walker_skip_pathes . add ( dst ) if not simulate : if res . is_dir (): shutil . copytree ( src = res . path , dst = dst ) else : shutil . copy2 ( src = res . path , dst = dst ) # continue with either the original path or the path to the copy if self . continue_with == \"copy\" : res . path = dst Examples: Copy all pdfs into ~/Desktop/somefolder/ and keep filenames rules: - locations: ~/Desktop filters: - extension: pdf actions: - copy: \"~/Desktop/somefolder/\" Use a placeholder to copy all .pdf files into a \"PDF\" folder and all .jpg files into a \"JPG\" folder. Existing files will be overwritten. rules: - locations: ~/Desktop filters: - extension: - pdf - jpg actions: - copy: dest: \"~/Desktop/{extension.upper()}/\" on_conflict: overwrite Copy into the folder Invoices . Keep the filename but do not overwrite existing files. To prevent overwriting files, an index is added to the filename, so somefile.jpg becomes somefile 2.jpg . The counter separator is ' ' by default, but can be changed using the counter_separator property. rules: - locations: ~/Desktop/Invoices filters: - extension: - pdf actions: - copy: dest: \"~/Documents/Invoices/\" on_conflict: \"rename_new\" rename_template: \"{name} {counter}{extension}\"","title":"copy"},{"location":"actions/#delete","text":"Delete a file from disk. Deleted files have no recovery option! Using the Trash action is strongly advised for most use-cases! Source code in organize/actions/delete.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 @dataclass ( config = ConfigDict ( extra = \"forbid\" )) class Delete : \"\"\" Delete a file from disk. Deleted files have no recovery option! Using the `Trash` action is strongly advised for most use-cases! \"\"\" action_config : ClassVar [ ActionConfig ] = ActionConfig ( name = \"delete\" , standalone = False , files = True , dirs = True , ) def pipeline ( self , res : Resource , output : Output , simulate : bool ): assert res . path is not None , \"Does not support standalone mode\" output . msg ( res = res , msg = f \"Deleting { res . path } \" , sender = self ) if not simulate : delete ( res . path ) res . path = None Examples: Delete old downloads. rules: - locations: \"~/Downloads\" filters: - lastmodified: days: 365 - extension: - png - jpg actions: - delete Delete all empty subfolders rules: - name: Delete all empty subfolders locations: - path: \"~/Downloads\" max_depth: null targets: dirs filters: - empty actions: - delete","title":"delete"},{"location":"actions/#echo","text":"Prints the given message. This can be useful to test your rules, especially in combination with placeholder variables. Attributes: msg ( str ) \u2013 The message to print. Accepts placeholder variables. Source code in organize/actions/echo.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 @dataclass ( config = ConfigDict ( extra = \"forbid\" )) class Echo : \"\"\"Prints the given message. This can be useful to test your rules, especially in combination with placeholder variables. Attributes: msg (str): The message to print. Accepts placeholder variables. \"\"\" msg : str = \"\" action_config : ClassVar [ ActionConfig ] = ActionConfig ( name = \"echo\" , standalone = True , files = True , dirs = True , ) def __post_init__ ( self ): self . _msg_templ = Template . from_string ( self . msg ) def pipeline ( self , res : Resource , output : Output , simulate : bool ): full_msg = render ( self . _msg_templ , res . dict ()) output . msg ( res , full_msg , sender = self ) Examples: rules: - name: \"Find files older than a year\" locations: ~/Desktop filters: - lastmodified: days: 365 actions: - echo: \"Found old file\" Prints \"Hello World!\" and filepath for each file on the desktop: rules: - locations: - ~/Desktop actions: - echo: \"Hello World! {path}\" This will print something like Found a ZIP: \"backup\" for each file on your desktop rules: - locations: - ~/Desktop filters: - extension - name actions: - echo: 'Found a {extension.upper()}: \"{name}\"' Show the {relative_path} and {path} of all files in '~/Downloads', '~/Desktop' and their subfolders: rules: - locations: - path: ~/Desktop max_depth: null - path: ~/Downloads max_depth: null actions: - echo: \"Path: {path}\" - echo: \"Relative: {relative_path}\"","title":"echo"},{"location":"actions/#hardlink","text":"Create a hardlink. Attributes: dest ( str ) \u2013 The hardlink destination. If dest ends with a slash `/``, create the hardlink in the given directory. Can contain placeholders. on_conflict ( str ) \u2013 What should happen in case dest already exists. One of skip , overwrite , trash , rename_new and rename_existing . Defaults to rename_new . rename_template ( str ) \u2013 A template for renaming the file / dir in case of a conflict. Defaults to {name} {counter}{extension} . autodetect_folder ( bool ) \u2013 In case you forget the ending slash \"/\" to indicate copying into a folder this settings will handle targets without a file extension as folders. If you really mean to copy to a file without file extension, set this to false. Default: true Source code in organize/actions/hardlink.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 @dataclass ( config = ConfigDict ( coerce_numbers_to_str = True , extra = \"forbid\" )) class Hardlink : \"\"\"Create a hardlink. Attributes: dest (str): The hardlink destination. If **dest** ends with a slash `/``, create the hardlink in the given directory. Can contain placeholders. on_conflict (str): What should happen in case **dest** already exists. One of `skip`, `overwrite`, `trash`, `rename_new` and `rename_existing`. Defaults to `rename_new`. rename_template (str): A template for renaming the file / dir in case of a conflict. Defaults to `{name} {counter}{extension}`. autodetect_folder (bool): In case you forget the ending slash \"/\" to indicate copying into a folder this settings will handle targets without a file extension as folders. If you really mean to copy to a file without file extension, set this to false. Default: true \"\"\" dest : str on_conflict : ConflictMode = \"rename_new\" rename_template : str = \" {name} {counter}{extension} \" autodetect_folder : bool = True action_config : ClassVar [ ActionConfig ] = ActionConfig ( name = \"hardlink\" , standalone = False , files = True , dirs = True , ) def __post_init__ ( self ): self . _dest = Template . from_string ( self . dest ) self . _rename_template = Template . from_string ( self . rename_template ) def pipeline ( self , res : Resource , output : Output , simulate : bool ): assert res . path is not None , \"Does not support standalone mode\" rendered = render ( self . _dest , res . dict ()) dst = prepare_target_path ( src_name = res . path . name , dst = rendered , autodetect_folder = self . autodetect_folder , simulate = simulate , ) skip_action , dst = resolve_conflict ( dst = dst , res = res , conflict_mode = self . on_conflict , rename_template = self . _rename_template , simulate = simulate , output = output , ) if skip_action : return output . msg ( res = res , msg = f \"Creating hardlink at { dst } \" , sender = self ) if not simulate : create_hardlink ( target = res . path , link = dst ) res . walker_skip_pathes . add ( dst )","title":"hardlink"},{"location":"actions/#macos_tags","text":"Add macOS tags. Attributes: *tags ( str ) \u2013 A list of tags or a single tag. The color can be specified in brackets after the tag name, for example: macos_tags: \"Invoices (red)\" Available colors are none , gray , green , purple , blue , yellow , red and orange . Source code in organize/actions/macos_tags.py 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 @dataclass ( config = ConfigDict ( coerce_numbers_to_str = True , extra = \"forbid\" )) class MacOSTags : \"\"\"Add macOS tags. Attributes: *tags (str): A list of tags or a single tag. The color can be specified in brackets after the tag name, for example: ```yaml macos_tags: \"Invoices (red)\" ``` Available colors are `none`, `gray`, `green`, `purple`, `blue`, `yellow`, `red` and `orange`. \"\"\" tags : FlatList [ str ] action_config : ClassVar [ ActionConfig ] = ActionConfig ( name = \"macos_tags\" , standalone = False , files = True , dirs = True , ) def __post_init__ ( self ): self . _tags = [ Template . from_string ( tag ) for tag in self . tags ] if sys . platform != \"darwin\" : raise EnvironmentError ( \"The macos_tags action is only available on macOS\" ) def pipeline ( self , res : Resource , output : Output , simulate : bool ): import macos_tags COLORS = [ c . name . lower () for c in macos_tags . Color ] for template in self . _tags : tag = render ( template , res . dict ()) name , color = self . _parse_tag ( tag ) if color not in COLORS : raise ValueError ( \"color %s is unknown. (Available: %s )\" % ( color , \" / \" . join ( COLORS )) ) output . msg ( res = res , sender = self , msg = f 'Adding tag: \" { name } \" (color: { color } )' , ) if not simulate : _tag = macos_tags . Tag ( name = name , color = macos_tags . Color [ color . upper ()], ) # type: ignore macos_tags . add ( _tag , file = str ( res . path )) def _parse_tag ( self , s ): \"\"\"parse a tag definition and return a tuple (name, color)\"\"\" result = sm . match ( \" {name} ( {color} )\" , s ) if not result : return s , \"none\" return result [ \"name\" ], result [ \"color\" ] . lower () Examples: rules: - name: \"add a single tag\" locations: \"~/Documents/Invoices\" filters: - name: startswith: \"Invoice\" - extension: pdf actions: - macos_tags: Invoice Adding multiple tags (\"Invoice\" and \"Important\") rules: - locations: \"~/Documents/Invoices\" filters: - name: startswith: \"Invoice\" - extension: pdf actions: - macos_tags: - Important - Invoice Specify tag colors rules: - locations: \"~/Documents/Invoices\" filters: - name: startswith: \"Invoice\" - extension: pdf actions: - macos_tags: - Important (green) - Invoice (purple) Add a templated tag with color rules: - locations: \"~/Documents/Invoices\" filters: - created actions: - macos_tags: - Year-{created.year} (red)","title":"macos_tags"},{"location":"actions/#move","text":"Move a file to a new location. The file can also be renamed. If the specified path does not exist it will be created. If you only want to rename the file and keep the folder, it is easier to use the rename action. Attributes: dest ( str ) \u2013 The destination where the file / dir should be moved to. If dest ends with a slash, it is assumed to be a target directory and the file / dir will be moved into dest and keep its name. on_conflict ( str ) \u2013 What should happen in case dest already exists. One of skip , overwrite , trash , rename_new and rename_existing . Defaults to rename_new . rename_template ( str ) \u2013 A template for renaming the file / dir in case of a conflict. Defaults to {name} {counter}{extension} . autodetect_folder ( bool ) \u2013 In case you forget the ending slash \"/\" to indicate moving into a folder this settings will handle targets without a file extension as folders. If you really mean to move to a file without file extension, set this to false. Default: True The next action will work with the moved file / dir. Source code in organize/actions/move.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 @dataclass ( config = ConfigDict ( coerce_numbers_to_str = True , extra = \"forbid\" )) class Move : \"\"\"Move a file to a new location. The file can also be renamed. If the specified path does not exist it will be created. If you only want to rename the file and keep the folder, it is easier to use the `rename` action. Attributes: dest (str): The destination where the file / dir should be moved to. If `dest` ends with a slash, it is assumed to be a target directory and the file / dir will be moved into `dest` and keep its name. on_conflict (str): What should happen in case **dest** already exists. One of `skip`, `overwrite`, `trash`, `rename_new` and `rename_existing`. Defaults to `rename_new`. rename_template (str): A template for renaming the file / dir in case of a conflict. Defaults to `{name} {counter}{extension}`. autodetect_folder (bool): In case you forget the ending slash \"/\" to indicate moving into a folder this settings will handle targets without a file extension as folders. If you really mean to move to a file without file extension, set this to false. Default: True The next action will work with the moved file / dir. \"\"\" dest : str on_conflict : ConflictMode = \"rename_new\" rename_template : str = \" {name} {counter}{extension} \" autodetect_folder : bool = True action_config : ClassVar [ ActionConfig ] = ActionConfig ( name = \"move\" , standalone = False , files = True , dirs = True , ) def __post_init__ ( self ): self . _dest = Template . from_string ( self . dest ) self . _rename_template = Template . from_string ( self . rename_template ) def pipeline ( self , res : Resource , output : Output , simulate : bool ): assert res . path is not None , \"Does not support standalone mode\" rendered = render ( self . _dest , res . dict ()) # fully resolve the destination for folder targets and prepare the folder # structure dst = prepare_target_path ( src_name = res . path . name , dst = rendered , autodetect_folder = self . autodetect_folder , simulate = simulate , ) # Resolve conflicts before moving the file to the destination skip_action , dst = resolve_conflict ( dst = dst , res = res , conflict_mode = self . on_conflict , rename_template = self . _rename_template , simulate = simulate , output = output , ) if skip_action : return output . msg ( res = res , msg = f \"Move to { dst } \" , sender = self ) res . walker_skip_pathes . add ( dst ) if not simulate : shutil . move ( src = res . path , dst = dst ) # continue with the new path res . path = dst Examples: Move all pdfs and jpgs from the desktop into the folder \"~/Desktop/media/\". Filenames are not changed. rules: - locations: ~/Desktop filters: - extension: - pdf - jpg actions: - move: \"~/Desktop/media/\" Use a placeholder to move all .pdf files into a \"PDF\" folder and all .jpg files into a \"JPG\" folder. Existing files will be overwritten. rules: - locations: ~/Desktop filters: - extension: - pdf - jpg actions: - move: dest: \"~/Desktop/{extension.upper()}/\" on_conflict: \"overwrite\" Move pdfs into the folder Invoices . Keep the filename but do not overwrite existing files. To prevent overwriting files, an index is added to the filename, so somefile.jpg becomes somefile 2.jpg . rules: - locations: ~/Desktop/Invoices filters: - extension: - pdf actions: - move: dest: \"~/Documents/Invoices/\" on_conflict: \"rename_new\" rename_template: \"{name} {counter}{extension}\"","title":"move"},{"location":"actions/#python","text":"Execute python code. Attributes: code ( str ) \u2013 The python code to execute. run_in_simulation ( bool ) \u2013 Whether to execute this code in simulation mode (Default false). Variables of previous filters are available, but you have to use the normal python dictionary syntax x = regex[\"my_group\"] . Source code in organize/actions/python.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 @dataclass ( config = ConfigDict ( coerce_numbers_to_str = True , extra = \"forbid\" )) class Python : \"\"\"Execute python code. Attributes: code (str): The python code to execute. run_in_simulation (bool): Whether to execute this code in simulation mode (Default false). Variables of previous filters are available, but you have to use the normal python dictionary syntax `x = regex[\"my_group\"]`. \"\"\" code : str run_in_simulation : bool = False action_config : ClassVar [ ActionConfig ] = ActionConfig ( name = \"python\" , standalone = True , files = True , dirs = True , ) def __post_init__ ( self ): self . code = textwrap . dedent ( self . code ) def __usercode__ ( self , print , ** kwargs ) -> Optional [ Dict ]: raise NotImplementedError () def pipeline ( self , res : Resource , output : Output , simulate : bool ): if simulate and not self . run_in_simulation : output . msg ( res = res , msg = \"** Code not run in simulation. **\" , level = \"warn\" , sender = self , ) return def _output_msg ( * values , sep : str = \" \" , end : str = \"\" ): \"\"\" the print function for the use code needs to print via the current output \"\"\" msg = f \" { sep . join ( str ( x ) for x in values ) }{ end } \" output . msg ( res = res , msg = msg , sender = self ) # codegen the user function with arguments as available in the resource kwargs = \", \" . join ( res . dict () . keys ()) func = f \"def __userfunc(print, { kwargs } ): \\n \" func += textwrap . indent ( self . code , \" \" ) func += \" \\n\\n self.__usercode__ = __userfunc\" exec ( func , globals () . copy (), locals () . copy ()) result = self . __usercode__ ( print = _output_msg , ** res . dict ()) # deep merge the resulting dict if not ( result is None or isinstance ( result , dict )): raise ValueError ( \"The python code must return None or a dict\" ) if isinstance ( result , dict ): res . deep_merge ( key = self . action_config . name , data = result ) Examples: A basic example that shows how to get the current file path and do some printing in a for loop. The | is yaml syntax for defining a string literal spanning multiple lines. rules: - locations: \"~/Desktop\" actions: - python: | print('The path of the current file is %s' % path) for _ in range(5): print('Heyho, its me from the loop') rules: - name: \"You can access filter data\" locations: ~/Desktop filters: - regex: '^(?P<name>.*)\\.(?P<extension>.*)$' actions: - python: | print('Name: %s' % regex[\"name\"]) print('Extension: %s' % regex[\"extension\"]) Running in simulation and yaml aliases : my_python_script: &script | print(\"Hello World!\") print(path) rules: - name: \"Run in simulation and yaml alias\" locations: - ~/Desktop/ actions: - python: code: *script run_in_simulation: yes You have access to all the python magic -- do a google search for each filename starting with an underscore: rules: - locations: ~/Desktop filters: - name: startswith: \"_\" actions: - python: | import webbrowser webbrowser.open('https://www.google.com/search?q=%s' % name)","title":"python"},{"location":"actions/#rename","text":"Renames a file. Attributes: new_name ( str ) \u2013 The new name for the file / dir. on_conflict ( str ) \u2013 What should happen in case dest already exists. One of skip , overwrite , trash , rename_new and rename_existing . Defaults to rename_new . rename_template ( str ) \u2013 A template for renaming the file / dir in case of a conflict. Defaults to {name} {counter}{extension} . The next action will work with the renamed file / dir. Source code in organize/actions/rename.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 @dataclass ( config = ConfigDict ( coerce_numbers_to_str = True , extra = \"forbid\" )) class Rename : \"\"\"Renames a file. Attributes: new_name (str): The new name for the file / dir. on_conflict (str): What should happen in case **dest** already exists. One of `skip`, `overwrite`, `trash`, `rename_new` and `rename_existing`. Defaults to `rename_new`. rename_template (str): A template for renaming the file / dir in case of a conflict. Defaults to `{name} {counter}{extension}`. The next action will work with the renamed file / dir. \"\"\" new_name : str on_conflict : ConflictMode = \"rename_new\" rename_template : str = \" {name} {counter}{extension} \" # TODO: keep_extension? action_config : ClassVar [ ActionConfig ] = ActionConfig ( name = \"rename\" , standalone = False , files = True , dirs = True , ) def __post_init__ ( self ): self . _new_name = Template . from_string ( self . new_name ) self . _rename_template = Template . from_string ( self . rename_template ) def pipeline ( self , res : Resource , output : Output , simulate : bool ): assert res . path is not None , \"Does not support standalone mode\" new_name = render ( self . _new_name , res . dict ()) if \"/\" in new_name : raise ValueError ( \"The new name cannot contain slashes. \" \"To move files or folders use `move`.\" ) dst = res . path . with_name ( new_name ) skip_action , dst = resolve_conflict ( dst = dst , res = res , conflict_mode = self . on_conflict , rename_template = self . _rename_template , simulate = simulate , output = output , ) if skip_action : return output . msg ( res = res , msg = f \"Renaming to { new_name } \" , sender = self ) if not simulate : res . path . rename ( dst ) res . path = dst res . walker_skip_pathes . add ( dst ) Examples: rules: - name: \"Convert all .PDF file extensions to lowercase (.pdf)\" locations: \"~/Desktop\" filters: - name - extension: PDF actions: - rename: \"{name}.pdf\" rules: - name: \"Convert **all** file extensions to lowercase\" locations: \"~/Desktop\" filters: - name - extension actions: - rename: \"{name}.{extension.lower()}\"","title":"rename"},{"location":"actions/#shell","text":"Executes a shell command Attributes: cmd ( str ) \u2013 The command to execute. run_in_simulation ( bool ) \u2013 Whether to execute in simulation mode (default = false) ignore_errors ( bool ) \u2013 Whether to continue on returncodes != 0. simulation_output ( str ) \u2013 The value of {shell.output} if run in simulation simulation_returncode ( int ) \u2013 The value of {shell.returncode} if run in simulation Returns {shell.output} ( str ): The stdout of the executed process. {shell.returncode} ( int ): The returncode of the executed process. Source code in organize/actions/shell.py 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 @dataclass ( config = ConfigDict ( coerce_numbers_to_str = True , extra = \"forbid\" )) class Shell : \"\"\" Executes a shell command Attributes: cmd (str): The command to execute. run_in_simulation (bool): Whether to execute in simulation mode (default = false) ignore_errors (bool): Whether to continue on returncodes != 0. simulation_output (str): The value of `{shell.output}` if run in simulation simulation_returncode (int): The value of `{shell.returncode}` if run in simulation Returns - `{shell.output}` (`str`): The stdout of the executed process. - `{shell.returncode}` (`int`): The returncode of the executed process. \"\"\" cmd : str run_in_simulation : bool = False ignore_errors : bool = False simulation_output : str = \"** simulation **\" simulation_returncode : int = 0 action_config : ClassVar [ ActionConfig ] = ActionConfig ( name = \"shell\" , standalone = True , files = True , dirs = True , ) def __post_init__ ( self ): self . _cmd = Template . from_string ( self . cmd ) self . _simulation_output = Template . from_string ( self . simulation_output ) def pipeline ( self , res : Resource , output : Output , simulate : bool ): full_cmd = render ( self . _cmd , res . dict ()) if not simulate or self . run_in_simulation : output . msg ( res = res , msg = f \"$ { full_cmd } \" , sender = self ) try : call = subprocess . run ( full_cmd , check = True , stdout = subprocess . PIPE , stderr = subprocess . STDOUT , shell = True , ) except subprocess . CalledProcessError as e : if not self . ignore_errors : raise e res . vars [ self . action_config . name ] = { \"output\" : call . stdout . decode ( \"utf-8\" ), \"returncode\" : call . returncode , } else : output . msg ( res = res , msg = f \"** not run in simulation ** $ { full_cmd } \" , sender = self , ) res . vars [ self . action_config . name ] = { \"output\" : render ( self . _simulation_output , res . dict ()), \"returncode\" : self . simulation_returncode , } Examples: rules: - name: \"On macOS: Open all pdfs on your desktop\" locations: \"~/Desktop\" filters: - extension: pdf actions: - shell: 'open \"{path}\"'","title":"shell"},{"location":"actions/#symlink","text":"Create a symbolic link. Attributes: dest ( str ) \u2013 The symlink destination. If dest ends with a slash `/``, create the symlink in the given directory. Can contain placeholders. on_conflict ( str ) \u2013 What should happen in case dest already exists. One of skip , overwrite , trash , rename_new and rename_existing . Defaults to rename_new . rename_template ( str ) \u2013 A template for renaming the file / dir in case of a conflict. Defaults to {name} {counter}{extension} . autodetect_folder ( bool ) \u2013 In case you forget the ending slash \"/\" to indicate creating the link inside the destination folder this settings will handle targets without a file extension as folders. If you really mean to copy to a file without file extension, set this to false. Default: true Source code in organize/actions/symlink.py 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 @dataclass ( config = ConfigDict ( coerce_numbers_to_str = True , extra = \"forbid\" )) class Symlink : \"\"\"Create a symbolic link. Attributes: dest (str): The symlink destination. If **dest** ends with a slash `/``, create the symlink in the given directory. Can contain placeholders. on_conflict (str): What should happen in case **dest** already exists. One of `skip`, `overwrite`, `trash`, `rename_new` and `rename_existing`. Defaults to `rename_new`. rename_template (str): A template for renaming the file / dir in case of a conflict. Defaults to `{name} {counter}{extension}`. autodetect_folder (bool): In case you forget the ending slash \"/\" to indicate creating the link inside the destination folder this settings will handle targets without a file extension as folders. If you really mean to copy to a file without file extension, set this to false. Default: true \"\"\" dest : str on_conflict : ConflictMode = \"rename_new\" rename_template : str = \" {name} {counter}{extension} \" autodetect_folder : bool = True action_config : ClassVar [ ActionConfig ] = ActionConfig ( name = \"symlink\" , standalone = False , files = True , dirs = True , ) def __post_init__ ( self ): self . _dest = Template . from_string ( self . dest ) self . _rename_template = Template . from_string ( self . rename_template ) def pipeline ( self , res : Resource , output : Output , simulate : bool ): assert res . path is not None , \"Does not support standalone mode\" rendered = render ( self . _dest , res . dict ()) dst = prepare_target_path ( src_name = res . path . name , dst = rendered , autodetect_folder = self . autodetect_folder , simulate = simulate , ) skip_action , dst = resolve_conflict ( dst = dst , res = res , conflict_mode = self . on_conflict , rename_template = self . _rename_template , simulate = simulate , output = output , ) if skip_action : return output . msg ( res = res , msg = f \"Creating symlink at { dst } \" , sender = self ) res . walker_skip_pathes . add ( dst ) if not simulate : dst . symlink_to ( target = res . path , target_is_directory = res . is_dir ())","title":"symlink"},{"location":"actions/#trash","text":"Move a file or dir into the trash. Source code in organize/actions/trash.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 @dataclass ( config = ConfigDict ( coerce_numbers_to_str = True , extra = \"forbid\" )) class Trash : \"\"\"Move a file or dir into the trash.\"\"\" action_config : ClassVar [ ActionConfig ] = ActionConfig ( name = \"trash\" , standalone = False , files = True , dirs = True , ) def pipeline ( self , res : Resource , output : Output , simulate : bool ): assert res . path is not None , \"Does not support standalone mode\" output . msg ( res = res , msg = f 'Trash \" { res . path } \"' , sender = self ) if not simulate : trash ( res . path ) Examples: rules: - name: Move all JPGs and PNGs on the desktop which are older than one year into the trash locations: \"~/Desktop\" filters: - lastmodified: years: 1 mode: older - extension: - png - jpg actions: - trash","title":"trash"},{"location":"actions/#write","text":"Write text to a file. If the specified path does not exist it will be created. Attributes: text ( str ) \u2013 The text that should be written. Supports templates. outfile ( str ) \u2013 The file text should be written into. Supports templates. mode ( str ) \u2013 Can be either append (append text to the file), prepend (insert text as first line) or overwrite (overwrite content with text). Defaults to append . encoding ( str ) \u2013 The text encoding to use. Default: \"utf-8\". newline ( str ) \u2013 (Optional) Whether to append a newline to the given text . Defaults to true . clear_before_first_write ( bool ) \u2013 (Optional) Clears the file before first appending / prepending text to it. This happens only the first time the file is written to. If the rule filters don't match anything the file is left as it is. Defaults to false . Source code in organize/actions/write.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 @dataclass ( config = ConfigDict ( coerce_numbers_to_str = True , extra = \"forbid\" )) class Write : \"\"\" Write text to a file. If the specified path does not exist it will be created. Attributes: text (str): The text that should be written. Supports templates. outfile (str): The file `text` should be written into. Supports templates. mode (str): Can be either `append` (append text to the file), `prepend` (insert text as first line) or `overwrite` (overwrite content with text). Defaults to `append`. encoding (str): The text encoding to use. Default: \"utf-8\". newline (str): (Optional) Whether to append a newline to the given `text`. Defaults to `true`. clear_before_first_write (bool): (Optional) Clears the file before first appending / prepending text to it. This happens only the first time the file is written to. If the rule filters don't match anything the file is left as it is. Defaults to `false`. \"\"\" text : str outfile : str mode : Literal [ \"append\" , \"prepend\" , \"overwrite\" ] = \"append\" encoding : str = \"utf-8\" newline : bool = True clear_before_first_write : bool = False action_config : ClassVar [ ActionConfig ] = ActionConfig ( name = \"write\" , standalone = True , files = True , dirs = True , ) def __post_init__ ( self ): self . _text = Template . from_string ( self . text ) self . _path = Template . from_string ( self . outfile ) self . _known_files = set () def pipeline ( self , res : Resource , output : Output , simulate : bool ): text = render ( self . _text , res . dict ()) path = Path ( render ( self . _path , res . dict ())) resolved = path . resolve () if resolved not in self . _known_files : self . _known_files . add ( resolved ) if not simulate : resolved . parent . mkdir ( parents = True , exist_ok = True ) # clear on first write if resolved . exists () and self . clear_before_first_write : output . msg ( res = res , msg = f \"Clearing file { path } \" , sender = self ) if not simulate : resolved . open ( \"w\" ) # clear the file output . msg ( res = res , msg = f ' { path } : { self . mode } \" { text } \"' , sender = self ) if self . newline : text += \" \\n \" if not simulate : if self . mode == \"append\" : with open ( path , \"a\" , encoding = self . encoding ) as f : f . write ( text ) elif self . mode == \"prepend\" : content = \"\" if path . exists (): content = path . read_text ( encoding = self . encoding ) path . write_text ( text + content , encoding = self . encoding ) elif self . mode == \"overwrite\" : path . write_text ( text , encoding = self . encoding ) Examples rules: - name: \"Record file sizes\" locations: ~/Downloads filters: - size actions: - write: outfile: \"./sizes.txt\" text: \"{size.traditional} -- {relative_path}\" mode: \"append\" clear_before_first_write: true This will create a file sizes.txt in the current working folder which contains the filesizes of everything in the ~/Downloads folder: 2.9 MB -- SIM7600.pdf 1.0 MB -- Bildschirmfoto 2022-07-05 um 10.43.16.png 5.9 MB -- Albumcover.png 51.2 KB -- Urlaubsantrag 2022-04-19.pdf 1.8 MB -- ETH_USB_HUB_HAT.pdf 2.1 MB -- ArduinoDUE_V02g_sch.pdf ... You can use templates both in the text as well as in the textfile parameter: rules: - name: \"File sizes by extension\" locations: ~/Downloads filters: - size - extension actions: - write: outfile: \"./sizes.{extension}.txt\" text: \"{size.traditional} -- {relative_path}\" mode: \"prepend\" clear_before_first_write: true This will separate the filesizes by extension.","title":"write"},{"location":"changelog/","text":"Changelog # [Unreleased] # v3.2.0 (2024-02-19) # Integrated .docx , .pdf and various raw text parsers into filecontent filter. Removed textract and ~50 MB of dependencies as they are no longer required. Full Python 3.12 support Add support for piping in a config file from STDIN ( organize run --stdin < file.yml ) Important: You may have to adjust your filecontent regexes. The output should be a bit cleaner now. v3.1.2 (2024-02-16) # Fixes a validation error where correctly defined actions were not accepted in Python 3.12.2. v3.1.1 (2024-02-11) # Fixes the organize show command which broke in v3.1.0. v3.1.0 (2024-02-04) # Add a new output format errorsonly which only shows output if an error occured. Fixes a bug where messages and paths containing brackets where not printed correctly (#348, thanks @kwbr!) v3.0.1 (2024-01-12) # Fixes a bug where Quicktime and mp4 files return no Exif data. (#313, @jleatham thanks for debugging!) Fixes a bug where exlude_dirs are not correctly excluded. (#339) v3.0.0 (2024-01-05) # Supports exiftool in the exif filter by setting the ORGANIZE_EXIFTOOL_PATH env var. (thanks to @HernandoR for working on qtff support) Fixes the min_depth location parameter. (thanks to @danielklim for working on this) v3.0.0a2 (2024-01-02) # Fix bug on first run of organize new . Create the organize config directory if it does not exist. (thanks @white-gecko) Adds action hardlink . v3.0.0a1 (2024-01-01) # Default to UTF-8 encoding when reading and writing config files for windows users who don't use python in UTF-8 mode (env variable PYTHONUTF8=1 ). write -action: Allow setting the text encoding. v3.0.0a0 (2023-12-31) # New action: write to write lines into a file. New filter: date_lastused (macOS only). You can now specify the timezone in all time based filters. Removed hidden (deprecated) CLI option --config-file . Lots of new tests and some bugfixes. exif filter now supports the simplematch syntax. Placeholder {now} must be {now()} now. Multiple path s per location are now supported. Locations now support a min_depth option Duplicate filter: detect_original_by now supports last_seen . New command line interface (added new , show and list commands). JSONL output ( organize run --format=JSONL ) move and copy now intelligently autodetect if you mean to move to a folder (This autodetection can be deactivated). copy action: You can now specify whether you want to continue with the original or with the copy. Completely removes the pyfilesystem dependency. At least a 4x speed up. Often more than 10x. v2.4.3 (2023-10-14) # Modified filter: exif . Enabled datetime fields on exif data (Issue #266) (Thanks @FlorianFritz) Support Exif data from Huawei and Honer phones (Thanks @HernandoR) v2.4.2 (2023-08-25) # Fix reading exif data for HEIC images (Issue #267) v2.4.1 (2023-08-25) # Fix unicode bug in logging (Issue #294) (Thanks @xdhmoore) Updated dependencies (Thanks @gaby) Removed support for python 3.7 (EOL - June 2023) (Thanks @gaby) v2.4.0 (2022-09-05) # New action: write . New filter: date_lastused (macOS only). Conflict resolution renaming now starts with 2 instead of 1. Add support for FS urls as path to the config file and working dir (both in the CLI and ORGANIZE_CONFIG environment variable). Removed hidden (deprecated) CLI option --config-file . Lots of new tests and some bugfixes. v2.3.0 (2022-07-26) # New filter: macos_tags (macOS only). Ignore broken symlinks (Issue #202) v2.2.0 (2022-03-31) # Tag support (#199) to run subsets of rules in your config. v2.1.2 (2022-02-13) # Hotfix for filecontent filter. v2.1.1 (2022-02-13) # filecontent filter: Fixes bug #188. Bugfix for #185 and #184. v2.1.0 (2022-02-11) # Added filter date_added (macOS only) created filter now supports gnu coreutils stat utility for birthtime detection refactored time based filters into a common class v2.0.9 (2022-02-10) # shell shows a message when code is not run in simulation shell add options simulation_output and simulation_returncode fixes a bug where location options are applied to other locations as well created filter now falls back to using the stat utility on linux systems where the birthtime is not included in os.stat . v2.0.8 (2022-02-09) # Bugfix shell for real. v2.0.7 (2022-02-09) # Bugfix for shell . v2.0.6 (2022-02-09) # Speed up moving files. shell action: Run command through the user's shell. v2.0.5 (2022-02-08) # Fixed the migration message and docs URL v2.0.4 (2022-02-08) # exclude_dir, system_exclude_dirs, exclude_files, system_exclude_files, filter and filter_dirs now accept single strings. Fixed a bug in the name filter v2.0.3 (2022-02-07) # Fixed typo: system_exlude_files v2.0.2 (2022-02-07) # Bugfix in env variable expansion in locations v2.0.1 (2022-02-07) # Small bugfix in macos_tags action. Bugfix in the migration detection. v2.0.0 (2022-02-07) # This is a huge update with lots of improvements. Please backup all your important stuff before running and use the simulate option! Migration Guide what's new # You can now target directories with your rules (copying, renaming, etc a whole folder) Organize inside or between (S)FTP, S3 Buckets, Zip archives and many more (list of available filesystems ). max_depth setting when recursing into subfolders Respects your rule order - safer, less magic, less surprises. (organize v1 tried to be clever. v2 now works your config file from top to bottom) Jinja2 template engine for placeholders . Instant start. (does not need to gather all the files before starting) Filters can now be excluded . Filter modes : all , any and none . Rule names . new conflict resolution settings in move , copy and rename action: Options are skip , overwrite , trash , rename_new or rename_existing You can now define a custom rename_template . The duplicate now supports several options on how to distinguish between original and duplicate file. The python action can now be run in simulation. The shell action now returns stdout and errorcode. Added filter empty - find empty files and folders Added filter hash - generate file hashes Added action symlink - generate symlinks Added action confirm - asks for confirmation Many small fixes and improvements! changed # The timezone keyword for lastmodified and created was removed. The timezone is now the local timezone by default. The filesize filter was renamed to size and can now be used to get directory sizes as well. The filename filter was renamed to name and can now be used to get directory names as well. The size filter now returns multiple formats removed # Glob syntax is gone from folders ( no longer needed ) \"!\" folder exclude syntax is gone ( no longer needed ) v1.10.1 (2021-04-21) # Action macos_tags now supports colors and placeholders. Show full expanded path if folder is not found. v1.10.0 (2021-04-20) # Add filter mimetype Add action macos_tags Support simplematch syntax in lename -filter. Updated dependencies Because installing textract is quite hard on some platforms it is now an optional dendency. Install it with pip install organize-tool[textract] This version needs python 3.6 minimum. Some dependencies that were simply backports (thlib2, typing) are removed. Add timezones in created and last_modified filters (Thank you, @win0err!) v1.9.1 (2020-11-10) # Add {env} variable Add {now} variable v1.9 (2020-06-12) # Add filter Duplicate . v1.8.2 (2020-04-03) # Fix a bug in the filename filter config parsing algorithm with digits-only filenames. v1.8.1 (2020-03-28) # Flatten filter and action lists to allow enhanced config file configuration (Thanks to @rawdamedia!) Add support for multiline content filters (Thanks to @zor-el!) v1.8.0 (2020-03-04) # Added action Delete . Added filter FileContent . Python 3.4 is officially deprecated and no longer supported. --config-file command line option now supports ~ for user folder and expansion oenvironment variables Added years , months , weeks and seconds parameter to filter created and stmodified v1.7.0 (2019-11-26) # Added filter Exif to filter by image exif data. Placeholder variable properties are now case insensitve. v1.6.2 (2019-11-22) # Fix Rename action ( 'PosixPath' object has no attribute 'items' ). Use type hints everywhere. v1.6.1 (2019-10-25) # Shows a warning for missing folders instead of raising an exception. v1.6 (2019-08-19) # Added filter: Python Added filter: FileSize The organize module can now be run directly: python3 -m organize Various code simplifications and speedups. Fixes an issue with globstring file exclusion. Remove clint dependency as it is no longer maintained. Added various integration tests The \"~~ SIMULATION ~~\"-banner now takes up the whole terminal width v1.5.3 (2019-08-01) # Filename filter now supports lists. v1.5.2 (2019-07-29) # Environment variables in folder pathes are now expanded (syntax $name or ${name} a additionally %name% on windows). F example this allows the usage of e.g. %public/Desktop% in windows. v1.5.1 (2019-07-23) # New filter \"Created\" to filter by creation date. Fixes issue #39 where globstrings don't work most of the time. Integration test for issue #39 Support indented config files v1.5 (2019-07-17) # Fixes issue #31 where the {path} variable always resolves to the source path Updated dependencies Exclude changelog and readme from published wheel v1.4.5 (2019-07-03) # Filter and Actions names are now case-insensitive v1.4.4 (2019-07-02) # Fixes issues #36 with umlauts in config file on windows v1.4.3 (2019-06-05) # Use safe YAML loader to fix a deprecation warning. (Thanks mope1!) Better error message if a folder does not exist. (Again thanks mope1!) Fix example code in documentation for LastModified filter. Custom config file locations (given by cmd line argument or environment variable). config --debug now shows the full path to the config file. v1.4.2 (2018-11-14) # Fixes a bug with command line arguments in the $EDITOR environment viable. Fixes a bug where an empty config wouldn't show the correct error message. Fix binary wheel creation in setup.py by using environment markers v1.4.1 (2018-10-05) # A custom separator counter_separator can now be set in the actions Move, Cy and Rename. v1.4 (2018-09-21) # Fixes a bug where glob wildcards are not detected correctly Adds support for excluding folders and files via glob syntax. Makes sure that files are only handled once per rule. v1.3 (2018-07-06) # Glob support in folder configuration. New variable {relative_path} is now available in actions. v1.2 (2018-03-19) # Shows the relative path to files in subfolders. v1.1 (2018-03-13) # Removes the colon from extension filter output so {extension.lower} now rurns 'png' instead of '.png' . v1.0 (2018-03-13) # Initial release.","title":"Changelog"},{"location":"changelog/#changelog","text":"","title":"Changelog"},{"location":"changelog/#unreleased","text":"","title":"[Unreleased]"},{"location":"changelog/#v320-2024-02-19","text":"Integrated .docx , .pdf and various raw text parsers into filecontent filter. Removed textract and ~50 MB of dependencies as they are no longer required. Full Python 3.12 support Add support for piping in a config file from STDIN ( organize run --stdin < file.yml ) Important: You may have to adjust your filecontent regexes. The output should be a bit cleaner now.","title":"v3.2.0 (2024-02-19)"},{"location":"changelog/#v312-2024-02-16","text":"Fixes a validation error where correctly defined actions were not accepted in Python 3.12.2.","title":"v3.1.2 (2024-02-16)"},{"location":"changelog/#v311-2024-02-11","text":"Fixes the organize show command which broke in v3.1.0.","title":"v3.1.1 (2024-02-11)"},{"location":"changelog/#v310-2024-02-04","text":"Add a new output format errorsonly which only shows output if an error occured. Fixes a bug where messages and paths containing brackets where not printed correctly (#348, thanks @kwbr!)","title":"v3.1.0 (2024-02-04)"},{"location":"changelog/#v301-2024-01-12","text":"Fixes a bug where Quicktime and mp4 files return no Exif data. (#313, @jleatham thanks for debugging!) Fixes a bug where exlude_dirs are not correctly excluded. (#339)","title":"v3.0.1 (2024-01-12)"},{"location":"changelog/#v300-2024-01-05","text":"Supports exiftool in the exif filter by setting the ORGANIZE_EXIFTOOL_PATH env var. (thanks to @HernandoR for working on qtff support) Fixes the min_depth location parameter. (thanks to @danielklim for working on this)","title":"v3.0.0 (2024-01-05)"},{"location":"changelog/#v300a2-2024-01-02","text":"Fix bug on first run of organize new . Create the organize config directory if it does not exist. (thanks @white-gecko) Adds action hardlink .","title":"v3.0.0a2 (2024-01-02)"},{"location":"changelog/#v300a1-2024-01-01","text":"Default to UTF-8 encoding when reading and writing config files for windows users who don't use python in UTF-8 mode (env variable PYTHONUTF8=1 ). write -action: Allow setting the text encoding.","title":"v3.0.0a1 (2024-01-01)"},{"location":"changelog/#v300a0-2023-12-31","text":"New action: write to write lines into a file. New filter: date_lastused (macOS only). You can now specify the timezone in all time based filters. Removed hidden (deprecated) CLI option --config-file . Lots of new tests and some bugfixes. exif filter now supports the simplematch syntax. Placeholder {now} must be {now()} now. Multiple path s per location are now supported. Locations now support a min_depth option Duplicate filter: detect_original_by now supports last_seen . New command line interface (added new , show and list commands). JSONL output ( organize run --format=JSONL ) move and copy now intelligently autodetect if you mean to move to a folder (This autodetection can be deactivated). copy action: You can now specify whether you want to continue with the original or with the copy. Completely removes the pyfilesystem dependency. At least a 4x speed up. Often more than 10x.","title":"v3.0.0a0 (2023-12-31)"},{"location":"changelog/#v243-2023-10-14","text":"Modified filter: exif . Enabled datetime fields on exif data (Issue #266) (Thanks @FlorianFritz) Support Exif data from Huawei and Honer phones (Thanks @HernandoR)","title":"v2.4.3 (2023-10-14)"},{"location":"changelog/#v242-2023-08-25","text":"Fix reading exif data for HEIC images (Issue #267)","title":"v2.4.2 (2023-08-25)"},{"location":"changelog/#v241-2023-08-25","text":"Fix unicode bug in logging (Issue #294) (Thanks @xdhmoore) Updated dependencies (Thanks @gaby) Removed support for python 3.7 (EOL - June 2023) (Thanks @gaby)","title":"v2.4.1 (2023-08-25)"},{"location":"changelog/#v240-2022-09-05","text":"New action: write . New filter: date_lastused (macOS only). Conflict resolution renaming now starts with 2 instead of 1. Add support for FS urls as path to the config file and working dir (both in the CLI and ORGANIZE_CONFIG environment variable). Removed hidden (deprecated) CLI option --config-file . Lots of new tests and some bugfixes.","title":"v2.4.0 (2022-09-05)"},{"location":"changelog/#v230-2022-07-26","text":"New filter: macos_tags (macOS only). Ignore broken symlinks (Issue #202)","title":"v2.3.0 (2022-07-26)"},{"location":"changelog/#v220-2022-03-31","text":"Tag support (#199) to run subsets of rules in your config.","title":"v2.2.0 (2022-03-31)"},{"location":"changelog/#v212-2022-02-13","text":"Hotfix for filecontent filter.","title":"v2.1.2 (2022-02-13)"},{"location":"changelog/#v211-2022-02-13","text":"filecontent filter: Fixes bug #188. Bugfix for #185 and #184.","title":"v2.1.1 (2022-02-13)"},{"location":"changelog/#v210-2022-02-11","text":"Added filter date_added (macOS only) created filter now supports gnu coreutils stat utility for birthtime detection refactored time based filters into a common class","title":"v2.1.0 (2022-02-11)"},{"location":"changelog/#v209-2022-02-10","text":"shell shows a message when code is not run in simulation shell add options simulation_output and simulation_returncode fixes a bug where location options are applied to other locations as well created filter now falls back to using the stat utility on linux systems where the birthtime is not included in os.stat .","title":"v2.0.9 (2022-02-10)"},{"location":"changelog/#v208-2022-02-09","text":"Bugfix shell for real.","title":"v2.0.8 (2022-02-09)"},{"location":"changelog/#v207-2022-02-09","text":"Bugfix for shell .","title":"v2.0.7 (2022-02-09)"},{"location":"changelog/#v206-2022-02-09","text":"Speed up moving files. shell action: Run command through the user's shell.","title":"v2.0.6 (2022-02-09)"},{"location":"changelog/#v205-2022-02-08","text":"Fixed the migration message and docs URL","title":"v2.0.5 (2022-02-08)"},{"location":"changelog/#v204-2022-02-08","text":"exclude_dir, system_exclude_dirs, exclude_files, system_exclude_files, filter and filter_dirs now accept single strings. Fixed a bug in the name filter","title":"v2.0.4 (2022-02-08)"},{"location":"changelog/#v203-2022-02-07","text":"Fixed typo: system_exlude_files","title":"v2.0.3 (2022-02-07)"},{"location":"changelog/#v202-2022-02-07","text":"Bugfix in env variable expansion in locations","title":"v2.0.2 (2022-02-07)"},{"location":"changelog/#v201-2022-02-07","text":"Small bugfix in macos_tags action. Bugfix in the migration detection.","title":"v2.0.1 (2022-02-07)"},{"location":"changelog/#v200-2022-02-07","text":"This is a huge update with lots of improvements. Please backup all your important stuff before running and use the simulate option! Migration Guide","title":"v2.0.0 (2022-02-07)"},{"location":"changelog/#whats-new","text":"You can now target directories with your rules (copying, renaming, etc a whole folder) Organize inside or between (S)FTP, S3 Buckets, Zip archives and many more (list of available filesystems ). max_depth setting when recursing into subfolders Respects your rule order - safer, less magic, less surprises. (organize v1 tried to be clever. v2 now works your config file from top to bottom) Jinja2 template engine for placeholders . Instant start. (does not need to gather all the files before starting) Filters can now be excluded . Filter modes : all , any and none . Rule names . new conflict resolution settings in move , copy and rename action: Options are skip , overwrite , trash , rename_new or rename_existing You can now define a custom rename_template . The duplicate now supports several options on how to distinguish between original and duplicate file. The python action can now be run in simulation. The shell action now returns stdout and errorcode. Added filter empty - find empty files and folders Added filter hash - generate file hashes Added action symlink - generate symlinks Added action confirm - asks for confirmation Many small fixes and improvements!","title":"what's new"},{"location":"changelog/#changed","text":"The timezone keyword for lastmodified and created was removed. The timezone is now the local timezone by default. The filesize filter was renamed to size and can now be used to get directory sizes as well. The filename filter was renamed to name and can now be used to get directory names as well. The size filter now returns multiple formats","title":"changed"},{"location":"changelog/#removed","text":"Glob syntax is gone from folders ( no longer needed ) \"!\" folder exclude syntax is gone ( no longer needed )","title":"removed"},{"location":"changelog/#v1101-2021-04-21","text":"Action macos_tags now supports colors and placeholders. Show full expanded path if folder is not found.","title":"v1.10.1 (2021-04-21)"},{"location":"changelog/#v1100-2021-04-20","text":"Add filter mimetype Add action macos_tags Support simplematch syntax in lename -filter. Updated dependencies Because installing textract is quite hard on some platforms it is now an optional dendency. Install it with pip install organize-tool[textract] This version needs python 3.6 minimum. Some dependencies that were simply backports (thlib2, typing) are removed. Add timezones in created and last_modified filters (Thank you, @win0err!)","title":"v1.10.0 (2021-04-20)"},{"location":"changelog/#v191-2020-11-10","text":"Add {env} variable Add {now} variable","title":"v1.9.1 (2020-11-10)"},{"location":"changelog/#v19-2020-06-12","text":"Add filter Duplicate .","title":"v1.9 (2020-06-12)"},{"location":"changelog/#v182-2020-04-03","text":"Fix a bug in the filename filter config parsing algorithm with digits-only filenames.","title":"v1.8.2 (2020-04-03)"},{"location":"changelog/#v181-2020-03-28","text":"Flatten filter and action lists to allow enhanced config file configuration (Thanks to @rawdamedia!) Add support for multiline content filters (Thanks to @zor-el!)","title":"v1.8.1 (2020-03-28)"},{"location":"changelog/#v180-2020-03-04","text":"Added action Delete . Added filter FileContent . Python 3.4 is officially deprecated and no longer supported. --config-file command line option now supports ~ for user folder and expansion oenvironment variables Added years , months , weeks and seconds parameter to filter created and stmodified","title":"v1.8.0 (2020-03-04)"},{"location":"changelog/#v170-2019-11-26","text":"Added filter Exif to filter by image exif data. Placeholder variable properties are now case insensitve.","title":"v1.7.0 (2019-11-26)"},{"location":"changelog/#v162-2019-11-22","text":"Fix Rename action ( 'PosixPath' object has no attribute 'items' ). Use type hints everywhere.","title":"v1.6.2 (2019-11-22)"},{"location":"changelog/#v161-2019-10-25","text":"Shows a warning for missing folders instead of raising an exception.","title":"v1.6.1 (2019-10-25)"},{"location":"changelog/#v16-2019-08-19","text":"Added filter: Python Added filter: FileSize The organize module can now be run directly: python3 -m organize Various code simplifications and speedups. Fixes an issue with globstring file exclusion. Remove clint dependency as it is no longer maintained. Added various integration tests The \"~~ SIMULATION ~~\"-banner now takes up the whole terminal width","title":"v1.6 (2019-08-19)"},{"location":"changelog/#v153-2019-08-01","text":"Filename filter now supports lists.","title":"v1.5.3 (2019-08-01)"},{"location":"changelog/#v152-2019-07-29","text":"Environment variables in folder pathes are now expanded (syntax $name or ${name} a additionally %name% on windows). F example this allows the usage of e.g. %public/Desktop% in windows.","title":"v1.5.2 (2019-07-29)"},{"location":"changelog/#v151-2019-07-23","text":"New filter \"Created\" to filter by creation date. Fixes issue #39 where globstrings don't work most of the time. Integration test for issue #39 Support indented config files","title":"v1.5.1 (2019-07-23)"},{"location":"changelog/#v15-2019-07-17","text":"Fixes issue #31 where the {path} variable always resolves to the source path Updated dependencies Exclude changelog and readme from published wheel","title":"v1.5 (2019-07-17)"},{"location":"changelog/#v145-2019-07-03","text":"Filter and Actions names are now case-insensitive","title":"v1.4.5 (2019-07-03)"},{"location":"changelog/#v144-2019-07-02","text":"Fixes issues #36 with umlauts in config file on windows","title":"v1.4.4 (2019-07-02)"},{"location":"changelog/#v143-2019-06-05","text":"Use safe YAML loader to fix a deprecation warning. (Thanks mope1!) Better error message if a folder does not exist. (Again thanks mope1!) Fix example code in documentation for LastModified filter. Custom config file locations (given by cmd line argument or environment variable). config --debug now shows the full path to the config file.","title":"v1.4.3 (2019-06-05)"},{"location":"changelog/#v142-2018-11-14","text":"Fixes a bug with command line arguments in the $EDITOR environment viable. Fixes a bug where an empty config wouldn't show the correct error message. Fix binary wheel creation in setup.py by using environment markers","title":"v1.4.2 (2018-11-14)"},{"location":"changelog/#v141-2018-10-05","text":"A custom separator counter_separator can now be set in the actions Move, Cy and Rename.","title":"v1.4.1 (2018-10-05)"},{"location":"changelog/#v14-2018-09-21","text":"Fixes a bug where glob wildcards are not detected correctly Adds support for excluding folders and files via glob syntax. Makes sure that files are only handled once per rule.","title":"v1.4 (2018-09-21)"},{"location":"changelog/#v13-2018-07-06","text":"Glob support in folder configuration. New variable {relative_path} is now available in actions.","title":"v1.3 (2018-07-06)"},{"location":"changelog/#v12-2018-03-19","text":"Shows the relative path to files in subfolders.","title":"v1.2 (2018-03-19)"},{"location":"changelog/#v11-2018-03-13","text":"Removes the colon from extension filter output so {extension.lower} now rurns 'png' instead of '.png' .","title":"v1.1 (2018-03-13)"},{"location":"changelog/#v10-2018-03-13","text":"Initial release.","title":"v1.0 (2018-03-13)"},{"location":"configuration/","text":"Configuration # Editing the configuration # organize has a default config file if no other file is given. To edit the default configuration file: organize edit # opens in $EDITOR organize edit --editor=vim EDITOR=code organize edit To open the folder containing the configuration file: organize reveal organize reveal --path # show the full path to the default config To check your configuration run: organize check organize check --debug # check with debug output Running and simulating # To run / simulate the default config file: organize sim organize run To run / simulate a specific config file: organize sim [FILE] organize run [FILE] Optionally you can specify the working directory like this: organize sim [FILE] --working-dir=~/Documents Running specific rules of your config # You can tag your rules like this: rules: - name: My first rule actions: - echo: \"Hello world\" tags: - debug - fast Then use the command line options --tags and --skip-tags so select the rules you want to run. The options take a comma-separated list of tags: organize sim --tags=debug,foo --skip-tags=slow Special tags: Rules tagged with the special tag always will always run (except if --skip-tags=always is specified) Rules tagged with the special tag never will never run (except if ' --tags=never is specified) Environment variables # ORGANIZE_CONFIG - The path to the default config file. ORGANIZE_EXIFTOOL_PATH - Path to the exiftool executable (Default: \"\" ) ORGANIZE_NORMALIZE_UNICODE - Whether to normalize strings to NFC unicode form for comparisons (Default \"1\" ) NO_COLOR - if this is set, the output is not colored. EDITOR - The editor used to edit the config file. Parallelize jobs # To speed up organizing you can run multiple organize processes simultaneously like this (linux / macOS): organize run config_1.yaml & \\ organize run config_2.yaml & \\ organize run config_3.yaml & Make sure that the config files are independent from each other, meaning that no rule depends on another rule in another config file.","title":"Configuration"},{"location":"configuration/#configuration","text":"","title":"Configuration"},{"location":"configuration/#editing-the-configuration","text":"organize has a default config file if no other file is given. To edit the default configuration file: organize edit # opens in $EDITOR organize edit --editor=vim EDITOR=code organize edit To open the folder containing the configuration file: organize reveal organize reveal --path # show the full path to the default config To check your configuration run: organize check organize check --debug # check with debug output","title":"Editing the configuration"},{"location":"configuration/#running-and-simulating","text":"To run / simulate the default config file: organize sim organize run To run / simulate a specific config file: organize sim [FILE] organize run [FILE] Optionally you can specify the working directory like this: organize sim [FILE] --working-dir=~/Documents","title":"Running and simulating"},{"location":"configuration/#running-specific-rules-of-your-config","text":"You can tag your rules like this: rules: - name: My first rule actions: - echo: \"Hello world\" tags: - debug - fast Then use the command line options --tags and --skip-tags so select the rules you want to run. The options take a comma-separated list of tags: organize sim --tags=debug,foo --skip-tags=slow Special tags: Rules tagged with the special tag always will always run (except if --skip-tags=always is specified) Rules tagged with the special tag never will never run (except if ' --tags=never is specified)","title":"Running specific rules of your config"},{"location":"configuration/#environment-variables","text":"ORGANIZE_CONFIG - The path to the default config file. ORGANIZE_EXIFTOOL_PATH - Path to the exiftool executable (Default: \"\" ) ORGANIZE_NORMALIZE_UNICODE - Whether to normalize strings to NFC unicode form for comparisons (Default \"1\" ) NO_COLOR - if this is set, the output is not colored. EDITOR - The editor used to edit the config file.","title":"Environment variables"},{"location":"configuration/#parallelize-jobs","text":"To speed up organizing you can run multiple organize processes simultaneously like this (linux / macOS): organize run config_1.yaml & \\ organize run config_2.yaml & \\ organize run config_3.yaml & Make sure that the config files are independent from each other, meaning that no rule depends on another rule in another config file.","title":"Parallelize jobs"},{"location":"docker/","text":"Using the organize docker image # The organize docker image comes preinstalled with exiftool and pdftotext as well as all the python dependencies set up and ready to go. Danger As organize is mainly used for moving files around you have to be careful about your volume mounts and paths. If you move a file to a folder which is not persisted it is gone as soon as the container is stopped! Building the image # cd into the organize folder (containing the Dockerfile ) and build the image: docker build -t organize . The image is now tagged as organize . Now you can test the image by running docker run organize This will show the organize usage help text. Running # Let's create a basic config file docker-conf.yml : rules: - locations: /data actions: - echo: \"Found file: {path}\" We can now run mount the config file to the container path /config/config.yml . The current directory is mounted to /data so we have some files present. We can now start the container: docker run -v ./docker-conf.yml:/config/config.yml -v .:/data organize run Passing the config file from stdin # Instead of mounting the config file into the container you can also pass it from stdin: docker run -i organize check --stdin < ./docker-conf.yml","title":"Docker"},{"location":"docker/#using-the-organize-docker-image","text":"The organize docker image comes preinstalled with exiftool and pdftotext as well as all the python dependencies set up and ready to go. Danger As organize is mainly used for moving files around you have to be careful about your volume mounts and paths. If you move a file to a folder which is not persisted it is gone as soon as the container is stopped!","title":"Using the organize docker image"},{"location":"docker/#building-the-image","text":"cd into the organize folder (containing the Dockerfile ) and build the image: docker build -t organize . The image is now tagged as organize . Now you can test the image by running docker run organize This will show the organize usage help text.","title":"Building the image"},{"location":"docker/#running","text":"Let's create a basic config file docker-conf.yml : rules: - locations: /data actions: - echo: \"Found file: {path}\" We can now run mount the config file to the container path /config/config.yml . The current directory is mounted to /data so we have some files present. We can now start the container: docker run -v ./docker-conf.yml:/config/config.yml -v .:/data organize run","title":"Running"},{"location":"docker/#passing-the-config-file-from-stdin","text":"Instead of mounting the config file into the container you can also pass it from stdin: docker run -i organize check --stdin < ./docker-conf.yml","title":"Passing the config file from stdin"},{"location":"filters/","text":"Filters # This page shows the specifics of each filter. - How to exclude filters - # To exclude a filter, prefix the filter name with not (e.g. \"not empty\" , \"not extension\": jpg , etc). Note If you want to exclude all filters you can set the rule's filter_mode to none . Example: rules: # using filter_mode - locations: ~/Desktop filter_mode: \"none\" # <- excludes all filters: - empty - name: endswith: \"2022\" actions: - echo: \"{name}\" # Exclude a single filter - locations: ~/Desktop filters: - not extension: jpg # <- matches all non-jpgs - name: startswith: \"Invoice\" - not empty # <- matches files with content actions: - echo: \"{name}\" created # Matches files / folders by created date Attributes: years ( int ) \u2013 specify number of years months ( int ) \u2013 specify number of months weeks ( float ) \u2013 specify number of weeks days ( float ) \u2013 specify number of days hours ( float ) \u2013 specify number of hours minutes ( float ) \u2013 specify number of minutes seconds ( float ) \u2013 specify number of seconds mode ( str ) \u2013 either 'older' or 'newer'. 'older' matches files / folders created before the given time, 'newer' matches files / folders created within the given time. (default = 'older') Returns: \u2013 {created} (datetime): The datetime the file / folder was created. Source code in organize/filters/created.py 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 class Created ( TimeFilter ): \"\"\"Matches files / folders by created date Attributes: years (int): specify number of years months (int): specify number of months weeks (float): specify number of weeks days (float): specify number of days hours (float): specify number of hours minutes (float): specify number of minutes seconds (float): specify number of seconds mode (str): either 'older' or 'newer'. 'older' matches files / folders created before the given time, 'newer' matches files / folders created within the given time. (default = 'older') Returns: `{created}` (datetime): The datetime the file / folder was created. \"\"\" filter_config : ClassVar [ FilterConfig ] = FilterConfig ( name = \"created\" , files = True , dirs = True , ) def get_datetime ( self , path : Path ) -> datetime : return read_created ( path ) Examples: Show all files on your desktop created at least 10 days ago rules: - name: Show all files on your desktop created at least 10 days ago locations: \"~/Desktop\" filters: - created: days: 10 actions: - echo: \"Was created at least 10 days ago\" Show all files on your desktop which were created within the last 5 hours rules: - name: Show all files on your desktop which were created within the last 5 hours locations: \"~/Desktop\" filters: - created: hours: 5 mode: newer actions: - echo: \"Was created within the last 5 hours\" Sort pdfs by year of creation rules: - name: Sort pdfs by year of creation locations: \"~/Documents\" filters: - extension: pdf - created actions: - move: \"~/Documents/PDF/{created.year}/\" Formatting the creation date rules: - name: Display the creation date locations: \"~/Documents\" filters: - extension: pdf - created actions: - echo: \"ISO Format: {created.strftime('%Y-%m-%d')}\" - echo: \"As timestamp: {created.timestamp() | int}\" date_added # Matches files by the time the file was added to a folder. date_added is only available on macOS! Attributes: years ( int ) \u2013 specify number of years months ( int ) \u2013 specify number of months weeks ( float ) \u2013 specify number of weeks days ( float ) \u2013 specify number of days hours ( float ) \u2013 specify number of hours minutes ( float ) \u2013 specify number of minutes seconds ( float ) \u2013 specify number of seconds mode ( str ) \u2013 either 'older' or 'newer'. 'older' matches files / folders last modified before the given time, 'newer' matches files / folders last modified within the given time. (default = 'older') Returns: \u2013 {date_added} : The datetime the files / folders were added. Source code in organize/filters/date_added.py 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 class DateAdded ( TimeFilter ): \"\"\"Matches files by the time the file was added to a folder. **`date_added` is only available on macOS!** Attributes: years (int): specify number of years months (int): specify number of months weeks (float): specify number of weeks days (float): specify number of days hours (float): specify number of hours minutes (float): specify number of minutes seconds (float): specify number of seconds mode (str): either 'older' or 'newer'. 'older' matches files / folders last modified before the given time, 'newer' matches files / folders last modified within the given time. (default = 'older') Returns: `{date_added}`: The datetime the files / folders were added. \"\"\" filter_config : ClassVar [ FilterConfig ] = FilterConfig ( name = \"date_added\" , files = True , dirs = True , ) def __post_init__ ( self ): if sys . platform != \"darwin\" : raise EnvironmentError ( \"date_added is only available on macOS\" ) return super () . __post_init__ () def get_datetime ( self , path : Path ) -> datetime : return read_date_added ( path ) Works the same way as created and lastmodified . ** Examples ** rules: - name: Show the date the file was added to the folder locations: \"~/Desktop\" filters: - date_added actions: - echo: \"Date added: {date_added.strftime('%Y-%m-%d')}\" date_lastused # Matches files by the time the file was last used. date_lastused is only available on macOS! Attributes: years ( int ) \u2013 specify number of years months ( int ) \u2013 specify number of months weeks ( float ) \u2013 specify number of weeks days ( float ) \u2013 specify number of days hours ( float ) \u2013 specify number of hours minutes ( float ) \u2013 specify number of minutes seconds ( float ) \u2013 specify number of seconds mode ( str ) \u2013 either 'older' or 'newer'. 'older' matches files / folders last used before the given time, 'newer' matches files / folders last used within the given time. (default = 'older') Returns: \u2013 {date_lastused}: The datetime the files / folders were added. Source code in organize/filters/date_lastused.py 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 class DateLastUsed ( TimeFilter ): \"\"\"Matches files by the time the file was last used. **`date_lastused` is only available on macOS!** Attributes: years (int): specify number of years months (int): specify number of months weeks (float): specify number of weeks days (float): specify number of days hours (float): specify number of hours minutes (float): specify number of minutes seconds (float): specify number of seconds mode (str): either 'older' or 'newer'. 'older' matches files / folders last used before the given time, 'newer' matches files / folders last used within the given time. (default = 'older') Returns: {date_lastused}: The datetime the files / folders were added. \"\"\" filter_config : ClassVar [ FilterConfig ] = FilterConfig ( name = \"date_lastused\" , files = True , dirs = True , ) def __post_init__ ( self ): if sys . platform != \"darwin\" : raise EnvironmentError ( \"date_added is only available on macOS\" ) return super () . __post_init__ () def get_datetime ( self , path : Path ) -> datetime : return read_date_lastused ( path ) Works the same way as created and lastmodified . ** Examples ** rules: - name: Show the date the file was added to the folder locations: \"~/Desktop\" filters: - date_lastused actions: - echo: \"Date last used: {date_lastused.strftime('%Y-%m-%d')}\" duplicate # A fast duplicate file finder. This filter compares files byte by byte and finds identical files with potentially different filenames. Attributes: detect_original_by ( str ) \u2013 Detection method to distinguish between original and duplicate. Possible values are: \"first_seen\" : Whatever file is visited first is the original. This depends on the order of your location entries. \"name\" : The first entry sorted by name is the original. \"created\" : The first entry sorted by creation date is the original. \"lastmodified\" : The first file sorted by date of last modification is the original. You can reverse the sorting method by prefixing a - . So with detect_original_by: \"-created\" the file with the older creation date is the original and the younger file is the duplicate. This works on all methods, for example \"-first_seen\" , \"-name\" , \"-created\" , \"-lastmodified\" . Returns: {duplicate.original} - The path to the original Source code in organize/filters/duplicate.py 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 @dataclass ( config = ConfigDict ( extra = \"forbid\" )) class Duplicate : \"\"\"A fast duplicate file finder. This filter compares files byte by byte and finds identical files with potentially different filenames. Attributes: detect_original_by (str): Detection method to distinguish between original and duplicate. Possible values are: - `\"first_seen\"`: Whatever file is visited first is the original. This depends on the order of your location entries. - `\"name\"`: The first entry sorted by name is the original. - `\"created\"`: The first entry sorted by creation date is the original. - `\"lastmodified\"`: The first file sorted by date of last modification is the original. You can reverse the sorting method by prefixing a `-`. So with `detect_original_by: \"-created\"` the file with the older creation date is the original and the younger file is the duplicate. This works on all methods, for example `\"-first_seen\"`, `\"-name\"`, `\"-created\"`, `\"-lastmodified\"`. **Returns:** `{duplicate.original}` - The path to the original \"\"\" detect_original_by : DetectionMethod = \"first_seen\" hash_algorithm : str = \"sha1\" filter_config : ClassVar [ FilterConfig ] = FilterConfig ( name = \"duplicate\" , files = True , dirs = False ) def __post_init__ ( self ): # reverse original detection order if starting with \"-\" self . _detect_original_by = self . detect_original_by self . _detect_original_reverse = False if self . detect_original_by . startswith ( \"-\" ): self . _detect_original_by = self . detect_original_by [ 1 :] self . _detect_original_reverse = True self . _files_for_size = defaultdict ( list ) self . _files_for_chunk = defaultdict ( list ) self . _file_for_hash = dict () # we keep track of the files we already computed the hashes for so we only do # that once. self . _seen_files = set () self . _first_chunk_known = set () self . _hash_known = set () def pipeline ( self , res : Resource , output : Output ) -> bool : assert res . path is not None , \"Does not support standalone mode\" # skip symlinks if res . path . is_symlink (): return False # the exact same path has already been handled. This happens if multiple # locations emit this file in a single rule or if we follow symlinks. # We skip these. if res . path in self . _seen_files : return False self . _seen_files . add ( res . path ) # check for files with equal size file_size = read_file_size ( path = res . path ) same_size = self . _files_for_size [ file_size ] same_size . append ( res . path ) if len ( same_size ) == 1 : # the file is unique in size and cannot be a duplicate return False # for all other files with the same file size: # make sure we know their hash of their first 1024 byte chunk for f in same_size [: - 1 ]: if f not in self . _first_chunk_known : chunk_hash = hash_first_chunk ( f , algo = self . hash_algorithm ) self . _first_chunk_known . add ( f ) self . _files_for_chunk [ chunk_hash ] . append ( f ) # check first chunk hash collisions with the current file chunk_hash = hash_first_chunk ( res . path , algo = self . hash_algorithm ) same_first_chunk = self . _files_for_chunk [ chunk_hash ] same_first_chunk . append ( res . path ) self . _first_chunk_known . add ( res . path ) if len ( same_first_chunk ) == 1 : # the file has a unique small hash and cannot be a duplicate return False # Ensure we know the full hashes of all files with the same first chunk as # the investigated file for f in same_first_chunk [: - 1 ]: if f not in self . _hash_known : hash_ = hash ( f , algo = self . hash_algorithm ) self . _hash_known . add ( f ) self . _file_for_hash [ hash_ ] = f # check full hash collisions with the current file hash_ = hash ( res . path , algo = self . hash_algorithm ) self . _hash_known . add ( res . path ) known = self . _file_for_hash . get ( hash_ ) if known : original , duplicate = detect_original ( known = known , new = res . path , method = self . _detect_original_by , reverse = self . _detect_original_reverse , ) if known != original : self . _file_for_hash [ hash_ ] = original res . path = duplicate res . vars [ self . filter_config . name ] = { \"original\" : original } return True return False Examples: Show all duplicate files in your desktop and download folder (and their subfolders) rules: - name: Show all duplicate files in your desktop and download folder (and their subfolders) locations: - ~/Desktop - ~/Downloads subfolders: true filters: - duplicate actions: - echo: \"{path} is a duplicate of {duplicate.original}\" Check for duplicated files between Desktop and a Zip file, select original by creation date rules: - name: \"Check for duplicated files between Desktop and a Zip file, select original by creation date\" locations: - ~/Desktop - zip://~/Desktop/backup.zip filters: - duplicate: detect_original_by: \"created\" actions: - echo: \"Duplicate found!\" empty # Finds empty dirs and files Source code in organize/filters/empty.py 11 12 13 14 15 16 17 18 19 20 21 22 23 @dataclass ( config = ConfigDict ( extra = \"forbid\" )) class Empty : \"\"\"Finds empty dirs and files\"\"\" filter_config : ClassVar [ FilterConfig ] = FilterConfig ( name = \"empty\" , files = True , dirs = True , ) def pipeline ( self , res : Resource , output : Output ) -> bool : return res . is_empty () Examples: Recursively delete empty folders rules: - targets: dirs locations: - path: ~/Desktop max_depth: null filters: - empty actions: - delete exif # Filter by image EXIF data The exif filter can be used as a filter as well as a way to get exif information into your actions. By default this library uses the exifread library. If your image format is not supported you can install exiftool (exiftool.org) and set the environment variable: ORGANIZE_EXIFTOOL_PATH=\"exiftool\" organize will then use exiftool to extract the EXIF data. Exif fields which contain \"datetime\", \"date\" or \"offsettime\" in their fieldname will have their value converted to 'datetime.datetime', 'datetime.date' and 'datetime.timedelta' respectivly. - datetime.datetime : exif.image.datetime, exif.exif.datetimeoriginal, ... - datetime.date : exif.gps.date, ... - datetime.timedelta : exif.exif.offsettimeoriginal, exif.exif.offsettimedigitized, ... Attributes: lowercase_keys ( bool ) \u2013 Whether to lowercase all EXIF keys (Default: true) :returns: {exif} -- a dict of all the collected exif inforamtion available in the file. Typically it consists of the following tags (if present in the file): - ``{exif.image}`` -- information related to the main image - ``{exif.exif}`` -- Exif information - ``{exif.gps}`` -- GPS information - ``{exif.interoperability}`` -- Interoperability information Source code in organize/filters/exif.py 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 class Exif ( BaseModel ): \"\"\"Filter by image EXIF data The `exif` filter can be used as a filter as well as a way to get exif information into your actions. By default this library uses the `exifread` library. If your image format is not supported you can install `exiftool` (exiftool.org) and set the environment variable: ``` ORGANIZE_EXIFTOOL_PATH=\"exiftool\" ``` organize will then use `exiftool` to extract the EXIF data. Exif fields which contain \"datetime\", \"date\" or \"offsettime\" in their fieldname will have their value converted to 'datetime.datetime', 'datetime.date' and 'datetime.timedelta' respectivly. - `datetime.datetime` : exif.image.datetime, exif.exif.datetimeoriginal, ... - `datetime.date` : exif.gps.date, ... - `datetime.timedelta` : exif.exif.offsettimeoriginal, exif.exif.offsettimedigitized, ... Attributes: lowercase_keys (bool): Whether to lowercase all EXIF keys (Default: true) :returns: ``{exif}`` -- a dict of all the collected exif inforamtion available in the file. Typically it consists of the following tags (if present in the file): - ``{exif.image}`` -- information related to the main image - ``{exif.exif}`` -- Exif information - ``{exif.gps}`` -- GPS information - ``{exif.interoperability}`` -- Interoperability information \"\"\" filter_tags : Dict lowercase_keys : bool = True filter_config : ClassVar [ FilterConfig ] = FilterConfig ( name = \"exif\" , files = True , dirs = False , ) def __init__ ( self , * args , filter_tags : Optional [ Dict ] = None , lowercase_keys : bool = True , ** kwargs , ): # exif filter is used differently from other filters. The **kwargs are not # filter parameters but all belong into the filter_tags dictionary to filter # for specific exif tags. params = filter_tags or dict () params . update ( kwargs ) # *args are tags filtered without a value, like [\"gps\", \"image.model\"]. for arg in args : params [ arg ] = None super () . __init__ ( filter_tags = params , lowercase_keys = lowercase_keys ) def pipeline ( self , res : Resource , output : Output ) -> bool : assert res . path is not None , \"Does not support standalone mode\" # gather the exif data in a dict if exiftool_available (): data = exiftool_read ( path = res . path ) else : data = exifread_read ( path = res . path ) # lowercase keys if wanted if self . lowercase_keys : data = lowercase_keys_recursive ( data ) # convert strings to datetime objects where possible parsed = convert_recursive ( data ) res . vars [ self . filter_config . name ] = parsed return matches_tags ( self . filter_tags , data ) Show available EXIF data of your pictures rules: - name: \"Show available EXIF data of your pictures\" locations: - path: ~/Pictures max_depth: null filters: - exif actions: - echo: \"{exif}\" Copy all images which contain GPS information while keeping subfolder structure: rules: - name: \"GPS demo\" locations: - path: ~/Pictures max_depth: null filters: - exif: gps.gpsdate actions: - copy: ~/Pictures/with_gps/{relative_path}/ Filter by camera manufacturer rules: - name: \"Filter by camera manufacturer\" locations: - path: ~/Pictures max_depth: null filters: - exif: image.model: Nikon D3200 actions: - move: \"~/Pictures/My old Nikon/\" Sort images by camera manufacturer. This will create folders for each camera model (for example \"Nikon D3200\", \"iPhone 6s\", \"iPhone 5s\", \"DMC-GX80\") and move the pictures accordingly: rules: - name: \"camera sort\" locations: - path: ~/Pictures max_depth: null filters: - extension: jpg - exif: image.model actions: - move: \"~/Pictures/{exif.image.model}/\" extension # Filter by file extension Attributes: *extensions ( list ( str ) or str ) \u2013 The file extensions to match (does not need to start with a colon). Returns: {extension} : the original file extension (without colon) Source code in organize/filters/extension.py 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 @dataclass ( config = ConfigDict ( coerce_numbers_to_str = True , extra = \"forbid\" )) class Extension : \"\"\"Filter by file extension Attributes: *extensions (list(str) or str): The file extensions to match (does not need to start with a colon). **Returns:** - `{extension}`: the original file extension (without colon) \"\"\" extensions : Set [ str ] = Field ( default_factory = set ) filter_config : ClassVar [ FilterConfig ] = FilterConfig ( name = \"extension\" , files = True , dirs = False , ) @field_validator ( \"extensions\" , mode = \"before\" ) def normalize_extensions ( cls , v ): as_list = convert_to_list ( v ) return set ( map ( normalize_extension , flatten ( list ( as_list )))) def suffix_match ( self , path : Path ) -> Tuple [ str , bool ]: suffix = path . suffix . lstrip ( \".\" ) if not self . extensions : return ( suffix , True ) if not suffix : return ( suffix , False ) return ( suffix , normalize_extension ( suffix ) in self . extensions ) def pipeline ( self , res : Resource , output : Output ) -> bool : assert res . path is not None , \"Does not support standalone mode\" if res . is_dir (): raise ValueError ( \"Dirs not supported\" ) suffix , match = self . suffix_match ( path = res . path ) res . vars [ self . filter_config . name ] = suffix return match Examples: Match a single file extension rules: - name: \"Match a single file extension\" locations: \"~/Desktop\" filters: - extension: png actions: - echo: \"Found PNG file: {path}\" Match multiple file extensions rules: - name: \"Match multiple file extensions\" locations: \"~/Desktop\" filters: - extension: - .jpg - jpeg actions: - echo: \"Found JPG file: {path}\" Make all file extensions lowercase rules: - name: \"Make all file extensions lowercase\" locations: \"~/Desktop\" filters: - extension actions: - rename: \"{path.stem}.{extension.lower()}\" Using extension lists ( yaml aliases img_ext: &img - png - jpg - tiff audio_ext: &audio - mp3 - wav - ogg rules: - name: \"Using extension lists\" locations: \"~/Desktop\" filters: - extension: - *img - *audio actions: - echo: \"Found media file: {path}\" filecontent # Matches file content with the given regular expression. Supports .md, .txt, .log, .pdf and .docx files. For PDF content extraction poppler should be installed for the pdftotext command. If this is not available filecontent will fall back to the pdfminer library. Attributes: expr ( str ) \u2013 The regular expression to be matched. Any named groups ( (?P<groupname>.*) ) in your regular expression will be returned like this: Returns: {filecontent.groupname} : The text matched with the named group (?P<groupname>) You can test the filter on any file by running: python -m organize.filters.filecontent \"/path/to/file.pdf\" Source code in organize/filters/filecontent.py 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 @dataclass ( config = ConfigDict ( coerce_numbers_to_str = True , extra = \"forbid\" )) class FileContent : \"\"\"Matches file content with the given regular expression. Supports .md, .txt, .log, .pdf and .docx files. For PDF content extraction poppler should be installed for the `pdftotext` command. If this is not available `filecontent` will fall back to the `pdfminer` library. Attributes: expr (str): The regular expression to be matched. Any named groups (`(?P<groupname>.*)`) in your regular expression will be returned like this: **Returns:** - `{filecontent.groupname}`: The text matched with the named group `(?P<groupname>)` You can test the filter on any file by running: ```sh python -m organize.filters.filecontent \"/path/to/file.pdf\" ``` \"\"\" expr : str = r \"(?P<all>.*)\" filter_config : ClassVar [ FilterConfig ] = FilterConfig ( name = \"filecontent\" , files = True , dirs = False , ) def __post_init__ ( self ): self . _expr = re . compile ( self . expr , re . MULTILINE | re . DOTALL ) def matches ( self , path : Path ) -> Union [ re . Match , None ]: try : content = textract ( path ) match = self . _expr . search ( content ) return match except Exception : return None def pipeline ( self , res : Resource , output : Output ) -> bool : assert res . path is not None , \"Does not support standalone mode\" match = self . matches ( path = res . path ) if match : res . deep_merge ( self . filter_config . name , match . groupdict ()) return bool ( match ) Examples: Show the content of all your PDF files rules: - name: \"Show the content of all your PDF files\" locations: ~/Documents filters: - extension: pdf - filecontent actions: - echo: \"{filecontent}\" Match an invoice with a regular expression and sort by customer rules: - name: \"Match an invoice with a regular expression and sort by customer\" locations: \"~/Desktop\" filters: - filecontent: 'Invoice.*Customer (?P<customer>\\w+)' actions: - move: \"~/Documents/Invoices/{filecontent.customer}/\" Exampe to filter the filename with respect to a valid date code. The filename should start with <year>-<month>-<day> . Regex: creates a placeholder variable containing the year allows only years which start with 20 and are followed by 2 numbers months can only have as first digit 0 or 1 and must be followed by a number days can only have 0, 1,2 or 3 and must followed by number Note: Filter is not perfect but still. rules: - locations: ~/Desktop filters: - regex: '(?P<year>20\\d{2})-[01]\\d-[0123]\\d.*' actions: - echo: \"Year: {regex.year}\" Note If you have trouble getting the filecontent filter to work, have a look at the installation hints hash # Calculates the hash of a file. Attributes: algorithm ( str ) \u2013 Any hashing algorithm available to python's hashlib . md5 by default. Algorithms guaranteed to be available are shake_256 , sha3_256 , sha1 , sha3_224 , sha384 , sha512 , blake2b , blake2s , sha256 , sha224 , shake_128 , sha3_512 , sha3_384 and md5 . Depending on your python installation and installed libs there may be additional hash algorithms to chose from. To list the available algorithms on your installation run this in a python interpreter: >>> import hashlib >>> hashlib.algorithms_available {'shake_256', 'whirlpool', 'mdc2', 'blake2s', 'sha224', 'shake_128', 'sha3_512', 'sha3_224', 'sha384', 'md5', 'sha1', 'sha512_256', 'blake2b', 'sha256', 'sha512_224', 'ripemd160', 'sha3_384', 'md4', 'sm3', 'sha3_256', 'md5-sha1', 'sha512'} Returns: {hash} : The hash of the file. Source code in organize/filters/hash.py 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 @dataclass ( config = ConfigDict ( extra = \"forbid\" )) class Hash : \"\"\"Calculates the hash of a file. Attributes: algorithm (str): Any hashing algorithm available to python's `hashlib`. `md5` by default. Algorithms guaranteed to be available are `shake_256`, `sha3_256`, `sha1`, `sha3_224`, `sha384`, `sha512`, `blake2b`, `blake2s`, `sha256`, `sha224`, `shake_128`, `sha3_512`, `sha3_384` and `md5`. Depending on your python installation and installed libs there may be additional hash algorithms to chose from. To list the available algorithms on your installation run this in a python interpreter: ```py >>> import hashlib >>> hashlib.algorithms_available {'shake_256', 'whirlpool', 'mdc2', 'blake2s', 'sha224', 'shake_128', 'sha3_512', 'sha3_224', 'sha384', 'md5', 'sha1', 'sha512_256', 'blake2b', 'sha256', 'sha512_224', 'ripemd160', 'sha3_384', 'md4', 'sm3', 'sha3_256', 'md5-sha1', 'sha512'} ``` **Returns:** - `{hash}`: The hash of the file. \"\"\" algorithm : str = \"md5\" filter_config : ClassVar [ FilterConfig ] = FilterConfig ( name = \"hash\" , files = True , dirs = False , ) def __post_init__ ( self ): self . _algorithm = Template . from_string ( self . algorithm ) def pipeline ( self , res : Resource , output : Output ) -> bool : assert res . path is not None algo = render ( self . _algorithm , res . dict ()) . lower () result = hash ( path = res . path , algo = algo ) res . vars [ self . filter_config . name ] = result return True Examples: Show the hashes of your files: rules: - name: \"Show the hashes and size of your files\" locations: \"~/Desktop\" filters: - hash - size actions: - echo: \"{hash} {size.decimal}\" lastmodified # Matches files by last modified date Attributes: years ( int ) \u2013 specify number of years months ( int ) \u2013 specify number of months weeks ( float ) \u2013 specify number of weeks days ( float ) \u2013 specify number of days hours ( float ) \u2013 specify number of hours minutes ( float ) \u2013 specify number of minutes seconds ( float ) \u2013 specify number of seconds mode ( str ) \u2013 either 'older' or 'newer'. 'older' matches files / folders last modified before the given time, 'newer' matches files / folders last modified within the given time. (default = 'older') Returns: \u2013 {lastmodified}: The datetime the files / folders was lastmodified. Source code in organize/filters/lastmodified.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 class LastModified ( TimeFilter ): \"\"\"Matches files by last modified date Attributes: years (int): specify number of years months (int): specify number of months weeks (float): specify number of weeks days (float): specify number of days hours (float): specify number of hours minutes (float): specify number of minutes seconds (float): specify number of seconds mode (str): either 'older' or 'newer'. 'older' matches files / folders last modified before the given time, 'newer' matches files / folders last modified within the given time. (default = 'older') Returns: {lastmodified}: The datetime the files / folders was lastmodified. \"\"\" filter_config : ClassVar [ FilterConfig ] = FilterConfig ( name = \"lastmodified\" , files = True , dirs = True , ) def get_datetime ( self , path : Path ) -> datetime : return read_lastmodified ( path ) Examples: rules: - name: \"Show all files on your desktop last modified at least 10 days ago\" locations: \"~/Desktop\" filters: - lastmodified: days: 10 actions: - echo: \"Was modified at least 10 days ago\" Show all files on your desktop which were modified within the last 5 hours: rules: - locations: \"~/Desktop\" filters: - lastmodified: hours: 5 mode: newer actions: - echo: \"Was modified within the last 5 hours\" Sort pdfs by year of last modification rules: - name: \"Sort pdfs by year of last modification\" locations: \"~/Documents\" filters: - extension: pdf - lastmodified actions: - move: \"~/Documents/PDF/{lastmodified.year}/\" Formatting the last modified date rules: - name: Formatting the lastmodified date locations: \"~/Documents\" filters: - extension: pdf - lastmodified actions: - echo: \"ISO Format: {lastmodified.strftime('%Y-%m-%d')}\" - echo: \"As timestamp: {lastmodified.timestamp() | int}\" macos_tags # Filter by macOS tags Attributes: tags ( list ( str ) or str ) \u2013 The tags to filter by Source code in organize/filters/macos_tags.py 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 @dataclass ( config = ConfigDict ( coerce_numbers_to_str = True , extra = \"forbid\" )) class MacOSTags : \"\"\"Filter by macOS tags Attributes: tags (list(str) or str): The tags to filter by \"\"\" tags : List [ str ] = Field ( default_factory = list ) filter_config : ClassVar [ FilterConfig ] = FilterConfig ( name = \"macos_tags\" , files = True , dirs = True , ) def __post_init__ ( self ): if sys . platform != \"darwin\" : raise EnvironmentError ( \"The macos_tags filter is only available on macOS\" ) @field_validator ( \"tags\" , mode = \"before\" ) def ensure_list ( cls , v ): if isinstance ( v , str ): return [ v ] return v def pipeline ( self , res : Resource , output : Output ) -> bool : file_tags = list_tags ( res . path ) res . vars [ self . filter_config . name ] = file_tags return matches_tags ( filter_tags = self . tags , file_tags = file_tags ) Examples: rules: - name: \"Only files with a red macOS tag\" locations: \"~/Downloads\" filters: - macos_tags: \"* (red)\" actions: - echo: \"File with red tag\" rules: - name: \"All files tagged 'Invoice' (any color)\" locations: \"~/Downloads\" filters: - macos_tags: \"Invoice (*)\" actions: - echo: \"Invoice found\" rules: - name: \"All files with a tag 'Invoice' (any color) or with a green tag\" locations: \"~/Downloads\" filters: - macos_tags: - \"Invoice (*)\" - \"* (green)\" actions: - echo: \"Match found!\" rules: - name: \"Listing file tags\" locations: \"~/Downloads\" filters: - macos_tags actions: - echo: \"{macos_tags}\" mimetype # Filter by MIME type associated with the file extension. Supports a single string or list of MIME type strings as argument. The types don't need to be fully specified, for example \"audio\" matches everything from \"audio/midi\" to \"audio/quicktime\". You can see a list of known MIME types on your system by running this oneliner: python3 -m organize.filters.mimetype Attributes: *mimetypes ( list ( str ) or str ) \u2013 The MIME types to filter for. Returns: {mimetype} : The MIME type of the file. Source code in organize/filters/mimetype.py 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 @dataclass ( config = ConfigDict ( coerce_numbers_to_str = True , extra = \"forbid\" )) class MimeType : \"\"\"Filter by MIME type associated with the file extension. Supports a single string or list of MIME type strings as argument. The types don't need to be fully specified, for example \"audio\" matches everything from \"audio/midi\" to \"audio/quicktime\". You can see a list of known MIME types on your system by running this oneliner: ```sh python3 -m organize.filters.mimetype ``` Attributes: *mimetypes (list(str) or str): The MIME types to filter for. **Returns:** - `{mimetype}`: The MIME type of the file. \"\"\" mimetypes : FlatList [ str ] = Field ( default_factory = list ) filter_config : ClassVar [ FilterConfig ] = FilterConfig ( name = \"mimetype\" , files = True , dirs = False , ) def matches ( self , mimetype ) -> bool : if mimetype is None : return False if not self . mimetypes : return True return any ( mimetype . startswith ( x ) for x in self . mimetypes ) def pipeline ( self , res : Resource , output : Output ) -> bool : mimetype = guess_mimetype ( res . path ) res . vars [ self . filter_config . name ] = mimetype return self . matches ( mimetype ) Examples: Show MIME types rules: - name: \"Show MIME types\" locations: \"~/Downloads\" filters: - mimetype actions: - echo: \"{mimetype}\" Filter by 'image' mimetype rules: - name: \"Filter by 'image' mimetype\" locations: \"~/Downloads\" filters: - mimetype: image actions: - echo: \"This file is an image: {mimetype}\" Filter by specific MIME type rules: - name: Filter by specific MIME type locations: \"~/Desktop\" filters: - mimetype: application/pdf actions: - echo: \"Found a PDF file\" Filter by multiple specific MIME types rules: - name: Filter by multiple specific MIME types locations: \"~/Music\" filters: - mimetype: - application/pdf - audio/midi actions: - echo: \"Found Midi or PDF.\" name # Match files and folders by name Attributes: match ( str ) \u2013 A matching string in simplematch-syntax startswith ( str ) \u2013 The filename must begin with the given string contains ( str ) \u2013 The filename must contain the given string endswith ( str ) \u2013 The filename (without extension) must end with the given string case_sensitive ( bool ) \u2013 By default, the matching is case sensitive. Change this to False to use case insensitive matching. Source code in organize/filters/name.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 @dataclass ( config = ConfigDict ( coerce_numbers_to_str = True , extra = \"forbid\" )) class Name : \"\"\"Match files and folders by name Attributes: match (str): A matching string in [simplematch-syntax](https://github.com/tfeldmann/simplematch) startswith (str): The filename must begin with the given string contains (str): The filename must contain the given string endswith (str): The filename (without extension) must end with the given string case_sensitive (bool): By default, the matching is case sensitive. Change this to False to use case insensitive matching. \"\"\" match : str = \"*\" startswith : Union [ str , List [ str ]] = \"\" contains : Union [ str , List [ str ]] = \"\" endswith : Union [ str , List [ str ]] = \"\" case_sensitive : bool = True filter_config : ClassVar [ FilterConfig ] = FilterConfig ( name = \"name\" , files = True , dirs = True , ) def __post_init__ ( self , * args , ** kwargs ): self . _matcher = simplematch . Matcher ( self . match , case_sensitive = self . case_sensitive , ) self . startswith = self . create_list ( self . startswith , self . case_sensitive ) self . contains = self . create_list ( self . contains , self . case_sensitive ) self . endswith = self . create_list ( self . endswith , self . case_sensitive ) def matches ( self , name : str ) -> bool : if not self . case_sensitive : name = name . lower () is_match = ( self . _matcher . test ( name ) and any ( x in name for x in self . contains ) and any ( name . startswith ( x ) for x in self . startswith ) and any ( name . endswith ( x ) for x in self . endswith ) ) return is_match def pipeline ( self , res : Resource , output : Output ) -> bool : assert res . path is not None , \"Does not support standalone mode\" if res . is_dir (): name = res . path . stem else : name , ext = res . path . stem , res . path . suffix if not name : name = ext result = self . matches ( normalize_unicode ( name )) m = self . _matcher . match ( normalize_unicode ( name )) if not m : m = name res . vars [ self . filter_config . name ] = m return result @staticmethod def create_list ( x : Union [ int , str , List [ Any ]], case_sensitive : bool ) -> List [ str ]: if isinstance ( x , ( int , float )): x = str ( x ) if isinstance ( x , str ): x = [ x ] x = [ str ( x ) for x in x ] if not case_sensitive : x = [ x . lower () for x in x ] return x Examples: Match all files starting with 'Invoice': rules: - locations: \"~/Desktop\" filters: - name: startswith: Invoice actions: - echo: \"This is an invoice\" Match all files starting with 'A' end containing the string 'hole' (case insensitive): rules: - locations: \"~/Desktop\" filters: - name: startswith: A contains: hole case_sensitive: false actions: - echo: \"Found a match.\" Match all files starting with 'A' or 'B' containing '5' or '6' and ending with '_end': rules: - locations: \"~/Desktop\" filters: - name: startswith: - \"A\" - \"B\" contains: - \"5\" - \"6\" endswith: _end case_sensitive: false actions: - echo: \"Found a match.\" python # Use python code to filter files. Attributes: code ( str ) \u2013 The python code to execute. The code must contain a return statement. Returns: If your code returns False or None the file is filtered out, otherwise the file is passed on to the next filters. {python} contains the returned value. If you return a dictionary (for example return {\"some_key\": some_value, \"nested\": {\"k\": 2}} ) it will be accessible via dot syntax actions: {python.some_key} , {python.nested.k} . Variables of previous filters are available, but you have to use the normal python dictionary syntax x = regex[\"my_group\"] . Source code in organize/filters/python.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 @dataclass ( config = ConfigDict ( coerce_numbers_to_str = True , extra = \"forbid\" )) class Python : \"\"\"Use python code to filter files. Attributes: code (str): The python code to execute. The code must contain a `return` statement. **Returns:** - If your code returns `False` or `None` the file is filtered out, otherwise the file is passed on to the next filters. - `{python}` contains the returned value. If you return a dictionary (for example `return {\"some_key\": some_value, \"nested\": {\"k\": 2}}`) it will be accessible via dot syntax actions: `{python.some_key}`, `{python.nested.k}`. - Variables of previous filters are available, but you have to use the normal python dictionary syntax `x = regex[\"my_group\"]`. \"\"\" code : str filter_config : ClassVar [ FilterConfig ] = FilterConfig ( name = \"python\" , files = True , dirs = True , ) @field_validator ( \"code\" , mode = \"after\" ) @classmethod def must_have_return_statement ( cls , value ): if \"return\" not in value : raise ValueError ( \"No return statement found in your code!\" ) return value def __post_init__ ( self ): self . code = textwrap . dedent ( self . code ) def __usercode__ ( self , print , ** kwargs ) -> Optional [ Dict ]: raise NotImplementedError () def pipeline ( self , res : Resource , output : Output ) -> bool : def _output_msg ( * values , sep : str = \" \" , end : str = \"\" ): \"\"\" the print function for the use code needs to print via the current output \"\"\" output . msg ( res = res , msg = f \" { sep . join ( str ( x ) for x in values ) }{ end } \" , sender = \"python\" , ) # codegen the user function with arguments as available in the resource kwargs = \", \" . join ( res . dict () . keys ()) func = f \"def __userfunc(print, { kwargs } ): \\n \" func += textwrap . indent ( self . code , \" \" ) func += \" \\n\\n self.__usercode__ = __userfunc\" exec ( func , globals () . copy (), locals () . copy ()) result = self . __usercode__ ( print = _output_msg , ** res . dict ()) if isinstance ( result , dict ): res . deep_merge ( key = self . filter_config . name , data = result ) else : res . vars [ self . filter_config . name ] = result return result not in ( False , None ) Examples: rules: - name: A file name reverser. locations: ~/Documents filters: - extension - python: | return {\"reversed_name\": path.stem[::-1]} actions: - rename: \"{python.reversed_name}.{extension}\" A filter for odd student numbers. Assuming the folder ~/Students contains the files student-01.jpg , student-01.txt , student-02.txt and student-03.txt this rule will print \"Odd student numbers: student-01.txt\" and \"Odd student numbers: student-03.txt\" rules: - name: \"Filter odd student numbers\" locations: ~/Students/ filters: - python: | return int(path.stem.split('-')[1]) % 2 == 1 actions: - echo: \"Odd student numbers: {path.name}\" Advanced usecase. You can access data from previous filters in your python code. This can be used to match files and capturing names with a regular expression and then renaming the files with the output of your python script. rules: - name: \"Access placeholders in python filter\" locations: files filters: - extension: txt - regex: (?P<firstname>\\w+)-(?P<lastname>\\w+)\\..* - python: | emails = { \"Betts\": \"dbetts@mail.de\", \"Cornish\": \"acornish@google.com\", \"Bean\": \"dbean@aol.com\", \"Frey\": \"l-frey@frey.org\", } if regex.lastname in emails: # get emails from wherever return {\"mail\": emails[regex.lastname]} actions: - rename: \"{python.mail}.txt\" Result: Devonte-Betts.txt becomes dbetts@mail.de.txt Alaina-Cornish.txt becomes acornish@google.com.txt Dimitri-Bean.txt becomes dbean@aol.com.txt Lowri-Frey.txt becomes l-frey@frey.org.txt Someunknown-User.txt remains unchanged because the email is not found regex # Matches filenames with the given regular expression Attributes: expr ( str ) \u2013 The regular expression to be matched. Returns: Any named groups in your regular expression will be returned like this: {regex.groupname} : The text matched with the named group (?P<groupname>.*) Source code in organize/filters/regex.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 @dataclass ( config = ConfigDict ( coerce_numbers_to_str = True , extra = \"forbid\" )) class Regex : \"\"\"Matches filenames with the given regular expression Attributes: expr (str): The regular expression to be matched. **Returns:** Any named groups in your regular expression will be returned like this: - `{regex.groupname}`: The text matched with the named group `(?P<groupname>.*)` \"\"\" expr : str filter_config : ClassVar [ FilterConfig ] = FilterConfig ( name = \"regex\" , files = True , dirs = True , ) def __post_init__ ( self ): self . _expr = re . compile ( self . expr , flags = re . UNICODE ) def matches ( self , path : str ): return self . _expr . search ( path ) def pipeline ( self , res : Resource , output : Output ) -> bool : assert res . path is not None , \"Does not support standalone mode\" match = self . matches ( normalize_unicode ( res . path . name )) if match : res . deep_merge ( key = self . filter_config . name , data = match . groupdict ()) return True return False Examples: Match an invoice with a regular expression: rules: - locations: \"~/Desktop\" filters: - regex: '^RG(\\d{12})-sig\\.pdf$' actions: - move: \"~/Documents/Invoices/1und1/\" Match and extract data from filenames with regex named groups: This is just like the previous example but we rename the invoice using the invoice number extracted via the regular expression and the named group the_number . rules: - locations: ~/Desktop filters: - regex: '^RG(?P<the_number>\\d{12})-sig\\.pdf$' actions: - move: ~/Documents/Invoices/1und1/{regex.the_number}.pdf size # Matches files and folders by size Attributes: *conditions ( list ( str ) or str ) \u2013 The size constraints. Accepts file size conditions, e.g: \">= 500 MB\" , \"< 20k\" , \">0\" , \"= 10 KiB\" . It is possible to define both lower and upper conditions like this: \">20k, < 1 TB\" , \">= 20 Mb, <25 Mb\" . The filter will match if all given conditions are satisfied. Accepts all units from KB to YB. If no unit is given, kilobytes are assumend. If binary prefix is given (KiB, GiB) the size is calculated using base 1024. Returns: {size.bytes} : (int) Size in bytes {size.traditional} : (str) Size with unit (powers of 1024, JDEC prefixes) {size.binary} : (str) Size with unit (powers of 1024, IEC prefixes) {size.decimal} : (str) Size with unit (powers of 1000, SI prefixes) Source code in organize/filters/size.py 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 @dataclass ( config = ConfigDict ( coerce_numbers_to_str = True , extra = \"forbid\" )) class Size : \"\"\"Matches files and folders by size Attributes: *conditions (list(str) or str): The size constraints. Accepts file size conditions, e.g: `\">= 500 MB\"`, `\"< 20k\"`, `\">0\"`, `\"= 10 KiB\"`. It is possible to define both lower and upper conditions like this: `\">20k, < 1 TB\"`, `\">= 20 Mb, <25 Mb\"`. The filter will match if all given conditions are satisfied. - Accepts all units from KB to YB. - If no unit is given, kilobytes are assumend. - If binary prefix is given (KiB, GiB) the size is calculated using base 1024. **Returns:** - `{size.bytes}`: (int) Size in bytes - `{size.traditional}`: (str) Size with unit (powers of 1024, JDEC prefixes) - `{size.binary}`: (str) Size with unit (powers of 1024, IEC prefixes) - `{size.decimal}`: (str) Size with unit (powers of 1000, SI prefixes) \"\"\" conditions : FlatList [ str ] = Field ( default_factory = list ) filter_config : ClassVar [ FilterConfig ] = FilterConfig ( name = \"size\" , files = True , dirs = True ) def __post_init__ ( self ): self . _constraints = set () for x in self . conditions : for constraint in create_constraints ( x ): self . _constraints . add ( constraint ) def matches ( self , filesize : int ) -> bool : if not self . _constraints : return True return all ( op ( filesize , c_size ) for op , c_size in self . _constraints ) def pipeline ( self , res : Resource , output : Output ) -> bool : assert res . path is not None bytes = read_resource_size ( res = res ) res . vars [ self . filter_config . name ] = { \"bytes\" : bytes , \"traditional\" : traditional ( bytes ), \"binary\" : binary ( bytes ), \"decimal\" : decimal ( bytes ), } return self . matches ( bytes ) Examples: Trash big downloads: rules: - locations: \"~/Downloads\" targets: files filters: - size: \"> 0.5 GB\" actions: - trash Move all JPEGS bigger > 1MB and <10 MB. Search all subfolders and keep the original relative path. rules: - locations: - path: \"~/Pictures\" max_depth: null filters: - extension: - jpg - jpeg - size: \">1mb, <10mb\" actions: - move: \"~/Pictures/sorted/{relative_path}/\"","title":"Filters"},{"location":"filters/#filters","text":"This page shows the specifics of each filter.","title":"Filters"},{"location":"filters/#-how-to-exclude-filters-","text":"To exclude a filter, prefix the filter name with not (e.g. \"not empty\" , \"not extension\": jpg , etc). Note If you want to exclude all filters you can set the rule's filter_mode to none . Example: rules: # using filter_mode - locations: ~/Desktop filter_mode: \"none\" # <- excludes all filters: - empty - name: endswith: \"2022\" actions: - echo: \"{name}\" # Exclude a single filter - locations: ~/Desktop filters: - not extension: jpg # <- matches all non-jpgs - name: startswith: \"Invoice\" - not empty # <- matches files with content actions: - echo: \"{name}\"","title":"- How to exclude filters -"},{"location":"filters/#created","text":"Matches files / folders by created date Attributes: years ( int ) \u2013 specify number of years months ( int ) \u2013 specify number of months weeks ( float ) \u2013 specify number of weeks days ( float ) \u2013 specify number of days hours ( float ) \u2013 specify number of hours minutes ( float ) \u2013 specify number of minutes seconds ( float ) \u2013 specify number of seconds mode ( str ) \u2013 either 'older' or 'newer'. 'older' matches files / folders created before the given time, 'newer' matches files / folders created within the given time. (default = 'older') Returns: \u2013 {created} (datetime): The datetime the file / folder was created. Source code in organize/filters/created.py 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 class Created ( TimeFilter ): \"\"\"Matches files / folders by created date Attributes: years (int): specify number of years months (int): specify number of months weeks (float): specify number of weeks days (float): specify number of days hours (float): specify number of hours minutes (float): specify number of minutes seconds (float): specify number of seconds mode (str): either 'older' or 'newer'. 'older' matches files / folders created before the given time, 'newer' matches files / folders created within the given time. (default = 'older') Returns: `{created}` (datetime): The datetime the file / folder was created. \"\"\" filter_config : ClassVar [ FilterConfig ] = FilterConfig ( name = \"created\" , files = True , dirs = True , ) def get_datetime ( self , path : Path ) -> datetime : return read_created ( path ) Examples: Show all files on your desktop created at least 10 days ago rules: - name: Show all files on your desktop created at least 10 days ago locations: \"~/Desktop\" filters: - created: days: 10 actions: - echo: \"Was created at least 10 days ago\" Show all files on your desktop which were created within the last 5 hours rules: - name: Show all files on your desktop which were created within the last 5 hours locations: \"~/Desktop\" filters: - created: hours: 5 mode: newer actions: - echo: \"Was created within the last 5 hours\" Sort pdfs by year of creation rules: - name: Sort pdfs by year of creation locations: \"~/Documents\" filters: - extension: pdf - created actions: - move: \"~/Documents/PDF/{created.year}/\" Formatting the creation date rules: - name: Display the creation date locations: \"~/Documents\" filters: - extension: pdf - created actions: - echo: \"ISO Format: {created.strftime('%Y-%m-%d')}\" - echo: \"As timestamp: {created.timestamp() | int}\"","title":"created"},{"location":"filters/#date_added","text":"Matches files by the time the file was added to a folder. date_added is only available on macOS! Attributes: years ( int ) \u2013 specify number of years months ( int ) \u2013 specify number of months weeks ( float ) \u2013 specify number of weeks days ( float ) \u2013 specify number of days hours ( float ) \u2013 specify number of hours minutes ( float ) \u2013 specify number of minutes seconds ( float ) \u2013 specify number of seconds mode ( str ) \u2013 either 'older' or 'newer'. 'older' matches files / folders last modified before the given time, 'newer' matches files / folders last modified within the given time. (default = 'older') Returns: \u2013 {date_added} : The datetime the files / folders were added. Source code in organize/filters/date_added.py 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 class DateAdded ( TimeFilter ): \"\"\"Matches files by the time the file was added to a folder. **`date_added` is only available on macOS!** Attributes: years (int): specify number of years months (int): specify number of months weeks (float): specify number of weeks days (float): specify number of days hours (float): specify number of hours minutes (float): specify number of minutes seconds (float): specify number of seconds mode (str): either 'older' or 'newer'. 'older' matches files / folders last modified before the given time, 'newer' matches files / folders last modified within the given time. (default = 'older') Returns: `{date_added}`: The datetime the files / folders were added. \"\"\" filter_config : ClassVar [ FilterConfig ] = FilterConfig ( name = \"date_added\" , files = True , dirs = True , ) def __post_init__ ( self ): if sys . platform != \"darwin\" : raise EnvironmentError ( \"date_added is only available on macOS\" ) return super () . __post_init__ () def get_datetime ( self , path : Path ) -> datetime : return read_date_added ( path ) Works the same way as created and lastmodified . ** Examples ** rules: - name: Show the date the file was added to the folder locations: \"~/Desktop\" filters: - date_added actions: - echo: \"Date added: {date_added.strftime('%Y-%m-%d')}\"","title":"date_added"},{"location":"filters/#date_lastused","text":"Matches files by the time the file was last used. date_lastused is only available on macOS! Attributes: years ( int ) \u2013 specify number of years months ( int ) \u2013 specify number of months weeks ( float ) \u2013 specify number of weeks days ( float ) \u2013 specify number of days hours ( float ) \u2013 specify number of hours minutes ( float ) \u2013 specify number of minutes seconds ( float ) \u2013 specify number of seconds mode ( str ) \u2013 either 'older' or 'newer'. 'older' matches files / folders last used before the given time, 'newer' matches files / folders last used within the given time. (default = 'older') Returns: \u2013 {date_lastused}: The datetime the files / folders were added. Source code in organize/filters/date_lastused.py 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 class DateLastUsed ( TimeFilter ): \"\"\"Matches files by the time the file was last used. **`date_lastused` is only available on macOS!** Attributes: years (int): specify number of years months (int): specify number of months weeks (float): specify number of weeks days (float): specify number of days hours (float): specify number of hours minutes (float): specify number of minutes seconds (float): specify number of seconds mode (str): either 'older' or 'newer'. 'older' matches files / folders last used before the given time, 'newer' matches files / folders last used within the given time. (default = 'older') Returns: {date_lastused}: The datetime the files / folders were added. \"\"\" filter_config : ClassVar [ FilterConfig ] = FilterConfig ( name = \"date_lastused\" , files = True , dirs = True , ) def __post_init__ ( self ): if sys . platform != \"darwin\" : raise EnvironmentError ( \"date_added is only available on macOS\" ) return super () . __post_init__ () def get_datetime ( self , path : Path ) -> datetime : return read_date_lastused ( path ) Works the same way as created and lastmodified . ** Examples ** rules: - name: Show the date the file was added to the folder locations: \"~/Desktop\" filters: - date_lastused actions: - echo: \"Date last used: {date_lastused.strftime('%Y-%m-%d')}\"","title":"date_lastused"},{"location":"filters/#duplicate","text":"A fast duplicate file finder. This filter compares files byte by byte and finds identical files with potentially different filenames. Attributes: detect_original_by ( str ) \u2013 Detection method to distinguish between original and duplicate. Possible values are: \"first_seen\" : Whatever file is visited first is the original. This depends on the order of your location entries. \"name\" : The first entry sorted by name is the original. \"created\" : The first entry sorted by creation date is the original. \"lastmodified\" : The first file sorted by date of last modification is the original. You can reverse the sorting method by prefixing a - . So with detect_original_by: \"-created\" the file with the older creation date is the original and the younger file is the duplicate. This works on all methods, for example \"-first_seen\" , \"-name\" , \"-created\" , \"-lastmodified\" . Returns: {duplicate.original} - The path to the original Source code in organize/filters/duplicate.py 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 @dataclass ( config = ConfigDict ( extra = \"forbid\" )) class Duplicate : \"\"\"A fast duplicate file finder. This filter compares files byte by byte and finds identical files with potentially different filenames. Attributes: detect_original_by (str): Detection method to distinguish between original and duplicate. Possible values are: - `\"first_seen\"`: Whatever file is visited first is the original. This depends on the order of your location entries. - `\"name\"`: The first entry sorted by name is the original. - `\"created\"`: The first entry sorted by creation date is the original. - `\"lastmodified\"`: The first file sorted by date of last modification is the original. You can reverse the sorting method by prefixing a `-`. So with `detect_original_by: \"-created\"` the file with the older creation date is the original and the younger file is the duplicate. This works on all methods, for example `\"-first_seen\"`, `\"-name\"`, `\"-created\"`, `\"-lastmodified\"`. **Returns:** `{duplicate.original}` - The path to the original \"\"\" detect_original_by : DetectionMethod = \"first_seen\" hash_algorithm : str = \"sha1\" filter_config : ClassVar [ FilterConfig ] = FilterConfig ( name = \"duplicate\" , files = True , dirs = False ) def __post_init__ ( self ): # reverse original detection order if starting with \"-\" self . _detect_original_by = self . detect_original_by self . _detect_original_reverse = False if self . detect_original_by . startswith ( \"-\" ): self . _detect_original_by = self . detect_original_by [ 1 :] self . _detect_original_reverse = True self . _files_for_size = defaultdict ( list ) self . _files_for_chunk = defaultdict ( list ) self . _file_for_hash = dict () # we keep track of the files we already computed the hashes for so we only do # that once. self . _seen_files = set () self . _first_chunk_known = set () self . _hash_known = set () def pipeline ( self , res : Resource , output : Output ) -> bool : assert res . path is not None , \"Does not support standalone mode\" # skip symlinks if res . path . is_symlink (): return False # the exact same path has already been handled. This happens if multiple # locations emit this file in a single rule or if we follow symlinks. # We skip these. if res . path in self . _seen_files : return False self . _seen_files . add ( res . path ) # check for files with equal size file_size = read_file_size ( path = res . path ) same_size = self . _files_for_size [ file_size ] same_size . append ( res . path ) if len ( same_size ) == 1 : # the file is unique in size and cannot be a duplicate return False # for all other files with the same file size: # make sure we know their hash of their first 1024 byte chunk for f in same_size [: - 1 ]: if f not in self . _first_chunk_known : chunk_hash = hash_first_chunk ( f , algo = self . hash_algorithm ) self . _first_chunk_known . add ( f ) self . _files_for_chunk [ chunk_hash ] . append ( f ) # check first chunk hash collisions with the current file chunk_hash = hash_first_chunk ( res . path , algo = self . hash_algorithm ) same_first_chunk = self . _files_for_chunk [ chunk_hash ] same_first_chunk . append ( res . path ) self . _first_chunk_known . add ( res . path ) if len ( same_first_chunk ) == 1 : # the file has a unique small hash and cannot be a duplicate return False # Ensure we know the full hashes of all files with the same first chunk as # the investigated file for f in same_first_chunk [: - 1 ]: if f not in self . _hash_known : hash_ = hash ( f , algo = self . hash_algorithm ) self . _hash_known . add ( f ) self . _file_for_hash [ hash_ ] = f # check full hash collisions with the current file hash_ = hash ( res . path , algo = self . hash_algorithm ) self . _hash_known . add ( res . path ) known = self . _file_for_hash . get ( hash_ ) if known : original , duplicate = detect_original ( known = known , new = res . path , method = self . _detect_original_by , reverse = self . _detect_original_reverse , ) if known != original : self . _file_for_hash [ hash_ ] = original res . path = duplicate res . vars [ self . filter_config . name ] = { \"original\" : original } return True return False Examples: Show all duplicate files in your desktop and download folder (and their subfolders) rules: - name: Show all duplicate files in your desktop and download folder (and their subfolders) locations: - ~/Desktop - ~/Downloads subfolders: true filters: - duplicate actions: - echo: \"{path} is a duplicate of {duplicate.original}\" Check for duplicated files between Desktop and a Zip file, select original by creation date rules: - name: \"Check for duplicated files between Desktop and a Zip file, select original by creation date\" locations: - ~/Desktop - zip://~/Desktop/backup.zip filters: - duplicate: detect_original_by: \"created\" actions: - echo: \"Duplicate found!\"","title":"duplicate"},{"location":"filters/#empty","text":"Finds empty dirs and files Source code in organize/filters/empty.py 11 12 13 14 15 16 17 18 19 20 21 22 23 @dataclass ( config = ConfigDict ( extra = \"forbid\" )) class Empty : \"\"\"Finds empty dirs and files\"\"\" filter_config : ClassVar [ FilterConfig ] = FilterConfig ( name = \"empty\" , files = True , dirs = True , ) def pipeline ( self , res : Resource , output : Output ) -> bool : return res . is_empty () Examples: Recursively delete empty folders rules: - targets: dirs locations: - path: ~/Desktop max_depth: null filters: - empty actions: - delete","title":"empty"},{"location":"filters/#exif","text":"Filter by image EXIF data The exif filter can be used as a filter as well as a way to get exif information into your actions. By default this library uses the exifread library. If your image format is not supported you can install exiftool (exiftool.org) and set the environment variable: ORGANIZE_EXIFTOOL_PATH=\"exiftool\" organize will then use exiftool to extract the EXIF data. Exif fields which contain \"datetime\", \"date\" or \"offsettime\" in their fieldname will have their value converted to 'datetime.datetime', 'datetime.date' and 'datetime.timedelta' respectivly. - datetime.datetime : exif.image.datetime, exif.exif.datetimeoriginal, ... - datetime.date : exif.gps.date, ... - datetime.timedelta : exif.exif.offsettimeoriginal, exif.exif.offsettimedigitized, ... Attributes: lowercase_keys ( bool ) \u2013 Whether to lowercase all EXIF keys (Default: true) :returns: {exif} -- a dict of all the collected exif inforamtion available in the file. Typically it consists of the following tags (if present in the file): - ``{exif.image}`` -- information related to the main image - ``{exif.exif}`` -- Exif information - ``{exif.gps}`` -- GPS information - ``{exif.interoperability}`` -- Interoperability information Source code in organize/filters/exif.py 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 class Exif ( BaseModel ): \"\"\"Filter by image EXIF data The `exif` filter can be used as a filter as well as a way to get exif information into your actions. By default this library uses the `exifread` library. If your image format is not supported you can install `exiftool` (exiftool.org) and set the environment variable: ``` ORGANIZE_EXIFTOOL_PATH=\"exiftool\" ``` organize will then use `exiftool` to extract the EXIF data. Exif fields which contain \"datetime\", \"date\" or \"offsettime\" in their fieldname will have their value converted to 'datetime.datetime', 'datetime.date' and 'datetime.timedelta' respectivly. - `datetime.datetime` : exif.image.datetime, exif.exif.datetimeoriginal, ... - `datetime.date` : exif.gps.date, ... - `datetime.timedelta` : exif.exif.offsettimeoriginal, exif.exif.offsettimedigitized, ... Attributes: lowercase_keys (bool): Whether to lowercase all EXIF keys (Default: true) :returns: ``{exif}`` -- a dict of all the collected exif inforamtion available in the file. Typically it consists of the following tags (if present in the file): - ``{exif.image}`` -- information related to the main image - ``{exif.exif}`` -- Exif information - ``{exif.gps}`` -- GPS information - ``{exif.interoperability}`` -- Interoperability information \"\"\" filter_tags : Dict lowercase_keys : bool = True filter_config : ClassVar [ FilterConfig ] = FilterConfig ( name = \"exif\" , files = True , dirs = False , ) def __init__ ( self , * args , filter_tags : Optional [ Dict ] = None , lowercase_keys : bool = True , ** kwargs , ): # exif filter is used differently from other filters. The **kwargs are not # filter parameters but all belong into the filter_tags dictionary to filter # for specific exif tags. params = filter_tags or dict () params . update ( kwargs ) # *args are tags filtered without a value, like [\"gps\", \"image.model\"]. for arg in args : params [ arg ] = None super () . __init__ ( filter_tags = params , lowercase_keys = lowercase_keys ) def pipeline ( self , res : Resource , output : Output ) -> bool : assert res . path is not None , \"Does not support standalone mode\" # gather the exif data in a dict if exiftool_available (): data = exiftool_read ( path = res . path ) else : data = exifread_read ( path = res . path ) # lowercase keys if wanted if self . lowercase_keys : data = lowercase_keys_recursive ( data ) # convert strings to datetime objects where possible parsed = convert_recursive ( data ) res . vars [ self . filter_config . name ] = parsed return matches_tags ( self . filter_tags , data ) Show available EXIF data of your pictures rules: - name: \"Show available EXIF data of your pictures\" locations: - path: ~/Pictures max_depth: null filters: - exif actions: - echo: \"{exif}\" Copy all images which contain GPS information while keeping subfolder structure: rules: - name: \"GPS demo\" locations: - path: ~/Pictures max_depth: null filters: - exif: gps.gpsdate actions: - copy: ~/Pictures/with_gps/{relative_path}/ Filter by camera manufacturer rules: - name: \"Filter by camera manufacturer\" locations: - path: ~/Pictures max_depth: null filters: - exif: image.model: Nikon D3200 actions: - move: \"~/Pictures/My old Nikon/\" Sort images by camera manufacturer. This will create folders for each camera model (for example \"Nikon D3200\", \"iPhone 6s\", \"iPhone 5s\", \"DMC-GX80\") and move the pictures accordingly: rules: - name: \"camera sort\" locations: - path: ~/Pictures max_depth: null filters: - extension: jpg - exif: image.model actions: - move: \"~/Pictures/{exif.image.model}/\"","title":"exif"},{"location":"filters/#extension","text":"Filter by file extension Attributes: *extensions ( list ( str ) or str ) \u2013 The file extensions to match (does not need to start with a colon). Returns: {extension} : the original file extension (without colon) Source code in organize/filters/extension.py 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 @dataclass ( config = ConfigDict ( coerce_numbers_to_str = True , extra = \"forbid\" )) class Extension : \"\"\"Filter by file extension Attributes: *extensions (list(str) or str): The file extensions to match (does not need to start with a colon). **Returns:** - `{extension}`: the original file extension (without colon) \"\"\" extensions : Set [ str ] = Field ( default_factory = set ) filter_config : ClassVar [ FilterConfig ] = FilterConfig ( name = \"extension\" , files = True , dirs = False , ) @field_validator ( \"extensions\" , mode = \"before\" ) def normalize_extensions ( cls , v ): as_list = convert_to_list ( v ) return set ( map ( normalize_extension , flatten ( list ( as_list )))) def suffix_match ( self , path : Path ) -> Tuple [ str , bool ]: suffix = path . suffix . lstrip ( \".\" ) if not self . extensions : return ( suffix , True ) if not suffix : return ( suffix , False ) return ( suffix , normalize_extension ( suffix ) in self . extensions ) def pipeline ( self , res : Resource , output : Output ) -> bool : assert res . path is not None , \"Does not support standalone mode\" if res . is_dir (): raise ValueError ( \"Dirs not supported\" ) suffix , match = self . suffix_match ( path = res . path ) res . vars [ self . filter_config . name ] = suffix return match Examples: Match a single file extension rules: - name: \"Match a single file extension\" locations: \"~/Desktop\" filters: - extension: png actions: - echo: \"Found PNG file: {path}\" Match multiple file extensions rules: - name: \"Match multiple file extensions\" locations: \"~/Desktop\" filters: - extension: - .jpg - jpeg actions: - echo: \"Found JPG file: {path}\" Make all file extensions lowercase rules: - name: \"Make all file extensions lowercase\" locations: \"~/Desktop\" filters: - extension actions: - rename: \"{path.stem}.{extension.lower()}\" Using extension lists ( yaml aliases img_ext: &img - png - jpg - tiff audio_ext: &audio - mp3 - wav - ogg rules: - name: \"Using extension lists\" locations: \"~/Desktop\" filters: - extension: - *img - *audio actions: - echo: \"Found media file: {path}\"","title":"extension"},{"location":"filters/#filecontent","text":"Matches file content with the given regular expression. Supports .md, .txt, .log, .pdf and .docx files. For PDF content extraction poppler should be installed for the pdftotext command. If this is not available filecontent will fall back to the pdfminer library. Attributes: expr ( str ) \u2013 The regular expression to be matched. Any named groups ( (?P<groupname>.*) ) in your regular expression will be returned like this: Returns: {filecontent.groupname} : The text matched with the named group (?P<groupname>) You can test the filter on any file by running: python -m organize.filters.filecontent \"/path/to/file.pdf\" Source code in organize/filters/filecontent.py 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 @dataclass ( config = ConfigDict ( coerce_numbers_to_str = True , extra = \"forbid\" )) class FileContent : \"\"\"Matches file content with the given regular expression. Supports .md, .txt, .log, .pdf and .docx files. For PDF content extraction poppler should be installed for the `pdftotext` command. If this is not available `filecontent` will fall back to the `pdfminer` library. Attributes: expr (str): The regular expression to be matched. Any named groups (`(?P<groupname>.*)`) in your regular expression will be returned like this: **Returns:** - `{filecontent.groupname}`: The text matched with the named group `(?P<groupname>)` You can test the filter on any file by running: ```sh python -m organize.filters.filecontent \"/path/to/file.pdf\" ``` \"\"\" expr : str = r \"(?P<all>.*)\" filter_config : ClassVar [ FilterConfig ] = FilterConfig ( name = \"filecontent\" , files = True , dirs = False , ) def __post_init__ ( self ): self . _expr = re . compile ( self . expr , re . MULTILINE | re . DOTALL ) def matches ( self , path : Path ) -> Union [ re . Match , None ]: try : content = textract ( path ) match = self . _expr . search ( content ) return match except Exception : return None def pipeline ( self , res : Resource , output : Output ) -> bool : assert res . path is not None , \"Does not support standalone mode\" match = self . matches ( path = res . path ) if match : res . deep_merge ( self . filter_config . name , match . groupdict ()) return bool ( match ) Examples: Show the content of all your PDF files rules: - name: \"Show the content of all your PDF files\" locations: ~/Documents filters: - extension: pdf - filecontent actions: - echo: \"{filecontent}\" Match an invoice with a regular expression and sort by customer rules: - name: \"Match an invoice with a regular expression and sort by customer\" locations: \"~/Desktop\" filters: - filecontent: 'Invoice.*Customer (?P<customer>\\w+)' actions: - move: \"~/Documents/Invoices/{filecontent.customer}/\" Exampe to filter the filename with respect to a valid date code. The filename should start with <year>-<month>-<day> . Regex: creates a placeholder variable containing the year allows only years which start with 20 and are followed by 2 numbers months can only have as first digit 0 or 1 and must be followed by a number days can only have 0, 1,2 or 3 and must followed by number Note: Filter is not perfect but still. rules: - locations: ~/Desktop filters: - regex: '(?P<year>20\\d{2})-[01]\\d-[0123]\\d.*' actions: - echo: \"Year: {regex.year}\" Note If you have trouble getting the filecontent filter to work, have a look at the installation hints","title":"filecontent"},{"location":"filters/#hash","text":"Calculates the hash of a file. Attributes: algorithm ( str ) \u2013 Any hashing algorithm available to python's hashlib . md5 by default. Algorithms guaranteed to be available are shake_256 , sha3_256 , sha1 , sha3_224 , sha384 , sha512 , blake2b , blake2s , sha256 , sha224 , shake_128 , sha3_512 , sha3_384 and md5 . Depending on your python installation and installed libs there may be additional hash algorithms to chose from. To list the available algorithms on your installation run this in a python interpreter: >>> import hashlib >>> hashlib.algorithms_available {'shake_256', 'whirlpool', 'mdc2', 'blake2s', 'sha224', 'shake_128', 'sha3_512', 'sha3_224', 'sha384', 'md5', 'sha1', 'sha512_256', 'blake2b', 'sha256', 'sha512_224', 'ripemd160', 'sha3_384', 'md4', 'sm3', 'sha3_256', 'md5-sha1', 'sha512'} Returns: {hash} : The hash of the file. Source code in organize/filters/hash.py 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 @dataclass ( config = ConfigDict ( extra = \"forbid\" )) class Hash : \"\"\"Calculates the hash of a file. Attributes: algorithm (str): Any hashing algorithm available to python's `hashlib`. `md5` by default. Algorithms guaranteed to be available are `shake_256`, `sha3_256`, `sha1`, `sha3_224`, `sha384`, `sha512`, `blake2b`, `blake2s`, `sha256`, `sha224`, `shake_128`, `sha3_512`, `sha3_384` and `md5`. Depending on your python installation and installed libs there may be additional hash algorithms to chose from. To list the available algorithms on your installation run this in a python interpreter: ```py >>> import hashlib >>> hashlib.algorithms_available {'shake_256', 'whirlpool', 'mdc2', 'blake2s', 'sha224', 'shake_128', 'sha3_512', 'sha3_224', 'sha384', 'md5', 'sha1', 'sha512_256', 'blake2b', 'sha256', 'sha512_224', 'ripemd160', 'sha3_384', 'md4', 'sm3', 'sha3_256', 'md5-sha1', 'sha512'} ``` **Returns:** - `{hash}`: The hash of the file. \"\"\" algorithm : str = \"md5\" filter_config : ClassVar [ FilterConfig ] = FilterConfig ( name = \"hash\" , files = True , dirs = False , ) def __post_init__ ( self ): self . _algorithm = Template . from_string ( self . algorithm ) def pipeline ( self , res : Resource , output : Output ) -> bool : assert res . path is not None algo = render ( self . _algorithm , res . dict ()) . lower () result = hash ( path = res . path , algo = algo ) res . vars [ self . filter_config . name ] = result return True Examples: Show the hashes of your files: rules: - name: \"Show the hashes and size of your files\" locations: \"~/Desktop\" filters: - hash - size actions: - echo: \"{hash} {size.decimal}\"","title":"hash"},{"location":"filters/#lastmodified","text":"Matches files by last modified date Attributes: years ( int ) \u2013 specify number of years months ( int ) \u2013 specify number of months weeks ( float ) \u2013 specify number of weeks days ( float ) \u2013 specify number of days hours ( float ) \u2013 specify number of hours minutes ( float ) \u2013 specify number of minutes seconds ( float ) \u2013 specify number of seconds mode ( str ) \u2013 either 'older' or 'newer'. 'older' matches files / folders last modified before the given time, 'newer' matches files / folders last modified within the given time. (default = 'older') Returns: \u2013 {lastmodified}: The datetime the files / folders was lastmodified. Source code in organize/filters/lastmodified.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 class LastModified ( TimeFilter ): \"\"\"Matches files by last modified date Attributes: years (int): specify number of years months (int): specify number of months weeks (float): specify number of weeks days (float): specify number of days hours (float): specify number of hours minutes (float): specify number of minutes seconds (float): specify number of seconds mode (str): either 'older' or 'newer'. 'older' matches files / folders last modified before the given time, 'newer' matches files / folders last modified within the given time. (default = 'older') Returns: {lastmodified}: The datetime the files / folders was lastmodified. \"\"\" filter_config : ClassVar [ FilterConfig ] = FilterConfig ( name = \"lastmodified\" , files = True , dirs = True , ) def get_datetime ( self , path : Path ) -> datetime : return read_lastmodified ( path ) Examples: rules: - name: \"Show all files on your desktop last modified at least 10 days ago\" locations: \"~/Desktop\" filters: - lastmodified: days: 10 actions: - echo: \"Was modified at least 10 days ago\" Show all files on your desktop which were modified within the last 5 hours: rules: - locations: \"~/Desktop\" filters: - lastmodified: hours: 5 mode: newer actions: - echo: \"Was modified within the last 5 hours\" Sort pdfs by year of last modification rules: - name: \"Sort pdfs by year of last modification\" locations: \"~/Documents\" filters: - extension: pdf - lastmodified actions: - move: \"~/Documents/PDF/{lastmodified.year}/\" Formatting the last modified date rules: - name: Formatting the lastmodified date locations: \"~/Documents\" filters: - extension: pdf - lastmodified actions: - echo: \"ISO Format: {lastmodified.strftime('%Y-%m-%d')}\" - echo: \"As timestamp: {lastmodified.timestamp() | int}\"","title":"lastmodified"},{"location":"filters/#macos_tags","text":"Filter by macOS tags Attributes: tags ( list ( str ) or str ) \u2013 The tags to filter by Source code in organize/filters/macos_tags.py 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 @dataclass ( config = ConfigDict ( coerce_numbers_to_str = True , extra = \"forbid\" )) class MacOSTags : \"\"\"Filter by macOS tags Attributes: tags (list(str) or str): The tags to filter by \"\"\" tags : List [ str ] = Field ( default_factory = list ) filter_config : ClassVar [ FilterConfig ] = FilterConfig ( name = \"macos_tags\" , files = True , dirs = True , ) def __post_init__ ( self ): if sys . platform != \"darwin\" : raise EnvironmentError ( \"The macos_tags filter is only available on macOS\" ) @field_validator ( \"tags\" , mode = \"before\" ) def ensure_list ( cls , v ): if isinstance ( v , str ): return [ v ] return v def pipeline ( self , res : Resource , output : Output ) -> bool : file_tags = list_tags ( res . path ) res . vars [ self . filter_config . name ] = file_tags return matches_tags ( filter_tags = self . tags , file_tags = file_tags ) Examples: rules: - name: \"Only files with a red macOS tag\" locations: \"~/Downloads\" filters: - macos_tags: \"* (red)\" actions: - echo: \"File with red tag\" rules: - name: \"All files tagged 'Invoice' (any color)\" locations: \"~/Downloads\" filters: - macos_tags: \"Invoice (*)\" actions: - echo: \"Invoice found\" rules: - name: \"All files with a tag 'Invoice' (any color) or with a green tag\" locations: \"~/Downloads\" filters: - macos_tags: - \"Invoice (*)\" - \"* (green)\" actions: - echo: \"Match found!\" rules: - name: \"Listing file tags\" locations: \"~/Downloads\" filters: - macos_tags actions: - echo: \"{macos_tags}\"","title":"macos_tags"},{"location":"filters/#mimetype","text":"Filter by MIME type associated with the file extension. Supports a single string or list of MIME type strings as argument. The types don't need to be fully specified, for example \"audio\" matches everything from \"audio/midi\" to \"audio/quicktime\". You can see a list of known MIME types on your system by running this oneliner: python3 -m organize.filters.mimetype Attributes: *mimetypes ( list ( str ) or str ) \u2013 The MIME types to filter for. Returns: {mimetype} : The MIME type of the file. Source code in organize/filters/mimetype.py 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 @dataclass ( config = ConfigDict ( coerce_numbers_to_str = True , extra = \"forbid\" )) class MimeType : \"\"\"Filter by MIME type associated with the file extension. Supports a single string or list of MIME type strings as argument. The types don't need to be fully specified, for example \"audio\" matches everything from \"audio/midi\" to \"audio/quicktime\". You can see a list of known MIME types on your system by running this oneliner: ```sh python3 -m organize.filters.mimetype ``` Attributes: *mimetypes (list(str) or str): The MIME types to filter for. **Returns:** - `{mimetype}`: The MIME type of the file. \"\"\" mimetypes : FlatList [ str ] = Field ( default_factory = list ) filter_config : ClassVar [ FilterConfig ] = FilterConfig ( name = \"mimetype\" , files = True , dirs = False , ) def matches ( self , mimetype ) -> bool : if mimetype is None : return False if not self . mimetypes : return True return any ( mimetype . startswith ( x ) for x in self . mimetypes ) def pipeline ( self , res : Resource , output : Output ) -> bool : mimetype = guess_mimetype ( res . path ) res . vars [ self . filter_config . name ] = mimetype return self . matches ( mimetype ) Examples: Show MIME types rules: - name: \"Show MIME types\" locations: \"~/Downloads\" filters: - mimetype actions: - echo: \"{mimetype}\" Filter by 'image' mimetype rules: - name: \"Filter by 'image' mimetype\" locations: \"~/Downloads\" filters: - mimetype: image actions: - echo: \"This file is an image: {mimetype}\" Filter by specific MIME type rules: - name: Filter by specific MIME type locations: \"~/Desktop\" filters: - mimetype: application/pdf actions: - echo: \"Found a PDF file\" Filter by multiple specific MIME types rules: - name: Filter by multiple specific MIME types locations: \"~/Music\" filters: - mimetype: - application/pdf - audio/midi actions: - echo: \"Found Midi or PDF.\"","title":"mimetype"},{"location":"filters/#name","text":"Match files and folders by name Attributes: match ( str ) \u2013 A matching string in simplematch-syntax startswith ( str ) \u2013 The filename must begin with the given string contains ( str ) \u2013 The filename must contain the given string endswith ( str ) \u2013 The filename (without extension) must end with the given string case_sensitive ( bool ) \u2013 By default, the matching is case sensitive. Change this to False to use case insensitive matching. Source code in organize/filters/name.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 @dataclass ( config = ConfigDict ( coerce_numbers_to_str = True , extra = \"forbid\" )) class Name : \"\"\"Match files and folders by name Attributes: match (str): A matching string in [simplematch-syntax](https://github.com/tfeldmann/simplematch) startswith (str): The filename must begin with the given string contains (str): The filename must contain the given string endswith (str): The filename (without extension) must end with the given string case_sensitive (bool): By default, the matching is case sensitive. Change this to False to use case insensitive matching. \"\"\" match : str = \"*\" startswith : Union [ str , List [ str ]] = \"\" contains : Union [ str , List [ str ]] = \"\" endswith : Union [ str , List [ str ]] = \"\" case_sensitive : bool = True filter_config : ClassVar [ FilterConfig ] = FilterConfig ( name = \"name\" , files = True , dirs = True , ) def __post_init__ ( self , * args , ** kwargs ): self . _matcher = simplematch . Matcher ( self . match , case_sensitive = self . case_sensitive , ) self . startswith = self . create_list ( self . startswith , self . case_sensitive ) self . contains = self . create_list ( self . contains , self . case_sensitive ) self . endswith = self . create_list ( self . endswith , self . case_sensitive ) def matches ( self , name : str ) -> bool : if not self . case_sensitive : name = name . lower () is_match = ( self . _matcher . test ( name ) and any ( x in name for x in self . contains ) and any ( name . startswith ( x ) for x in self . startswith ) and any ( name . endswith ( x ) for x in self . endswith ) ) return is_match def pipeline ( self , res : Resource , output : Output ) -> bool : assert res . path is not None , \"Does not support standalone mode\" if res . is_dir (): name = res . path . stem else : name , ext = res . path . stem , res . path . suffix if not name : name = ext result = self . matches ( normalize_unicode ( name )) m = self . _matcher . match ( normalize_unicode ( name )) if not m : m = name res . vars [ self . filter_config . name ] = m return result @staticmethod def create_list ( x : Union [ int , str , List [ Any ]], case_sensitive : bool ) -> List [ str ]: if isinstance ( x , ( int , float )): x = str ( x ) if isinstance ( x , str ): x = [ x ] x = [ str ( x ) for x in x ] if not case_sensitive : x = [ x . lower () for x in x ] return x Examples: Match all files starting with 'Invoice': rules: - locations: \"~/Desktop\" filters: - name: startswith: Invoice actions: - echo: \"This is an invoice\" Match all files starting with 'A' end containing the string 'hole' (case insensitive): rules: - locations: \"~/Desktop\" filters: - name: startswith: A contains: hole case_sensitive: false actions: - echo: \"Found a match.\" Match all files starting with 'A' or 'B' containing '5' or '6' and ending with '_end': rules: - locations: \"~/Desktop\" filters: - name: startswith: - \"A\" - \"B\" contains: - \"5\" - \"6\" endswith: _end case_sensitive: false actions: - echo: \"Found a match.\"","title":"name"},{"location":"filters/#python","text":"Use python code to filter files. Attributes: code ( str ) \u2013 The python code to execute. The code must contain a return statement. Returns: If your code returns False or None the file is filtered out, otherwise the file is passed on to the next filters. {python} contains the returned value. If you return a dictionary (for example return {\"some_key\": some_value, \"nested\": {\"k\": 2}} ) it will be accessible via dot syntax actions: {python.some_key} , {python.nested.k} . Variables of previous filters are available, but you have to use the normal python dictionary syntax x = regex[\"my_group\"] . Source code in organize/filters/python.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 @dataclass ( config = ConfigDict ( coerce_numbers_to_str = True , extra = \"forbid\" )) class Python : \"\"\"Use python code to filter files. Attributes: code (str): The python code to execute. The code must contain a `return` statement. **Returns:** - If your code returns `False` or `None` the file is filtered out, otherwise the file is passed on to the next filters. - `{python}` contains the returned value. If you return a dictionary (for example `return {\"some_key\": some_value, \"nested\": {\"k\": 2}}`) it will be accessible via dot syntax actions: `{python.some_key}`, `{python.nested.k}`. - Variables of previous filters are available, but you have to use the normal python dictionary syntax `x = regex[\"my_group\"]`. \"\"\" code : str filter_config : ClassVar [ FilterConfig ] = FilterConfig ( name = \"python\" , files = True , dirs = True , ) @field_validator ( \"code\" , mode = \"after\" ) @classmethod def must_have_return_statement ( cls , value ): if \"return\" not in value : raise ValueError ( \"No return statement found in your code!\" ) return value def __post_init__ ( self ): self . code = textwrap . dedent ( self . code ) def __usercode__ ( self , print , ** kwargs ) -> Optional [ Dict ]: raise NotImplementedError () def pipeline ( self , res : Resource , output : Output ) -> bool : def _output_msg ( * values , sep : str = \" \" , end : str = \"\" ): \"\"\" the print function for the use code needs to print via the current output \"\"\" output . msg ( res = res , msg = f \" { sep . join ( str ( x ) for x in values ) }{ end } \" , sender = \"python\" , ) # codegen the user function with arguments as available in the resource kwargs = \", \" . join ( res . dict () . keys ()) func = f \"def __userfunc(print, { kwargs } ): \\n \" func += textwrap . indent ( self . code , \" \" ) func += \" \\n\\n self.__usercode__ = __userfunc\" exec ( func , globals () . copy (), locals () . copy ()) result = self . __usercode__ ( print = _output_msg , ** res . dict ()) if isinstance ( result , dict ): res . deep_merge ( key = self . filter_config . name , data = result ) else : res . vars [ self . filter_config . name ] = result return result not in ( False , None ) Examples: rules: - name: A file name reverser. locations: ~/Documents filters: - extension - python: | return {\"reversed_name\": path.stem[::-1]} actions: - rename: \"{python.reversed_name}.{extension}\" A filter for odd student numbers. Assuming the folder ~/Students contains the files student-01.jpg , student-01.txt , student-02.txt and student-03.txt this rule will print \"Odd student numbers: student-01.txt\" and \"Odd student numbers: student-03.txt\" rules: - name: \"Filter odd student numbers\" locations: ~/Students/ filters: - python: | return int(path.stem.split('-')[1]) % 2 == 1 actions: - echo: \"Odd student numbers: {path.name}\" Advanced usecase. You can access data from previous filters in your python code. This can be used to match files and capturing names with a regular expression and then renaming the files with the output of your python script. rules: - name: \"Access placeholders in python filter\" locations: files filters: - extension: txt - regex: (?P<firstname>\\w+)-(?P<lastname>\\w+)\\..* - python: | emails = { \"Betts\": \"dbetts@mail.de\", \"Cornish\": \"acornish@google.com\", \"Bean\": \"dbean@aol.com\", \"Frey\": \"l-frey@frey.org\", } if regex.lastname in emails: # get emails from wherever return {\"mail\": emails[regex.lastname]} actions: - rename: \"{python.mail}.txt\" Result: Devonte-Betts.txt becomes dbetts@mail.de.txt Alaina-Cornish.txt becomes acornish@google.com.txt Dimitri-Bean.txt becomes dbean@aol.com.txt Lowri-Frey.txt becomes l-frey@frey.org.txt Someunknown-User.txt remains unchanged because the email is not found","title":"python"},{"location":"filters/#regex","text":"Matches filenames with the given regular expression Attributes: expr ( str ) \u2013 The regular expression to be matched. Returns: Any named groups in your regular expression will be returned like this: {regex.groupname} : The text matched with the named group (?P<groupname>.*) Source code in organize/filters/regex.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 @dataclass ( config = ConfigDict ( coerce_numbers_to_str = True , extra = \"forbid\" )) class Regex : \"\"\"Matches filenames with the given regular expression Attributes: expr (str): The regular expression to be matched. **Returns:** Any named groups in your regular expression will be returned like this: - `{regex.groupname}`: The text matched with the named group `(?P<groupname>.*)` \"\"\" expr : str filter_config : ClassVar [ FilterConfig ] = FilterConfig ( name = \"regex\" , files = True , dirs = True , ) def __post_init__ ( self ): self . _expr = re . compile ( self . expr , flags = re . UNICODE ) def matches ( self , path : str ): return self . _expr . search ( path ) def pipeline ( self , res : Resource , output : Output ) -> bool : assert res . path is not None , \"Does not support standalone mode\" match = self . matches ( normalize_unicode ( res . path . name )) if match : res . deep_merge ( key = self . filter_config . name , data = match . groupdict ()) return True return False Examples: Match an invoice with a regular expression: rules: - locations: \"~/Desktop\" filters: - regex: '^RG(\\d{12})-sig\\.pdf$' actions: - move: \"~/Documents/Invoices/1und1/\" Match and extract data from filenames with regex named groups: This is just like the previous example but we rename the invoice using the invoice number extracted via the regular expression and the named group the_number . rules: - locations: ~/Desktop filters: - regex: '^RG(?P<the_number>\\d{12})-sig\\.pdf$' actions: - move: ~/Documents/Invoices/1und1/{regex.the_number}.pdf","title":"regex"},{"location":"filters/#size","text":"Matches files and folders by size Attributes: *conditions ( list ( str ) or str ) \u2013 The size constraints. Accepts file size conditions, e.g: \">= 500 MB\" , \"< 20k\" , \">0\" , \"= 10 KiB\" . It is possible to define both lower and upper conditions like this: \">20k, < 1 TB\" , \">= 20 Mb, <25 Mb\" . The filter will match if all given conditions are satisfied. Accepts all units from KB to YB. If no unit is given, kilobytes are assumend. If binary prefix is given (KiB, GiB) the size is calculated using base 1024. Returns: {size.bytes} : (int) Size in bytes {size.traditional} : (str) Size with unit (powers of 1024, JDEC prefixes) {size.binary} : (str) Size with unit (powers of 1024, IEC prefixes) {size.decimal} : (str) Size with unit (powers of 1000, SI prefixes) Source code in organize/filters/size.py 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 @dataclass ( config = ConfigDict ( coerce_numbers_to_str = True , extra = \"forbid\" )) class Size : \"\"\"Matches files and folders by size Attributes: *conditions (list(str) or str): The size constraints. Accepts file size conditions, e.g: `\">= 500 MB\"`, `\"< 20k\"`, `\">0\"`, `\"= 10 KiB\"`. It is possible to define both lower and upper conditions like this: `\">20k, < 1 TB\"`, `\">= 20 Mb, <25 Mb\"`. The filter will match if all given conditions are satisfied. - Accepts all units from KB to YB. - If no unit is given, kilobytes are assumend. - If binary prefix is given (KiB, GiB) the size is calculated using base 1024. **Returns:** - `{size.bytes}`: (int) Size in bytes - `{size.traditional}`: (str) Size with unit (powers of 1024, JDEC prefixes) - `{size.binary}`: (str) Size with unit (powers of 1024, IEC prefixes) - `{size.decimal}`: (str) Size with unit (powers of 1000, SI prefixes) \"\"\" conditions : FlatList [ str ] = Field ( default_factory = list ) filter_config : ClassVar [ FilterConfig ] = FilterConfig ( name = \"size\" , files = True , dirs = True ) def __post_init__ ( self ): self . _constraints = set () for x in self . conditions : for constraint in create_constraints ( x ): self . _constraints . add ( constraint ) def matches ( self , filesize : int ) -> bool : if not self . _constraints : return True return all ( op ( filesize , c_size ) for op , c_size in self . _constraints ) def pipeline ( self , res : Resource , output : Output ) -> bool : assert res . path is not None bytes = read_resource_size ( res = res ) res . vars [ self . filter_config . name ] = { \"bytes\" : bytes , \"traditional\" : traditional ( bytes ), \"binary\" : binary ( bytes ), \"decimal\" : decimal ( bytes ), } return self . matches ( bytes ) Examples: Trash big downloads: rules: - locations: \"~/Downloads\" targets: files filters: - size: \"> 0.5 GB\" actions: - trash Move all JPEGS bigger > 1MB and <10 MB. Search all subfolders and keep the original relative path. rules: - locations: - path: \"~/Pictures\" max_depth: null filters: - extension: - jpg - jpeg - size: \">1mb, <10mb\" actions: - move: \"~/Pictures/sorted/{relative_path}/\"","title":"size"},{"location":"locations/","text":"Locations # Locations are the folders in which organize searches for resources. You can set multiple locations for each rule if you want. A minimum location definition is just a path where to look for files / folders: rules: - locations: ~/Desktop actions: ... If you want to handle multiple locations in a rule, create a list: rules: - locations: - ~/Desktop - /usr/bin/ - \"%PROGRAMDATA%/test\" actions: ... Using options: rules: - name: \"Location list\" locations: - path: \"~/Desktop\" max_depth: 3 actions: ... Location options # rules: - locations: - path: ... min_depth: ... max_depth: ... search: ... exclude_files: ... exclude_dirs: ... system_exclude_files: ... system_exclude_dirs: ... ignore_errors: ... filter: ... filter_dirs: ... path ( str ) Path to a local folder min_depth ( int or null ) Minimum directory depth to search. This can be useful if you want to only handle files in subdirectories of location . max_depth ( int or null ) Maximum directory depth to search. search ( \"breadth\" or \"depth\" ) Whether to use breadth or depth search to recurse into subfolders. Note that if you want to move or delete files from this location, this has to be set to \"depth\" . (Default: \"depth\" ) exclude_files ( List[str] ) A list of filename patterns that should be excluded in this location, e.g. [\"~*\"] . exclude_dirs ( List[str] ) A list of folder name patterns that will be used to filter out directory names in this location. e.g. [\"do-not-move\", \"*-Important\", \"Backup*\"] system_exclude_files ( List[str] ) The list of filename patterns that are excluded by default. Defaults to: [\"thumbs.db\", \"desktop.ini\", \"~$*\", \".DS_Store\", \".localized\"] . Override with [] to include system files. system_exclude_dirs ( List[str] ) The list of folder name patterns that are excluded by default ( ['.git', '.svn'] ). Override with [] to include system dirs. ignore_errors ( bool ) If true , any errors reading the location will be ignored. filter ( List[str] ) A list of filename patterns that should be used in this location, e.g. [\"*.py\"] . All other files are skipped. filter_dirs ( List[str] ) A list of patterns to match directory names that are included in this location. All other directories are skipped. max_depth and subfolders # If subfolders: true is specified on the rule, all locations are set to max_depth: null by default. A max_depth setting in a location is given precedence over the rule's subfolders setting. Environment variables in locations # You can use environment variables in your locations. You can access them via the {env} placeholder or prefix them with a dollar sign. Examples: rules: - locations: # via {env} - the \"\" are important here! - \"{env.MY_FOLDER}\" # via $ - equal to the one above. - \"$MY_FOLDER\" # with location options - path: \"{env.OTHER_FOLDER}/Inbox/Invoices\" max_depth: null actions: - echo: \"{path}\" Relative locations # Locations can be relative. This allows you to create simple one-off rules that can be copied between projects. There is a command line option to change the working directory should you need it. huge-pic-warner.yaml: rules: - locations: \"docs\" # here \"docs\" is relative to the current working dir filters: - extension: jpg - size: \">3 MB\" actions: - echo: \"Warning - huge pic found!\" Then run it with: organize sim huge-pic-warner.yaml --working-dir=some/other/dir/","title":"Locations"},{"location":"locations/#locations","text":"Locations are the folders in which organize searches for resources. You can set multiple locations for each rule if you want. A minimum location definition is just a path where to look for files / folders: rules: - locations: ~/Desktop actions: ... If you want to handle multiple locations in a rule, create a list: rules: - locations: - ~/Desktop - /usr/bin/ - \"%PROGRAMDATA%/test\" actions: ... Using options: rules: - name: \"Location list\" locations: - path: \"~/Desktop\" max_depth: 3 actions: ...","title":"Locations"},{"location":"locations/#location-options","text":"rules: - locations: - path: ... min_depth: ... max_depth: ... search: ... exclude_files: ... exclude_dirs: ... system_exclude_files: ... system_exclude_dirs: ... ignore_errors: ... filter: ... filter_dirs: ... path ( str ) Path to a local folder min_depth ( int or null ) Minimum directory depth to search. This can be useful if you want to only handle files in subdirectories of location . max_depth ( int or null ) Maximum directory depth to search. search ( \"breadth\" or \"depth\" ) Whether to use breadth or depth search to recurse into subfolders. Note that if you want to move or delete files from this location, this has to be set to \"depth\" . (Default: \"depth\" ) exclude_files ( List[str] ) A list of filename patterns that should be excluded in this location, e.g. [\"~*\"] . exclude_dirs ( List[str] ) A list of folder name patterns that will be used to filter out directory names in this location. e.g. [\"do-not-move\", \"*-Important\", \"Backup*\"] system_exclude_files ( List[str] ) The list of filename patterns that are excluded by default. Defaults to: [\"thumbs.db\", \"desktop.ini\", \"~$*\", \".DS_Store\", \".localized\"] . Override with [] to include system files. system_exclude_dirs ( List[str] ) The list of folder name patterns that are excluded by default ( ['.git', '.svn'] ). Override with [] to include system dirs. ignore_errors ( bool ) If true , any errors reading the location will be ignored. filter ( List[str] ) A list of filename patterns that should be used in this location, e.g. [\"*.py\"] . All other files are skipped. filter_dirs ( List[str] ) A list of patterns to match directory names that are included in this location. All other directories are skipped.","title":"Location options"},{"location":"locations/#max_depth-and-subfolders","text":"If subfolders: true is specified on the rule, all locations are set to max_depth: null by default. A max_depth setting in a location is given precedence over the rule's subfolders setting.","title":"max_depth and subfolders"},{"location":"locations/#environment-variables-in-locations","text":"You can use environment variables in your locations. You can access them via the {env} placeholder or prefix them with a dollar sign. Examples: rules: - locations: # via {env} - the \"\" are important here! - \"{env.MY_FOLDER}\" # via $ - equal to the one above. - \"$MY_FOLDER\" # with location options - path: \"{env.OTHER_FOLDER}/Inbox/Invoices\" max_depth: null actions: - echo: \"{path}\"","title":"Environment variables in locations"},{"location":"locations/#relative-locations","text":"Locations can be relative. This allows you to create simple one-off rules that can be copied between projects. There is a command line option to change the working directory should you need it. huge-pic-warner.yaml: rules: - locations: \"docs\" # here \"docs\" is relative to the current working dir filters: - extension: jpg - size: \">3 MB\" actions: - echo: \"Warning - huge pic found!\" Then run it with: organize sim huge-pic-warner.yaml --working-dir=some/other/dir/","title":"Relative locations"},{"location":"migrating/","text":"Migrating from older versions # First of all, thank you for being a long time user of organize ! I tried to keep the amount of breaking changes small but could not avoid them completely. Feel free to pin organize whatever version you need, but then you're missing the party. Please open a issue on Github if you need help migrating your config file! Migrating from v2 to v3 # Locations # In organize v3 remote filesystems are no longer supported. You have to remove all filesystem parameters from your config and cannot longer use pyfilesystem URLs your location . Placeholders # Use {now()} instead of {now} . Use {utcnow()} instead of {utcnow} . The placeholders {fs} and {fs_path} are no longer available. Command line interface # The command line interface changed quite a bit! Update any scripts using the CLI to the new options: organize check --debug becomes organize debug organize reveal becomes organize show --reveal organize reveal --path becomes organize show --path organize schema is not longer supported. The already deprecated --config-file option is now removed. That's it. If you encounter any other bugs or problems during the migration, please reach out! Migrating from v1 to v2 # Folders # Folders have become Locations in organize v2. folders must be renamed to locations in your config. REMOVED: The glob syntax ( /Docs/**/*.png ). See Location options . REMOVED: The exclamation mark exclude syntax ( ! ~/Desktop/exclude ). See Location options . All keys (filter names, action names, option names) now must be lowercase. Placeholders # organize v2 uses the Jinja template engine. You may need to change some of your placeholders. {basedir} is no longer available. You have to replace undocumented placeholders like this: \"{created.year}-{created.month:02}-{created.day:02}\" With this: \"{created.strftime('%Y-%m-%d')}\" If you need to left pad other numbers you can now use the following syntax: \"{'%02d' % your_variable}\" # or \"{ '{:02}'.format(your_variable) }\" Filters # filename is renamed to name . filesize is renamed to size . created no longer accepts a timezone and uses the local timezone by default. lastmodified no longer accepts a timezone and uses the local timezone by default. extension lower and upper are now functions and must be called like this: \"{extension.upper()}\" and \"{extension.lower()}\" . Actions # The copy, move and rename actions got a whole lot more powerful. You now have several conflict options and can specify exactly how a file should be renamed in case of a conflict. This means you might need to change your config to use the new parameters. copy arguments changed to support conflict resolution options. move arguments changed to support conflict resolution options. rename arguments changed to support conflict resolution options. Example: rules: - folders: ~/Desktop filters: - extension: pdf actions: - move: dest: ~/Documents/PDFs/ overwrite: false counter_seperator: \"-\" becomes (organize v2): rules: - locations: ~/Desktop filters: - extension: pdf actions: - move: dest: ~/Documents/PDFs/ on_conflict: rename_new rename_template: \"{name}-{counter}{extension}\" If you used move , copy or rename without arguments, nothing changes for you. Settings # The system_files setting has been removed. In order to include system files in your search, overwrite the default system_exclude_files with an empty list: rules: - locations: - path: ~/Desktop/ system_exclude_files: [] system_exclude_dirs: [] filters: - name: .DS_Store actions: - trash That's it. Again, feel free to open a issue if you have trouble migrating your config.","title":"Migrating from older versions"},{"location":"migrating/#migrating-from-older-versions","text":"First of all, thank you for being a long time user of organize ! I tried to keep the amount of breaking changes small but could not avoid them completely. Feel free to pin organize whatever version you need, but then you're missing the party. Please open a issue on Github if you need help migrating your config file!","title":"Migrating from older versions"},{"location":"migrating/#migrating-from-v2-to-v3","text":"","title":"Migrating from v2 to v3"},{"location":"migrating/#locations","text":"In organize v3 remote filesystems are no longer supported. You have to remove all filesystem parameters from your config and cannot longer use pyfilesystem URLs your location .","title":"Locations"},{"location":"migrating/#placeholders","text":"Use {now()} instead of {now} . Use {utcnow()} instead of {utcnow} . The placeholders {fs} and {fs_path} are no longer available.","title":"Placeholders"},{"location":"migrating/#command-line-interface","text":"The command line interface changed quite a bit! Update any scripts using the CLI to the new options: organize check --debug becomes organize debug organize reveal becomes organize show --reveal organize reveal --path becomes organize show --path organize schema is not longer supported. The already deprecated --config-file option is now removed. That's it. If you encounter any other bugs or problems during the migration, please reach out!","title":"Command line interface"},{"location":"migrating/#migrating-from-v1-to-v2","text":"","title":"Migrating from v1 to v2"},{"location":"migrating/#folders","text":"Folders have become Locations in organize v2. folders must be renamed to locations in your config. REMOVED: The glob syntax ( /Docs/**/*.png ). See Location options . REMOVED: The exclamation mark exclude syntax ( ! ~/Desktop/exclude ). See Location options . All keys (filter names, action names, option names) now must be lowercase.","title":"Folders"},{"location":"migrating/#placeholders_1","text":"organize v2 uses the Jinja template engine. You may need to change some of your placeholders. {basedir} is no longer available. You have to replace undocumented placeholders like this: \"{created.year}-{created.month:02}-{created.day:02}\" With this: \"{created.strftime('%Y-%m-%d')}\" If you need to left pad other numbers you can now use the following syntax: \"{'%02d' % your_variable}\" # or \"{ '{:02}'.format(your_variable) }\"","title":"Placeholders"},{"location":"migrating/#filters","text":"filename is renamed to name . filesize is renamed to size . created no longer accepts a timezone and uses the local timezone by default. lastmodified no longer accepts a timezone and uses the local timezone by default. extension lower and upper are now functions and must be called like this: \"{extension.upper()}\" and \"{extension.lower()}\" .","title":"Filters"},{"location":"migrating/#actions","text":"The copy, move and rename actions got a whole lot more powerful. You now have several conflict options and can specify exactly how a file should be renamed in case of a conflict. This means you might need to change your config to use the new parameters. copy arguments changed to support conflict resolution options. move arguments changed to support conflict resolution options. rename arguments changed to support conflict resolution options. Example: rules: - folders: ~/Desktop filters: - extension: pdf actions: - move: dest: ~/Documents/PDFs/ overwrite: false counter_seperator: \"-\" becomes (organize v2): rules: - locations: ~/Desktop filters: - extension: pdf actions: - move: dest: ~/Documents/PDFs/ on_conflict: rename_new rename_template: \"{name}-{counter}{extension}\" If you used move , copy or rename without arguments, nothing changes for you.","title":"Actions"},{"location":"migrating/#settings","text":"The system_files setting has been removed. In order to include system files in your search, overwrite the default system_exclude_files with an empty list: rules: - locations: - path: ~/Desktop/ system_exclude_files: [] system_exclude_dirs: [] filters: - name: .DS_Store actions: - trash That's it. Again, feel free to open a issue if you have trouble migrating your config.","title":"Settings"},{"location":"rules/","text":"Rules # A organize config file can be written in YAML or JSON . See configuration on how to locate your config file. The top level element must be a dict with a key \"rules\". \"rules\" contains a list of objects with the required keys \"locations\" and \"actions\". A minimum config: rules: - locations: \"~/Desktop\" actions: - echo: \"Hello World!\" Organize checks your rules from top to bottom. For every resource in each location (top to bottom) it will check whether the filters apply (top to bottom) and then execute the given actions (top to bottom). So with this minimal configuration it will print \"Hello World!\" for each file it finds in your Desktop. Rule options # rules: # First rule - name: ... enabled: ... targets: ... locations: ... subfolders: ... filter_mode: ... filters: ... actions: ... tags: ... # Another rule - name: ... enabled: ... # ... and so on The rule options in detail: name ( str ): The rule name enabled ( bool ): Whether the rule is enabled / disabled (Default: true ) targets ( str ): \"dirs\" or \"files\" (Default: \"files\" ) locations ( str | list ) - A single location string or list of locations subfolders ( bool ): Whether to recurse into subfolders of all locations (Default: false ) filter_mode ( str ): \"all\" , \"any\" or \"none\" of the filters must apply (Default: \"all\" ) filters ( list ): A list of filters (Default: [] ) actions ( list ): A list of actions tags ( list ): A list of tags Targeting directories # When targets is set to dirs , organize will work on the folders, not on files. The filters adjust their meaning automatically. For example the size filter sums up the size of all files contained in the given folder instead of returning the size of a single file. Of course other filters like exif or filecontent do not work on folders and will return an error. Templates and placeholders # Placeholder variables are used with curly braces {var} . These variables are always available : {env} ( dict ) All your environment variables. You can access individual env vars like this: {env.MY_VARIABLE} . {path} ( pathlib.Path ) The full path to the current file / folder on the local harddrive. {relative_path} ( str ) the relative path of the current file or dir. {now()} ( datetime ) The current datetime in the local timezone. {utcnow()} ( datetime ) The current UTC datetime. {today()} ( date ) Today's date. In addition to that nearly all filters add new placeholders with information about the currently handled file / folder. Example on how to access the size and hash of a file: rules: - locations: ~/Desktop filters: - size - hash actions: - echo: \"{size} {hash}\" Note In order to use a value returned by a filter it must be listed in the filters! Advanced: Aliases # Instead of repeating the same locations / actions / filters in each and every rule you can use an alias for multiple locations which you can then reference in each rule. Aliases are a standard feature of the YAML syntax. all_my_messy_folders: &all - ~/Desktop - ~/Downloads - ~/Documents - ~/Dropbox rules: - locations: *all filters: ... actions: ... - locations: *all filters: ... actions: ... You can even use multiple folder lists: private_folders: &private - \"/path/private\" - \"~/path/private\" work_folders: &work - \"/path/work\" - \"~/My work folder\" all_folders: &all - *private - *work rules: - locations: *private filters: ... actions: ... - locations: *work filters: ... actions: ... - locations: *all filters: ... actions: ... # same as *all - locations: - *work - *private filters: ... actions: ...","title":"Rules"},{"location":"rules/#rules","text":"A organize config file can be written in YAML or JSON . See configuration on how to locate your config file. The top level element must be a dict with a key \"rules\". \"rules\" contains a list of objects with the required keys \"locations\" and \"actions\". A minimum config: rules: - locations: \"~/Desktop\" actions: - echo: \"Hello World!\" Organize checks your rules from top to bottom. For every resource in each location (top to bottom) it will check whether the filters apply (top to bottom) and then execute the given actions (top to bottom). So with this minimal configuration it will print \"Hello World!\" for each file it finds in your Desktop.","title":"Rules"},{"location":"rules/#rule-options","text":"rules: # First rule - name: ... enabled: ... targets: ... locations: ... subfolders: ... filter_mode: ... filters: ... actions: ... tags: ... # Another rule - name: ... enabled: ... # ... and so on The rule options in detail: name ( str ): The rule name enabled ( bool ): Whether the rule is enabled / disabled (Default: true ) targets ( str ): \"dirs\" or \"files\" (Default: \"files\" ) locations ( str | list ) - A single location string or list of locations subfolders ( bool ): Whether to recurse into subfolders of all locations (Default: false ) filter_mode ( str ): \"all\" , \"any\" or \"none\" of the filters must apply (Default: \"all\" ) filters ( list ): A list of filters (Default: [] ) actions ( list ): A list of actions tags ( list ): A list of tags","title":"Rule options"},{"location":"rules/#targeting-directories","text":"When targets is set to dirs , organize will work on the folders, not on files. The filters adjust their meaning automatically. For example the size filter sums up the size of all files contained in the given folder instead of returning the size of a single file. Of course other filters like exif or filecontent do not work on folders and will return an error.","title":"Targeting directories"},{"location":"rules/#templates-and-placeholders","text":"Placeholder variables are used with curly braces {var} . These variables are always available : {env} ( dict ) All your environment variables. You can access individual env vars like this: {env.MY_VARIABLE} . {path} ( pathlib.Path ) The full path to the current file / folder on the local harddrive. {relative_path} ( str ) the relative path of the current file or dir. {now()} ( datetime ) The current datetime in the local timezone. {utcnow()} ( datetime ) The current UTC datetime. {today()} ( date ) Today's date. In addition to that nearly all filters add new placeholders with information about the currently handled file / folder. Example on how to access the size and hash of a file: rules: - locations: ~/Desktop filters: - size - hash actions: - echo: \"{size} {hash}\" Note In order to use a value returned by a filter it must be listed in the filters!","title":"Templates and placeholders"},{"location":"rules/#advanced-aliases","text":"Instead of repeating the same locations / actions / filters in each and every rule you can use an alias for multiple locations which you can then reference in each rule. Aliases are a standard feature of the YAML syntax. all_my_messy_folders: &all - ~/Desktop - ~/Downloads - ~/Documents - ~/Dropbox rules: - locations: *all filters: ... actions: ... - locations: *all filters: ... actions: ... You can even use multiple folder lists: private_folders: &private - \"/path/private\" - \"~/path/private\" work_folders: &work - \"/path/work\" - \"~/My work folder\" all_folders: &all - *private - *work rules: - locations: *private filters: ... actions: ... - locations: *work filters: ... actions: ... - locations: *all filters: ... actions: ... # same as *all - locations: - *work - *private filters: ... actions: ...","title":"Advanced: Aliases"},{"location":"textract-hints/","text":"Textract installation hints # Textract needs Poppler to extract text from PDFs. Windows # Download the latest binary of your choice from github.com/oschwartz10612 . In this example we will download and use Release-22.01.0-0.zip . Extract the archive file Release-22.01.0-0.zip Copy the folders from poppler-22.01.0\\Library into C:\\Program Files\\Poppler . Thus, the directory structure should look something like this: C:\\Program Files\\Poppler \\bin \\include \\lib \\share Add C:\\Program Files\\Poppler\\bin to your system PATH! Try it with a filecontent example rule","title":"Textract installation hints"},{"location":"textract-hints/#textract-installation-hints","text":"Textract needs Poppler to extract text from PDFs.","title":"Textract installation hints"},{"location":"textract-hints/#windows","text":"Download the latest binary of your choice from github.com/oschwartz10612 . In this example we will download and use Release-22.01.0-0.zip . Extract the archive file Release-22.01.0-0.zip Copy the folders from poppler-22.01.0\\Library into C:\\Program Files\\Poppler . Thus, the directory structure should look something like this: C:\\Program Files\\Poppler \\bin \\include \\lib \\share Add C:\\Program Files\\Poppler\\bin to your system PATH! Try it with a filecontent example rule","title":"Windows"}]}